#!/usr/bin/env python3
"""
ğŸ¯ åŸºäºé«˜åˆ†æ¨¡å‹çš„æ¦‚ç‡ä¼˜åŒ–å™¨
ä½¿ç”¨æ‰€æœ‰é«˜åˆ†æ–‡ä»¶å»ºç«‹æ¯ä¸ªè´¦æˆ·çš„Badæ¦‚ç‡ï¼Œæ™ºèƒ½é€‰æ‹©æœ€ä¼˜çš„727ä¸ªBadè´¦æˆ·
"""
import pandas as pd
import numpy as np
from pathlib import Path
import json
import os
from collections import Counter, defaultdict
from datetime import datetime
from upload import submit_file
from time import sleep

class ProbabilityBasedOptimizer:
    def __init__(self):
        self.high_score_dir = Path("/Users/mannormal/4011/Qi Zihan/v2/results/high_score_predictions")
        self.target_bad_count = 727  # å·²çŸ¥çœŸå®Badæ•°é‡
        self.results_dir = Path("/Users/mannormal/4011/Qi Zihan/v2/results")
        self.probability_file = self.results_dir / "account_probabilities.json"
        
        print("ğŸ¯ æ¦‚ç‡ä¼˜åŒ–å™¨åˆå§‹åŒ–")
        print(f"   ç›®æ ‡Badæ•°é‡: {self.target_bad_count}")
        
        # åŠ è½½æ‰€æœ‰é«˜åˆ†æ¨¡å‹
        self.load_high_score_models()
        
        # è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„Badæ¦‚ç‡
        self.calculate_account_probabilities()
        
    def load_high_score_models(self):
        """åŠ è½½æ‰€æœ‰é«˜åˆ†æ¨¡å‹é¢„æµ‹"""
        print(f"\nğŸ“‚ åŠ è½½é«˜åˆ†æ¨¡å‹...")
        
        self.models = {}
        self.model_scores = {}
        
        for filepath in self.high_score_dir.glob("*.csv"):
            filename = filepath.name
            
            # æå–çœŸå®F1åˆ†æ•°
            if "REAL_F1_" in filename:
                try:
                    score_part = filename.split("REAL_F1_")[1].replace(".csv", "")
                    score = float(score_part)
                except:
                    score = 0.0
            else:
                score = 0.0
            
            if score < 0.73:  # è¿‡æ»¤ä½åˆ†æ¨¡å‹
                continue
                
            try:
                df = pd.read_csv(filepath)
                if len(df.columns) >= 2:
                    # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯IDï¼Œç¬¬äºŒåˆ—æ˜¯é¢„æµ‹
                    id_col = df.columns[0]
                    pred_col = df.columns[1]
                    
                    model_key = filename.replace(".csv", "")
                    self.models[model_key] = dict(zip(df[id_col], df[pred_col]))
                    self.model_scores[model_key] = score
                    
                    bad_rate = df[pred_col].mean()
                    print(f"âœ… {model_key[:50]:<50} | F1: {score:.4f} | Badç‡: {bad_rate:.3f}")
                    
            except Exception as e:
                print(f"âŒ è·³è¿‡ {filename}: {e}")
        
        print(f"\nğŸ“Š æˆåŠŸåŠ è½½ {len(self.models)} ä¸ªé«˜åˆ†æ¨¡å‹")
        print(f"   F1åˆ†æ•°èŒƒå›´: {min(self.model_scores.values()):.4f} - {max(self.model_scores.values()):.4f}")
        
    def calculate_account_probabilities(self):
        """è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„Badæ¦‚ç‡"""
        print(f"\nğŸ§® è®¡ç®—è´¦æˆ·Badæ¦‚ç‡...")
        
        # è·å–æ‰€æœ‰è´¦æˆ·ID
        all_accounts = set()
        for model_pred in self.models.values():
            all_accounts.update(model_pred.keys())
        all_accounts = sorted(all_accounts)
        
        print(f"   æ€»è´¦æˆ·æ•°: {len(all_accounts)}")
        
        self.account_probabilities = {}
        
        for account_id in all_accounts:
            votes = []
            weights = []
            
            # æ”¶é›†æ¯ä¸ªæ¨¡å‹å¯¹è¯¥è´¦æˆ·çš„é¢„æµ‹å’Œæƒé‡
            for model_name, predictions in self.models.items():
                if account_id in predictions:
                    prediction = predictions[account_id]
                    weight = self.model_scores[model_name]  # ç”¨F1åˆ†æ•°ä½œä¸ºæƒé‡
                    
                    votes.append(prediction)
                    weights.append(weight)
            
            if votes:
                # åŠ æƒå¹³å‡æ¦‚ç‡
                weighted_prob = np.average(votes, weights=weights)
                
                # ç®€å•æŠ•ç¥¨æ¦‚ç‡
                simple_prob = np.mean(votes)
                
                # æœ€é«˜åˆ†æ¨¡å‹çš„é¢„æµ‹
                max_weight_idx = np.argmax(weights)
                top_model_pred = votes[max_weight_idx]
                
                self.account_probabilities[account_id] = {
                    'weighted_probability': weighted_prob,
                    'simple_probability': simple_prob,
                    'top_model_prediction': top_model_pred,
                    'vote_count': len(votes),
                    'votes': votes,
                    'weights': weights,
                    'max_weight': max(weights),
                    'consensus_strength': self._calculate_consensus_strength(votes)
                }
        
        print(f"   å®Œæˆæ¦‚ç‡è®¡ç®—: {len(self.account_probabilities)} ä¸ªè´¦æˆ·")
        
        # ä¿å­˜æ¦‚ç‡æ•°æ®
        self.save_probability_data()
        
        # åˆ†ææ¦‚ç‡åˆ†å¸ƒ
        self.analyze_probability_distribution()
    
    def _calculate_consensus_strength(self, votes):
        """è®¡ç®—æ¨¡å‹é—´ä¸€è‡´æ€§å¼ºåº¦"""
        if len(votes) <= 1:
            return 1.0
        
        # è®¡ç®—æ–¹å·®ï¼Œæ–¹å·®è¶Šå°ä¸€è‡´æ€§è¶Šå¼º
        variance = np.var(votes)
        # è½¬æ¢ä¸º0-1ä¹‹é—´çš„ä¸€è‡´æ€§åˆ†æ•°
        consensus = 1.0 / (1.0 + variance * 4)  # è°ƒèŠ‚å› å­4
        return consensus
    
    def save_probability_data(self):
        """ä¿å­˜æ¦‚ç‡æ•°æ®åˆ°JSONæ–‡ä»¶"""
        # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ï¼Œä¾¿äºJSONåºåˆ—åŒ–
        serializable_data = {}
        for account_id, data in self.account_probabilities.items():
            serializable_data[account_id] = {
                'weighted_probability': float(data['weighted_probability']),
                'simple_probability': float(data['simple_probability']),
                'top_model_prediction': int(data['top_model_prediction']),
                'vote_count': int(data['vote_count']),
                'votes': [int(v) for v in data['votes']],
                'weights': [float(w) for w in data['weights']],
                'max_weight': float(data['max_weight']),
                'consensus_strength': float(data['consensus_strength'])
            }
        
        save_data = {
            'metadata': {
                'created_at': datetime.now().isoformat(),
                'model_count': len(self.models),
                'account_count': len(self.account_probabilities),
                'target_bad_count': self.target_bad_count
            },
            'model_scores': self.model_scores,
            'account_probabilities': serializable_data
        }
        
        with open(self.probability_file, 'w') as f:
            json.dump(save_data, f, indent=2)
        
        print(f"ğŸ’¾ æ¦‚ç‡æ•°æ®å·²ä¿å­˜: {self.probability_file}")
    
    def analyze_probability_distribution(self):
        """åˆ†ææ¦‚ç‡åˆ†å¸ƒ"""
        print(f"\nğŸ“Š æ¦‚ç‡åˆ†å¸ƒåˆ†æ:")
        
        weighted_probs = [data['weighted_probability'] for data in self.account_probabilities.values()]
        simple_probs = [data['simple_probability'] for data in self.account_probabilities.values()]
        consensus_scores = [data['consensus_strength'] for data in self.account_probabilities.values()]
        
        print(f"   åŠ æƒæ¦‚ç‡ç»Ÿè®¡:")
        print(f"     å‡å€¼: {np.mean(weighted_probs):.4f}")
        print(f"     æ ‡å‡†å·®: {np.std(weighted_probs):.4f}")
        print(f"     25%åˆ†ä½: {np.percentile(weighted_probs, 25):.4f}")
        print(f"     50%åˆ†ä½: {np.percentile(weighted_probs, 50):.4f}")
        print(f"     75%åˆ†ä½: {np.percentile(weighted_probs, 75):.4f}")
        
        print(f"\n   ä¸€è‡´æ€§åˆ†æ:")
        print(f"     å¹³å‡ä¸€è‡´æ€§: {np.mean(consensus_scores):.4f}")
        high_consensus = sum(1 for s in consensus_scores if s > 0.8)
        low_consensus = sum(1 for s in consensus_scores if s < 0.5)
        print(f"     é«˜ä¸€è‡´æ€§è´¦æˆ· (>0.8): {high_consensus} ({high_consensus/len(consensus_scores)*100:.1f}%)")
        print(f"     ä½ä¸€è‡´æ€§è´¦æˆ· (<0.5): {low_consensus} ({low_consensus/len(consensus_scores)*100:.1f}%)")
        
        # é¢„æµ‹å½“å‰æœ€ä¼˜çš„727ä¸ªBad
        print(f"\nğŸ¯ åŸºäºæ¦‚ç‡é¢„æµ‹æœ€ä¼˜727ä¸ªBad:")
        sorted_accounts = self.get_top_bad_candidates(method='weighted')
        
        top_727_weighted_probs = [self.account_probabilities[acc]['weighted_probability'] 
                                 for acc in sorted_accounts[:727]]
        print(f"   Top 727å¹³å‡æ¦‚ç‡: {np.mean(top_727_weighted_probs):.4f}")
        print(f"   æœ€ä½Badæ¦‚ç‡: {min(top_727_weighted_probs):.4f}")
        print(f"   æœ€é«˜Badæ¦‚ç‡: {max(top_727_weighted_probs):.4f}")
        
        # è¾¹ç•Œåˆ†æ
        if len(sorted_accounts) > 727:
            boundary_prob = self.account_probabilities[sorted_accounts[726]]['weighted_probability']
            next_prob = self.account_probabilities[sorted_accounts[727]]['weighted_probability']
            print(f"   è¾¹ç•Œæ¦‚ç‡: {boundary_prob:.4f} vs {next_prob:.4f} (å·®è·: {boundary_prob-next_prob:.4f})")
    
    def get_top_bad_candidates(self, n=727, method='weighted'):
        """è·å–Top Nä¸ªBadå€™é€‰è´¦æˆ·"""
        if method == 'weighted':
            sorted_accounts = sorted(self.account_probabilities.keys(),
                                   key=lambda x: self.account_probabilities[x]['weighted_probability'],
                                   reverse=True)
        elif method == 'simple':
            sorted_accounts = sorted(self.account_probabilities.keys(),
                                   key=lambda x: self.account_probabilities[x]['simple_probability'],
                                   reverse=True)
        elif method == 'consensus':
            # ä¼˜å…ˆé€‰æ‹©é«˜æ¦‚ç‡ä¸”é«˜ä¸€è‡´æ€§çš„è´¦æˆ·
            sorted_accounts = sorted(self.account_probabilities.keys(),
                                   key=lambda x: (self.account_probabilities[x]['weighted_probability'] * 
                                                self.account_probabilities[x]['consensus_strength']),
                                   reverse=True)
        else:  # top_model
            sorted_accounts = sorted(self.account_probabilities.keys(),
                                   key=lambda x: (self.account_probabilities[x]['top_model_prediction'],
                                                self.account_probabilities[x]['max_weight']),
                                   reverse=True)
        
        return sorted_accounts[:n]
    
    def create_probability_based_submission(self, method='weighted', name_suffix=''):
        """åˆ›å»ºåŸºäºæ¦‚ç‡çš„æäº¤æ–‡ä»¶"""
        print(f"\nğŸ¯ åˆ›å»ºåŸºäºæ¦‚ç‡çš„æäº¤ (æ–¹æ³•: {method})")
        
        top_bad_accounts = self.get_top_bad_candidates(self.target_bad_count, method)
        
        # åˆ›å»ºæäº¤æ•°æ®
        submission_data = []
        all_accounts = sorted(self.account_probabilities.keys())
        
        for account_id in all_accounts:
            prediction = 1 if account_id in top_bad_accounts else 0
            submission_data.append({
                'ID': account_id,
                'Predict': prediction
            })
        
        # åˆ›å»ºDataFrame
        submission_df = pd.DataFrame(submission_data)
        
        # ç»Ÿè®¡
        bad_count = sum(submission_df['Predict'])
        good_count = len(submission_df) - bad_count
        
        print(f"ğŸ“Š æäº¤ç»Ÿè®¡:")
        print(f"   Bad (1): {bad_count} ({bad_count/len(submission_df)*100:.2f}%)")
        print(f"   Good (0): {good_count} ({good_count/len(submission_df)*100:.2f}%)")
        
        # ä¿å­˜æ–‡ä»¶
        timestamp = datetime.now().strftime("%H%M%S")
        filename = f"PROBABILITY_{method.upper()}_{self.target_bad_count}{name_suffix}_{timestamp}.csv"
        filepath = self.results_dir / filename
        
        submission_df.to_csv(filepath, index=False)
        print(f"âœ… ä¿å­˜: {filename}")
        
        return filepath, submission_df
    
    def create_multiple_strategies(self):
        """åˆ›å»ºå¤šç§ç­–ç•¥çš„æäº¤æ–‡ä»¶"""
        print(f"\nğŸš€ ç”Ÿæˆå¤šç§æ¦‚ç‡ç­–ç•¥...")
        
        strategies = [
            ('weighted', 'åŸºäºF1åŠ æƒæ¦‚ç‡'),
            ('simple', 'ç®€å•æŠ•ç¥¨æ¦‚ç‡'), 
            ('consensus', 'æ¦‚ç‡Ã—ä¸€è‡´æ€§'),
            ('top_model', 'æœ€é«˜åˆ†æ¨¡å‹ä¸»å¯¼')
        ]
        
        submissions = []
        
        for method, description in strategies:
            print(f"\nğŸ“ ç­–ç•¥: {description}")
            filepath, submission_df = self.create_probability_based_submission(method)
            submissions.append({
                'method': method,
                'description': description,
                'filepath': filepath,
                'submission_df': submission_df
            })
        
        return submissions
    
    def submit_and_compare_strategies(self, submissions):
        """æäº¤å¹¶æ¯”è¾ƒä¸åŒç­–ç•¥"""
        print(f"\nğŸš€ æäº¤å¹¶æ¯”è¾ƒç­–ç•¥æ•ˆæœ...")
        
        results = []
        
        for i, submission in enumerate(submissions):
            print(f"\nğŸ¯ æäº¤ç­–ç•¥ {i+1}/{len(submissions)}: {submission['description']}")
            
            try:
                score = submit_file(12507, str(submission['filepath']))
                if score is not None:
                    print(f"   F1åˆ†æ•°: {score:.6f}")
                    
                    # é‡å‘½åæ–‡ä»¶åŒ…å«åˆ†æ•°
                    old_filepath = submission['filepath']
                    new_filename = old_filepath.stem + f"_F1_{score:.6f}.csv"
                    new_filepath = old_filepath.parent / new_filename
                    os.rename(old_filepath, new_filepath)
                    
                    results.append({
                        'method': submission['method'],
                        'description': submission['description'],
                        'f1_score': score,
                        'filepath': new_filepath
                    })
                    
                    print(f"   âœ… é‡å‘½åä¸º: {new_filename}")
                    
                else:
                    print(f"   âŒ æäº¤å¤±è´¥")
                    
            except Exception as e:
                print(f"   âŒ é”™è¯¯: {e}")
            
            # é¿å…æäº¤è¿‡å¿«
            if i < len(submissions) - 1:
                print(f"   â±ï¸  ç­‰å¾…3ç§’...")
                sleep(3)
        
        # ç»“æœæ’åºå’Œåˆ†æ
        if results:
            results.sort(key=lambda x: x['f1_score'], reverse=True)
            
            print(f"\nğŸ† ç­–ç•¥æ•ˆæœæ’å:")
            print("æ’å | æ–¹æ³•        | F1åˆ†æ•°   | æè¿°")
            print("-" * 50)
            
            for i, result in enumerate(results, 1):
                print(f"{i:2d}   | {result['method']:<10} | {result['f1_score']:.6f} | {result['description']}")
            
            best_result = results[0]
            print(f"\nğŸ‰ æœ€ä½³ç­–ç•¥: {best_result['method']} (F1: {best_result['f1_score']:.6f})")
            
            return results
        else:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„æäº¤")
            return []

def main():
    """ä¸»ç¨‹åº"""
    print("ğŸ¯ æ¦‚ç‡ä¼˜åŒ–å™¨å¯åŠ¨")
    print("="*50)
    
    optimizer = ProbabilityBasedOptimizer()
    
    # åˆ›å»ºå¤šç§ç­–ç•¥
    submissions = optimizer.create_multiple_strategies()
    
    print(f"\nâ“ æ˜¯å¦è¦æäº¤æ‰€æœ‰ç­–ç•¥è¿›è¡Œæ¯”è¾ƒï¼Ÿ")
    print(f"   ç­–ç•¥æ•°é‡: {len(submissions)}")
    print(f"   ç›®æ ‡: æ‰¾åˆ°æœ€ä¼˜çš„727ä¸ªBadè´¦æˆ·é€‰æ‹©æ–¹æ³•")
    
    choice = input("æäº¤æ‰€æœ‰ç­–ç•¥? (y/n): ").lower().strip()
    if choice == 'y':
        results = optimizer.submit_and_compare_strategies(submissions)
        
        if results:
            best_f1 = results[0]['f1_score']
            print(f"\nğŸ¯ æœ€ç»ˆç»“æœ:")
            print(f"   æœ€é«˜F1: {best_f1:.6f}")
            
            if best_f1 > 0.80:
                print("ğŸ‰ çªç ´0.8å¤§å…³ï¼åŸºäºæ¦‚ç‡çš„æ–¹æ³•éå¸¸æˆåŠŸï¼")
            elif best_f1 > 0.77:
                print("ğŸŠ æ˜¾è‘—æ”¹è¿›ï¼æ¥è¿‘æœ€ä¼˜è§£ï¼")
            else:
                print("ğŸ¤” éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–æ¦‚ç‡æ¨¡å‹")

if __name__ == "__main__":
    main()