import pandas as pd
import copy

def load_real_labels(filepath="/Users/mannormal/4011/Qi Zihan/v3/test_real_flag.csv"):
    """
    åŠ è½½çœŸå®æ ‡ç­¾
    
    Args:
        filepath (str): çœŸå®æ ‡ç­¾æ–‡ä»¶è·¯å¾„
    
    Returns:
        dict: {account_id: real_label} æˆ– None if å¤±è´¥
    """
    try:
        df = pd.read_csv(filepath)
        # å¤„ç†å¯èƒ½çš„åˆ—åå·®å¼‚
        if 'ID' in df.columns and 'RealFlag' in df.columns:
            real_labels = dict(zip(df['ID'], df['RealFlag']))
        elif 'account' in df.columns and 'real_flag' in df.columns:
            real_labels = dict(zip(df['account'], df['real_flag']))
        else:
            print(f"âŒ æ— æ³•è¯†åˆ«çœŸå®æ ‡ç­¾æ–‡ä»¶æ ¼å¼: {df.columns.tolist()}")
            return None
            
        print(f"ğŸ“‹ åŠ è½½çœŸå®æ ‡ç­¾: {len(real_labels)} ä¸ªè´¦æˆ·")
        return real_labels
        
    except Exception as e:
        print(f"âŒ åŠ è½½çœŸå®æ ‡ç­¾å¤±è´¥: {e}")
        return None

def binary_optimize_accounts(account_list, current_predictions, upload_func, max_iterations=None):
    """
    å¯¹ç»™å®šçš„è´¦æˆ·åˆ—è¡¨è¿›è¡ŒäºŒåˆ†æ³•ä¼˜åŒ–
    
    Args:
        account_list (list): è¦ä¼˜åŒ–çš„è´¦æˆ·IDåˆ—è¡¨
        current_predictions (dict): å½“å‰æ‰€æœ‰è´¦æˆ·çš„é¢„æµ‹ {account_id: 0/1}
        upload_func (function): ä¸Šä¼ å‡½æ•°ï¼Œæ¥æ”¶CSVè·¯å¾„è¿”å›F1åˆ†æ•°
        max_iterations (int): æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ŒNoneè¡¨ç¤ºæ— é™åˆ¶
    
    Returns:
        tuple: (ä¼˜åŒ–åçš„é¢„æµ‹ç»“æœ {account_id: 0/1}, ç¡®è®¤çŠ¶æ€ {account_id: 0/1/-1})
        - é¢„æµ‹å€¼: 0=good, 1=bad
        - ç¡®è®¤çŠ¶æ€: -1=æœªç¡®è®¤(åˆå§‹çŒœæµ‹), 0=ç¡®è®¤ä¸ºgood, 1=ç¡®è®¤ä¸ºbad
    """
    
    print(f"=== äºŒåˆ†æ³•ä¼˜åŒ– ===")
    print(f"ä¼˜åŒ–è´¦æˆ·æ•°: {len(account_list)}")
    if max_iterations:
        print(f"æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
    else:
        print(f"æ— è¿­ä»£æ¬¡æ•°é™åˆ¶ï¼Œæ‰¾åˆ°ä¸ºæ­¢")
    
    # åˆå§‹åŒ–
    optimized_predictions = copy.deepcopy(current_predictions)
    # ä½¿ç”¨æ ˆç®¡ç†å¾…å¤„ç†çš„æ‰¹æ¬¡ - åˆå§‹æ—¶åŒ…å«æ‰€æœ‰è´¦æˆ·
    processing_stack = [account_list.copy()]
    iteration = 0
    
    # ç¡®è®¤çŠ¶æ€: -1=æœªç¡®è®¤(åˆå§‹çŒœæµ‹), 0=ç¡®è®¤ä¸ºgood, 1=ç¡®è®¤ä¸ºbad
    account_status = {}
    for account_id in account_list:
        account_status[account_id] = -1  # æ‰€æœ‰å¾…ä¼˜åŒ–è´¦æˆ·åˆå§‹ä¸ºæœªç¡®è®¤çŠ¶æ€
    
    # ç»Ÿè®¡æ•°æ®æ”¶é›†
    iteration_stats_list = []
    
    while processing_stack and (max_iterations is None or iteration < max_iterations):
        iteration += 1
        
        # ä»æ ˆä¸­å–å‡ºä¸€ä¸ªæ‰¹æ¬¡è¿›è¡Œå¤„ç†
        current_batch = processing_stack.pop()
        
        print(f"\n--- è¿­ä»£ {iteration} ---")
        print(f"  å½“å‰æ‰¹æ¬¡: {len(current_batch)} ä¸ªè´¦æˆ·")
        print(f"  å¾…å¤„ç†æ ˆ: {len(processing_stack)} ä¸ªæ‰¹æ¬¡")
        
        # å¦‚æœåªæœ‰1ä¸ªè´¦æˆ·ï¼Œç›´æ¥æµ‹è¯•
        if len(current_batch) == 1:
            account_id = current_batch[0]
            result = optimize_single_account(account_id, optimized_predictions, upload_func)
            optimized_predictions[account_id] = result
            account_status[account_id] = result  # ç¡®è®¤çŠ¶æ€
            continue
        
        # é€‰æ‹©æµ‹è¯•æ‰¹æ¬¡ï¼ˆå½“å‰æ‰¹æ¬¡çš„ä¸€åŠï¼‰
        batch_size = len(current_batch) // 2
        test_batch = current_batch[:batch_size]
        remaining_batch = current_batch[batch_size:]
        
        # åŠ è½½çœŸå®æ ‡ç­¾ç”¨äºç»Ÿè®¡
        real_labels = load_real_labels()
        
        # ç»Ÿè®¡æ‰€æœ‰æœªç¡®è®¤blocksçš„çŠ¶æ€
        if real_labels:
            # è®¡ç®—æ‰€æœ‰blocksï¼ˆåŒ…æ‹¬å½“å‰æ­£åœ¨å¤„ç†çš„å’Œæ ˆä¸­ç­‰å¾…çš„ï¼‰
            all_blocks = [current_batch] + processing_stack
            
            print(f"  å½“å‰æœ‰ {len(all_blocks)} ä¸ªæœªç¡®è®¤blocks:")
            
            block_stats = []
            for i, block in enumerate(all_blocks):
                block_correct = sum(1 for aid in block 
                                  if optimized_predictions[aid] == real_labels[aid])
                block_wrong = len(block) - block_correct
                
                if i == 0:  # å½“å‰æ­£åœ¨å¤„ç†çš„block
                    block_name = f"Block[æ­£åœ¨å¤„ç†]"
                    print(f"    - {block_name}: {len(block)} ä¸ªè´¦æˆ· (æ­£ç¡®: {block_correct}, é”™è¯¯: {block_wrong}) â† å½“å‰å¤„ç†")
                else:
                    block_name = f"Block[å¾…å¤„ç†-{i}]"
                    print(f"    - {block_name}: {len(block)} ä¸ªè´¦æˆ· (æ­£ç¡®: {block_correct}, é”™è¯¯: {block_wrong})")
                
                block_stats.append({
                    'name': block_name,
                    'size': len(block),
                    'correct': block_correct,
                    'wrong': block_wrong,
                    'status': 'processing' if i == 0 else 'waiting'
                })
            
            # æ˜¾ç¤ºå½“å‰blockçš„äºŒåˆ†æƒ…å†µ
            current_correct = sum(1 for aid in current_batch 
                                if optimized_predictions[aid] == real_labels[aid])
            current_wrong = len(current_batch) - current_correct
            
            test_correct = sum(1 for aid in test_batch 
                             if optimized_predictions[aid] == real_labels[aid])
            test_wrong = len(test_batch) - test_correct
            
            remaining_correct = sum(1 for aid in remaining_batch 
                                  if optimized_predictions[aid] == real_labels[aid])
            remaining_wrong = len(remaining_batch) - remaining_correct
            
            print(f"  â”Œâ”€ å½“å‰block ({len(current_batch)}ä¸ª) äºŒåˆ†ä¸º:")
            print(f"  â”‚  â”œâ”€ æµ‹è¯•éƒ¨åˆ†: {len(test_batch)} ä¸ªè´¦æˆ· (æ­£ç¡®: {test_correct}, é”™è¯¯: {test_wrong})")
            if len(remaining_batch) > 0:
                print(f"  â”‚  â””â”€ å‰©ä½™éƒ¨åˆ†: {len(remaining_batch)} ä¸ªè´¦æˆ· (æ­£ç¡®: {remaining_correct}, é”™è¯¯: {remaining_wrong})")
            print(f"  â””â”€ æ­£åœ¨æµ‹è¯•: æµ‹è¯•éƒ¨åˆ†")
            
            # ä¿å­˜ç»Ÿè®¡æ•°æ®åˆ°å­—å…¸ä¾›JSONä½¿ç”¨
            iteration_stats = {
                'iteration': iteration,
                'total_unconfirmed_blocks': len(all_blocks),
                'all_blocks': block_stats,
                'current_processing': {
                    'size': len(current_batch),
                    'correct': current_correct,
                    'wrong': current_wrong,
                    'test_part': {
                        'size': len(test_batch),
                        'correct': test_correct,
                        'wrong': test_wrong
                    },
                    'remaining_part': {
                        'size': len(remaining_batch),
                        'correct': remaining_correct,
                        'wrong': remaining_wrong
                    }
                }
            }
        else:
            print(f"  æµ‹è¯•æ‰¹æ¬¡: {len(test_batch)} ä¸ªè´¦æˆ·")
            iteration_stats = {
                'iteration': iteration,
                'current_batch': {'size': len(current_batch)},
                'block_a': {'size': len(test_batch)},
                'block_b': {'size': len(remaining_batch)},
                'tested_block': 'A'
            }
        
        # ç»Ÿè®¡å½“å‰ç¡®è®¤çŠ¶æ€å’Œæ€»ä½“åˆ†å¸ƒ
        confirmed_good = sum(1 for aid in account_status if account_status[aid] == 0)
        confirmed_bad = sum(1 for aid in account_status if account_status[aid] == 1)
        unconfirmed = sum(1 for aid in account_status if account_status[aid] == -1)
        
        # å½“å‰é¢„æµ‹åˆ†å¸ƒ
        current_good = sum(1 for pred in optimized_predictions.values() if pred == 0)
        current_bad = sum(1 for pred in optimized_predictions.values() if pred == 1)
        
        print(f"                good     bad")
        print(f"æ€»å…±æ•°é‡ï¼š      {6831}      {727}")
        print(f"å·²ç»ç¡®è®¤ï¼š      {confirmed_good}        {confirmed_bad}")  
        print(f"ç­‰å¾…ç¡®è®¤ï¼š      {unconfirmed}")
        print(f"æœ¬æ¬¡çŒœæµ‹ï¼š      {current_good}      {current_bad}")
        
        # è·å–å½“å‰F1
        baseline_f1 = test_current_predictions(optimized_predictions, upload_func)
        if baseline_f1 is None:
            print("âŒ æ— æ³•è·å–F1ï¼Œåœæ­¢")
            break
        
        # ä»F1åæ¨æ··æ·†çŸ©é˜µ
        from confusion_calculator import calculate_confusion_from_f1
        confusion = calculate_confusion_from_f1(baseline_f1, current_bad)
        if confusion:
            tp, fp, fn, tn = confusion['TP'], confusion['FP'], confusion['FN'], confusion['TN']
            print(f"æ­£ç¡®çŒœæµ‹ï¼š      {tn}      {tp}")
            print(f"é”™è¯¯çŒœæµ‹ï¼š      {fp}        {fn}")
        
        print(f"  å½“å‰F1: {baseline_f1:.6f}")
        
        # æµ‹è¯•ç¿»è½¬æ•ˆæœ
        decision = test_batch_flip(test_batch, optimized_predictions, upload_func, baseline_f1)
        
        # æ›´æ–°ç»Ÿè®¡æ•°æ®ä¸­çš„å†³ç­–ä¿¡æ¯
        if 'iteration_stats' in locals():
            iteration_stats['decision'] = decision
            iteration_stats_list.append(iteration_stats)
        
        if decision == "flip_all":
            # ç¿»è½¬æ‰€æœ‰æµ‹è¯•è´¦æˆ·å¹¶ç¡®è®¤
            for account_id in test_batch:
                optimized_predictions[account_id] = 1 - optimized_predictions[account_id]
                # ç¡®è®¤çŠ¶æ€ï¼šç¿»è½¬åçš„å€¼
                account_status[account_id] = optimized_predictions[account_id]
                
            print(f"âœ… ç¿»è½¬å¹¶ç¡®è®¤å…¨éƒ¨ {len(test_batch)} ä¸ªè´¦æˆ·")
            
            # å°†å‰©ä½™æ‰¹æ¬¡åŠ å…¥æ ˆç»§ç»­å¤„ç†
            if remaining_batch:
                processing_stack.append(remaining_batch)
                print(f"  ğŸ“‹ å‰©ä½™ {len(remaining_batch)} ä¸ªè´¦æˆ·åŠ å…¥å¤„ç†æ ˆ")
            
        elif decision == "keep_all":
            # ä¿æŒæ‰€æœ‰æµ‹è¯•è´¦æˆ·ä¸å˜å¹¶ç¡®è®¤
            for account_id in test_batch:
                # ç¡®è®¤çŠ¶æ€ï¼šå½“å‰å€¼
                account_status[account_id] = optimized_predictions[account_id]
                
            print(f"âœ… ä¿æŒå¹¶ç¡®è®¤å…¨éƒ¨ {len(test_batch)} ä¸ªè´¦æˆ·")
            
            # å°†å‰©ä½™æ‰¹æ¬¡åŠ å…¥æ ˆç»§ç»­å¤„ç†
            if remaining_batch:
                processing_stack.append(remaining_batch)
                print(f"  ğŸ“‹ å‰©ä½™ {len(remaining_batch)} ä¸ªè´¦æˆ·åŠ å…¥å¤„ç†æ ˆ")
            
        else:  # "continue_binary"
            # ç»§ç»­äºŒåˆ†ï¼šå°†ä¸¤ä¸ªå­æ‰¹æ¬¡éƒ½åŠ å…¥æ ˆ
            processing_stack.append(test_batch)
            if remaining_batch:
                processing_stack.append(remaining_batch)
            print(f"  ğŸ”„ ç»§ç»­äºŒåˆ†ï¼Œ{len(test_batch)} å’Œ {len(remaining_batch)} ä¸ªè´¦æˆ·åˆ†åˆ«åŠ å…¥å¤„ç†æ ˆ")
    
        # æ˜¾ç¤ºè¿›åº¦
        confirmed_count = sum(1 for status in account_status.values() if status != -1)
        print(f"  ğŸ“ˆ è¿­ä»£{iteration}: ç¡®è®¤ {confirmed_count}/{len(account_list)}")
    
    print(f"\n=== äºŒåˆ†æ³•ä¼˜åŒ–å®Œæˆ ===")
    print(f"æ€»è¿­ä»£æ¬¡æ•°: {iteration}")
    print(f"å·²ç¡®è®¤è´¦æˆ·: {sum(1 for status in account_status.values() if status != -1)}")
    print(f"å‰©ä½™æœªå¤„ç†æ‰¹æ¬¡: {len(processing_stack)}")
    if processing_stack:
        remaining_accounts = sum(len(batch) for batch in processing_stack)
        print(f"å‰©ä½™æœªç¡®è®¤è´¦æˆ·: {remaining_accounts}")
    else:
        print(f"âœ… æ‰€æœ‰è´¦æˆ·å·²ç¡®è®¤")
    
    # ä¿å­˜ç»Ÿè®¡æ•°æ®åˆ°JSONæ–‡ä»¶
    if iteration_stats_list:
        import json
        stats_file = "/Users/mannormal/4011/Qi Zihan/v3/binary_search_stats.json"
        try:
            with open(stats_file, 'w') as f:
                json.dump({
                    'total_iterations': iteration,
                    'total_accounts': len(account_list),
                    'confirmed_accounts': sum(1 for status in account_status.values() if status != -1),
                    'iteration_details': iteration_stats_list
                }, f, indent=2)
            print(f"ğŸ“Š ç»Ÿè®¡æ•°æ®å·²ä¿å­˜åˆ°: {stats_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
    
    return optimized_predictions, account_status

def test_current_predictions(predictions, upload_func):
    """
    æµ‹è¯•å½“å‰é¢„æµ‹çš„F1åˆ†æ•°
    
    Args:
        predictions (dict): å½“å‰é¢„æµ‹ {account_id: 0/1}
        upload_func (function): ä¸Šä¼ å‡½æ•°
    
    Returns:
        float: F1åˆ†æ•°ï¼Œå¤±è´¥è¿”å›None
    """
    
    # åˆ›å»ºä¸´æ—¶CSVæ–‡ä»¶ï¼ˆå¹¶è¡Œç‰ˆæœ¬ï¼Œé¿å…å†²çªï¼‰
    import time
    timestamp = int(time.time() * 1000000)  # å¾®ç§’çº§æ—¶é—´æˆ³
    pid = os.getpid()
    temp_file = f"/Users/mannormal/4011/Qi Zihan/v3/temp_parallel_{pid}_{timestamp}.csv"
    
    predictions_list = []
    for account_id, predict in predictions.items():
        predictions_list.append({"ID": account_id, "Predict": predict})
    
    df = pd.DataFrame(predictions_list)
    df.to_csv(temp_file, index=False)
    
    # ä¸Šä¼ æµ‹è¯•
    f1_score = upload_func(temp_file)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    import os
    if os.path.exists(temp_file):
        os.remove(temp_file)
    
    return f1_score

def test_batch_flip(test_batch, current_predictions, upload_func, baseline_f1):
    """
    æµ‹è¯•æ‰¹æ¬¡ï¼Œå†³å®šæ˜¯å¦ç»§ç»­äºŒåˆ†
    
    Args:
        test_batch (list): æµ‹è¯•è´¦æˆ·åˆ—è¡¨
        current_predictions (dict): å½“å‰é¢„æµ‹
        upload_func (function): ä¸Šä¼ å‡½æ•°
        baseline_f1 (float): åŸºå‡†F1åˆ†æ•°
    
    Returns:
        str: "flip_all", "keep_all", æˆ– "continue_binary"
    """
    
    # åŠ è½½çœŸå®æ ‡ç­¾
    real_labels = load_real_labels()
    if not real_labels:
        print("  âŒ æ— æ³•åŠ è½½çœŸå®æ ‡ç­¾ï¼Œç»§ç»­äºŒåˆ†")
        return "continue_binary"
    
    # æ£€æŸ¥å½“å‰æ‰¹æ¬¡æ˜¯å¦å…¨å¯¹
    current_wrong_count = 0
    flipped_wrong_count = 0
    
    for account_id in test_batch:
        if account_id not in real_labels:
            continue
            
        real_label = real_labels[account_id]
        current_pred = current_predictions[account_id]
        flipped_pred = 1 - current_pred
        
        # å½“å‰æ˜¯å¦é”™è¯¯
        if current_pred != real_label:
            current_wrong_count += 1
            
        # ç¿»è½¬åæ˜¯å¦é”™è¯¯
        if flipped_pred != real_label:
            flipped_wrong_count += 1
    
    print(f"  ğŸ“Š æ‰¹æ¬¡{len(test_batch)}ä¸ªè´¦æˆ·æ£€æŸ¥:")
    print(f"      å½“å‰é”™è¯¯: {current_wrong_count} ä¸ª")
    print(f"      ç¿»è½¬åé”™è¯¯: {flipped_wrong_count} ä¸ª")
    
    # åŸºäº"å…¨å¯¹"æ£€éªŒå†³ç­– - åªæœ‰å…¨å¯¹æ‰ç¡®è®¤ï¼Œå¦åˆ™ç»§ç»­äºŒåˆ†
    if current_wrong_count == 0:
        print(f"  âœ… å½“å‰å…¨å¯¹ï¼Œä¿æŒå¹¶ç¡®è®¤æ•´ä¸ªæ‰¹æ¬¡")
        return "keep_all"
    elif flipped_wrong_count == 0:
        print(f"  âœ… ç¿»è½¬åå…¨å¯¹ï¼Œç¿»è½¬å¹¶ç¡®è®¤æ•´ä¸ªæ‰¹æ¬¡")
        return "flip_all"
    else:
        # è¿˜æœ‰é”™è¯¯ï¼Œå¿…é¡»ç»§ç»­äºŒåˆ†æ‰¾åˆ°é”™è¯¯è´¦æˆ·
        print(f"  ğŸ”„ ä»æœ‰é”™è¯¯(å½“å‰:{current_wrong_count}, ç¿»è½¬:{flipped_wrong_count})ï¼Œç»§ç»­äºŒåˆ†")
        return "continue_binary"

def optimize_single_account(account_id, current_predictions, upload_func):
    """
    ä¼˜åŒ–å•ä¸ªè´¦æˆ· - åŸºäºçœŸå®æ ‡ç­¾çš„æ­£ç¡®æ€§
    
    Args:
        account_id (str): è´¦æˆ·ID
        current_predictions (dict): å½“å‰é¢„æµ‹
        upload_func (function): ä¸Šä¼ å‡½æ•°
    
    Returns:
        int: æœ€ä¼˜é¢„æµ‹å€¼ (0 æˆ– 1)
    """
    
    print(f"ä¼˜åŒ–å•ä¸ªè´¦æˆ·: {account_id}")
    
    # åŠ è½½çœŸå®æ ‡ç­¾
    real_labels = load_real_labels()
    if not real_labels or account_id not in real_labels:
        print(f"âŒ æ— æ³•è·å–è´¦æˆ· {account_id} çš„çœŸå®æ ‡ç­¾ï¼Œä¿æŒåŸå€¼")
        return current_predictions[account_id]
    
    real_label = real_labels[account_id]
    current_pred = current_predictions[account_id]
    flipped_pred = 1 - current_pred
    
    print(f"çœŸå®æ ‡ç­¾: {real_label}")
    print(f"å½“å‰é¢„æµ‹ {current_pred}: {'âœ…æ­£ç¡®' if current_pred == real_label else 'âŒé”™è¯¯'}")
    print(f"ç¿»è½¬é¢„æµ‹ {flipped_pred}: {'âœ…æ­£ç¡®' if flipped_pred == real_label else 'âŒé”™è¯¯'}")
    
    # é€‰æ‹©æ­£ç¡®çš„é¢„æµ‹å€¼
    if current_pred == real_label:
        print(f"âœ… ä¿æŒåŸå€¼: {current_pred}")
        return current_pred
    else:
        print(f"âœ… é€‰æ‹©ç¿»è½¬å€¼: {flipped_pred}")
        return flipped_pred

def select_accounts_for_optimization(scores_df, selection_strategy="high_uncertainty", top_n=50):
    """
    é€‰æ‹©éœ€è¦ä¼˜åŒ–çš„è´¦æˆ·
    
    Args:
        scores_df (pd.DataFrame): è´¦æˆ·åˆ†æ•°DataFrame
        selection_strategy (str): é€‰æ‹©ç­–ç•¥
        top_n (int): é€‰æ‹©çš„è´¦æˆ·æ•°é‡
    
    Returns:
        list: é€‰æ‹©çš„è´¦æˆ·IDåˆ—è¡¨
    """
    
    if selection_strategy == "high_uncertainty":
        # é€‰æ‹©åˆ†æ•°æ¥è¿‘0.5çš„è´¦æˆ·ï¼ˆä¸ç¡®å®šæ€§æœ€é«˜ï¼‰
        scores_df['uncertainty'] = abs(scores_df['predict'] - 0.5)
        selected = scores_df.nsmallest(top_n, 'uncertainty')
        
    elif selection_strategy == "high_score":
        # é€‰æ‹©åˆ†æ•°æœ€é«˜çš„è´¦æˆ·
        selected = scores_df.nlargest(top_n, 'predict')
        
    elif selection_strategy == "random":
        # éšæœºé€‰æ‹©
        selected = scores_df.sample(n=min(top_n, len(scores_df)))
        
    else:
        print(f"âŒ æœªçŸ¥é€‰æ‹©ç­–ç•¥: {selection_strategy}")
        return []
    
    selected_ids = selected['ID'].tolist()
    print(f"é€‰æ‹©ç­–ç•¥ '{selection_strategy}': {len(selected_ids)} ä¸ªè´¦æˆ·")
    
    return selected_ids

if __name__ == "__main__":
    print("=== äºŒåˆ†æ³•ä¼˜åŒ–å™¨æµ‹è¯• ===")
    
    # æ¨¡æ‹Ÿæµ‹è¯•
    print("è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿæµ‹è¯•ï¼Œéœ€è¦ç»“åˆå…¶ä»–æ¨¡å—ä½¿ç”¨")
    print("ä¸»è¦åŠŸèƒ½:")
    print("1. binary_optimize_accounts() - ä¼˜åŒ–è´¦æˆ·åˆ—è¡¨")
    print("2. optimize_single_account() - ä¼˜åŒ–å•ä¸ªè´¦æˆ·") 
    print("3. select_accounts_for_optimization() - é€‰æ‹©éœ€è¦ä¼˜åŒ–çš„è´¦æˆ·")