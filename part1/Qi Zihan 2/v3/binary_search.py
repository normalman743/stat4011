import pandas as pd
import copy


def calculate_block_stats_from_inference(parent_block_accounts, base_predictions, 
                                       inferred_true_good, inferred_true_bad):
    """
    åŸºäºæ··æ·†çŸ©é˜µæ¨æ–­ç»“æœè®¡ç®—blockç»Ÿè®¡ä¿¡æ¯
    
    Args:
        parent_block_accounts: çˆ¶blockå†…çš„è´¦æˆ·åˆ—è¡¨
        base_predictions: å½“å‰é¢„æµ‹
        inferred_true_good: é€šè¿‡analyze_binary_splitæ¨æ–­å‡ºçš„çœŸå®goodæ•°é‡
        inferred_true_bad: é€šè¿‡analyze_binary_splitæ¨æ–­å‡ºçš„çœŸå®badæ•°é‡
    
    Returns:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    # ç»Ÿè®¡å½“å‰blockçš„é¢„æµ‹åˆ†å¸ƒ
    pred_good_count = sum(1 for aid in parent_block_accounts if base_predictions[aid] == 0)
    pred_bad_count = len(parent_block_accounts) - pred_good_count
    
    # åŸºäºæ¨æ–­çš„çœŸå®åˆ†å¸ƒå’Œé¢„æµ‹åˆ†å¸ƒè®¡ç®—æ··æ·†çŸ©é˜µç»„ä»¶
    # è¿™é‡Œæˆ‘ä»¬å‡è®¾é¢„æµ‹çš„åˆ†é…æ˜¯"æœ€ä¼˜"çš„ï¼ˆå®é™…ä¸Šä¸ä¸€å®šï¼Œä½†æˆ‘ä»¬åªèƒ½è¿™æ ·ä¼°ç®—ï¼‰
    
    # è®¡ç®—blockå†…çš„æ··æ·†çŸ©é˜µï¼ˆä¼°ç®—ï¼‰
    # æœ€å¥½æƒ…å†µä¸‹çš„æ­£ç¡®é¢„æµ‹æ•°é‡
    max_correct_good = min(pred_good_count, inferred_true_good)  # TN
    max_correct_bad = min(pred_bad_count, inferred_true_bad)     # TP
    
    # é”™è¯¯é¢„æµ‹æ•°é‡
    wrong_good_pred = pred_good_count - max_correct_good        # FN (é¢„æµ‹goodä½†å®é™…bad)
    wrong_bad_pred = pred_bad_count - max_correct_bad           # FP (é¢„æµ‹badä½†å®é™…good)
    
    total_correct = max_correct_good + max_correct_bad
    total_wrong = wrong_good_pred + wrong_bad_pred
    
    # éªŒè¯ä¸€è‡´æ€§
    assert total_correct + total_wrong == len(parent_block_accounts), "ç»Ÿè®¡ä¸ä¸€è‡´"
    assert max_correct_good + wrong_good_pred == pred_good_count, "goodé¢„æµ‹ç»Ÿè®¡ä¸ä¸€è‡´"
    assert max_correct_bad + wrong_bad_pred == pred_bad_count, "badé¢„æµ‹ç»Ÿè®¡ä¸ä¸€è‡´"
    
    return {
        'correct': total_correct,           # æ€»æ­£ç¡®é¢„æµ‹æ•°
        'wrong': total_wrong,               # æ€»é”™è¯¯é¢„æµ‹æ•°
        'pred_good': pred_good_count,       # é¢„æµ‹ä¸ºgoodçš„æ•°é‡
        'pred_bad': pred_bad_count,         # é¢„æµ‹ä¸ºbadçš„æ•°é‡
        'correct_good': max_correct_good,   # æ­£ç¡®é¢„æµ‹çš„good (TN)
        'correct_bad': max_correct_bad,     # æ­£ç¡®é¢„æµ‹çš„bad (TP) 
        'wrong_good': wrong_good_pred,      # é”™è¯¯é¢„æµ‹ä¸ºgood (FN)
        'wrong_bad': wrong_bad_pred,        # é”™è¯¯é¢„æµ‹ä¸ºbad (FP)
        'true_good': inferred_true_good,    # æ¨æ–­çš„çœŸå®goodæ•°é‡
        'true_bad': inferred_true_bad       # æ¨æ–­çš„çœŸå®badæ•°é‡
    }


def analyze_binary_split(confusion_baseline, confusion_flipped, n_b, total_good, total_bad, 
                       base_predictions, parent_block_accounts):
    """
    åˆ†æäºŒåˆ†ç»“æœ
    
    Args:
        confusion_baseline: åŸºå‡†æ··æ·†çŸ©é˜µ
        confusion_flipped: ç¿»è½¬åæ··æ·†çŸ©é˜µ
        n_b: block_bçš„å¤§å°
        total_good: å±‚çº§åŸºå‡†ä¸­çš„æ€»goodæ•°é‡
        total_bad: å±‚çº§åŸºå‡†ä¸­çš„æ€»badæ•°é‡
        base_predictions: å½“å‰é¢„æµ‹
        parent_block_accounts: çˆ¶blockçš„è´¦æˆ·åˆ—è¡¨
    
    Returns:
        (a_status, b_status, block_stats): ä¸¤ä¸ªblockçš„çŠ¶æ€åˆ¤æ–­å’Œç»Ÿè®¡ä¿¡æ¯
    """
    # è®¡ç®—å˜åŒ–é‡
    delta_tp = confusion_flipped['TP'] - confusion_baseline['TP']
    delta_fp = confusion_flipped['FP'] - confusion_baseline['FP']
    
    # æ¨æ–­block_bçš„çœŸå®åˆ†å¸ƒ
    b_bad = delta_tp
    b_good = delta_fp
    
    # éªŒè¯ä¸€è‡´æ€§
    if b_bad + b_good != n_b:
        return "MIXED", "MIXED", {'correct': 0, 'wrong': len(parent_block_accounts), 'pred_good': 0, 'pred_bad': 0}
    
    # æ¨æ–­æ•´ä¸ªparent_blockçš„çœŸå®åˆ†å¸ƒ
    parent_true_bad = total_bad  # ä½¿ç”¨å±‚çº§åŸºå‡†
    parent_true_good = total_good
    
    # ä½¿ç”¨æ–°å‡½æ•°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    block_stats = calculate_block_stats_from_inference(
        parent_block_accounts, 
        base_predictions, 
        parent_true_good, 
        parent_true_bad
    )
    
    # åˆ¤å®šblockçŠ¶æ€
    if b_bad == n_b:
        b_status = "ALL_BAD"
    elif b_good == n_b:
        b_status = "ALL_GOOD"
    else:
        b_status = "MIXED"
    
    a_bad = total_bad - b_bad
    a_good = total_good - b_good
    
    if a_bad == 0:
        a_status = "ALL_GOOD"
    elif a_good == 0:
        a_status = "ALL_BAD"
    else:
        a_status = "MIXED"
    
    return a_status, b_status, block_stats


def binary_optimize_accounts(account_list, current_predictions, upload_func, max_iterations=None):
    """
    å¯¹ç»™å®šçš„è´¦æˆ·åˆ—è¡¨è¿›è¡ŒäºŒåˆ†æ³•ä¼˜åŒ–ï¼ˆåŸºäºæ··æ·†çŸ©é˜µæ¨æ–­ï¼Œä¸ä½¿ç”¨çœŸå®æ ‡ç­¾ï¼‰
    
    Args:
        account_list (list): è¦ä¼˜åŒ–çš„è´¦æˆ·IDåˆ—è¡¨
        current_predictions (dict): å½“å‰æ‰€æœ‰è´¦æˆ·çš„é¢„æµ‹ {account_id: 0/1}
        upload_func (function): ä¸Šä¼ å‡½æ•°ï¼Œæ¥æ”¶CSVè·¯å¾„è¿”å›F1åˆ†æ•°
        max_iterations (int): æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ŒNoneè¡¨ç¤ºæ— é™åˆ¶
    
    Returns:
        tuple: (ä¼˜åŒ–åçš„é¢„æµ‹ç»“æœ {account_id: 0/1}, ç¡®è®¤çŠ¶æ€ {account_id: 0/1/-1})
        - é¢„æµ‹å€¼: 0=good, 1=bad
        - ç¡®è®¤çŠ¶æ€: -1=æœªç¡®è®¤(åˆå§‹çŒœæµ‹), 0=ç¡®è®¤ä¸ºgood, 1=ç¡®è®¤ä¸ºbad
    """
    
    print(f"=== äºŒåˆ†æ³•ä¼˜åŒ–ï¼ˆåŸºäºæ··æ·†çŸ©é˜µæ¨æ–­ï¼‰===")
    print(f"ä¼˜åŒ–è´¦æˆ·æ•°: {len(account_list)}")
    if max_iterations:
        print(f"æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
    else:
        print(f"æ— è¿­ä»£æ¬¡æ•°é™åˆ¶ï¼Œæ‰¾åˆ°ä¸ºæ­¢")
    
    # åˆå§‹åŒ–
    optimized_predictions = copy.deepcopy(current_predictions)
    # ä½¿ç”¨æ ˆç®¡ç†å¾…å¤„ç†çš„æ‰¹æ¬¡ - åˆå§‹æ—¶åŒ…å«æ‰€æœ‰è´¦æˆ·
    processing_stack = [account_list.copy()]
    iteration = 0
    
    # ç¡®è®¤çŠ¶æ€: -1=æœªç¡®è®¤(åˆå§‹çŒœæµ‹), 0=ç¡®è®¤ä¸ºgood, 1=ç¡®è®¤ä¸ºbad
    account_status = {}
    for account_id in account_list:
        account_status[account_id] = -1  # æ‰€æœ‰å¾…ä¼˜åŒ–è´¦æˆ·åˆå§‹ä¸ºæœªç¡®è®¤çŠ¶æ€
    
    # ç»Ÿè®¡æ•°æ®æ”¶é›†
    iteration_stats_list = []
    
    # è·å–åŸºå‡†æ··æ·†çŸ©é˜µ
    baseline_f1 = test_current_predictions(optimized_predictions, upload_func)
    if baseline_f1 is None:
        print("âŒ æ— æ³•è·å–åŸºå‡†F1ï¼Œåœæ­¢")
        return optimized_predictions, account_status
    
    from confusion_calculator import calculate_confusion_from_f1
    current_bad = sum(1 for pred in optimized_predictions.values() if pred == 1)
    baseline_confusion = calculate_confusion_from_f1(baseline_f1, current_bad)
    if not baseline_confusion:
        print("âŒ æ— æ³•è®¡ç®—åŸºå‡†æ··æ·†çŸ©é˜µï¼Œåœæ­¢")
        return optimized_predictions, account_status
    
    # æ ¹æ®æ··æ·†çŸ©é˜µæ¨æ–­æ€»ä½“çœŸå®åˆ†å¸ƒ
    total_good = 6831  # å·²çŸ¥çœŸå®åˆ†å¸ƒ
    total_bad = 727
    
    while processing_stack and (max_iterations is None or iteration < max_iterations):
        iteration += 1
        
        # ä»æ ˆä¸­å–å‡ºä¸€ä¸ªæ‰¹æ¬¡è¿›è¡Œå¤„ç†
        current_batch = processing_stack.pop()
        
        print(f"\n--- è¿­ä»£ {iteration} ---")
        print(f"  å½“å‰æ‰¹æ¬¡: {len(current_batch)} ä¸ªè´¦æˆ·")
        print(f"  å¾…å¤„ç†æ ˆ: {len(processing_stack)} ä¸ªæ‰¹æ¬¡")
        
        # å¦‚æœåªæœ‰1ä¸ªè´¦æˆ·ï¼ŒåŸºäºæ¦‚ç‡å†³å®š
        if len(current_batch) == 1:
            account_id = current_batch[0]
            # ç®€å•ç­–ç•¥ï¼šä¿æŒå½“å‰é¢„æµ‹
            account_status[account_id] = optimized_predictions[account_id]
            continue
        
        # é€‰æ‹©æµ‹è¯•æ‰¹æ¬¡ï¼ˆå½“å‰æ‰¹æ¬¡çš„ä¸€åŠï¼‰
        batch_size = len(current_batch) // 2
        test_batch = current_batch[:batch_size]
        remaining_batch = current_batch[batch_size:]
        
        # ç»Ÿè®¡å½“å‰ç¡®è®¤çŠ¶æ€å’Œæ€»ä½“åˆ†å¸ƒ
        confirmed_good = sum(1 for aid in account_status if account_status[aid] == 0)
        confirmed_bad = sum(1 for aid in account_status if account_status[aid] == 1)
        unconfirmed = sum(1 for aid in account_status if account_status[aid] == -1)
        
        # å½“å‰é¢„æµ‹åˆ†å¸ƒ
        current_good = sum(1 for pred in optimized_predictions.values() if pred == 0)
        current_bad = sum(1 for pred in optimized_predictions.values() if pred == 1)
        
        print(f"                good     bad")
        print(f"æ€»å…±æ•°é‡ï¼š      {total_good}      {total_bad}")
        print(f"å·²ç»ç¡®è®¤ï¼š      {confirmed_good}        {confirmed_bad}")  
        print(f"ç­‰å¾…ç¡®è®¤ï¼š      {unconfirmed}")
        print(f"æœ¬æ¬¡çŒœæµ‹ï¼š      {current_good}      {current_bad}")
        
        # è·å–å½“å‰F1
        current_f1 = test_current_predictions(optimized_predictions, upload_func)
        if current_f1 is None:
            print("âŒ æ— æ³•è·å–F1ï¼Œåœæ­¢")
            break
        
        # ä»F1åæ¨æ··æ·†çŸ©é˜µ
        confusion = calculate_confusion_from_f1(current_f1, current_bad)
        if confusion:
            tp, fp, fn, tn = confusion['TP'], confusion['FP'], confusion['FN'], confusion['TN']
            print(f"æ­£ç¡®çŒœæµ‹ï¼š      {tn}      {tp}")
            print(f"é”™è¯¯çŒœæµ‹ï¼š      {fp}        {fn}")
        
        print(f"  å½“å‰F1: {current_f1:.6f}")
        
        # æµ‹è¯•ç¿»è½¬æ•ˆæœ
        decision = test_batch_flip_with_confusion(test_batch, optimized_predictions, upload_func, 
                                                current_f1, confusion, total_good, total_bad)
        
        # ä¿å­˜ç»Ÿè®¡æ•°æ®
        iteration_stats = {
            'iteration': iteration,
            'current_batch_size': len(current_batch),
            'test_batch_size': len(test_batch),
            'remaining_batch_size': len(remaining_batch),
            'current_f1': current_f1,
            'decision': decision,
            'confirmed_accounts': confirmed_good + confirmed_bad,
            'unconfirmed_accounts': unconfirmed
        }
        iteration_stats_list.append(iteration_stats)
        
        if decision == "flip_all":
            # ç¿»è½¬æ‰€æœ‰æµ‹è¯•è´¦æˆ·å¹¶ç¡®è®¤
            for account_id in test_batch:
                optimized_predictions[account_id] = 1 - optimized_predictions[account_id]
                # ç¡®è®¤çŠ¶æ€ï¼šç¿»è½¬åçš„å€¼
                account_status[account_id] = optimized_predictions[account_id]
                
            print(f"âœ… ç¿»è½¬å¹¶ç¡®è®¤å…¨éƒ¨ {len(test_batch)} ä¸ªè´¦æˆ·")
            
            # å°†å‰©ä½™æ‰¹æ¬¡åŠ å…¥æ ˆç»§ç»­å¤„ç†
            if remaining_batch:
                processing_stack.append(remaining_batch)
                print(f"  ğŸ“‹ å‰©ä½™ {len(remaining_batch)} ä¸ªè´¦æˆ·åŠ å…¥å¤„ç†æ ˆ")
            
        elif decision == "keep_all":
            # ä¿æŒæ‰€æœ‰æµ‹è¯•è´¦æˆ·ä¸å˜å¹¶ç¡®è®¤
            for account_id in test_batch:
                # ç¡®è®¤çŠ¶æ€ï¼šå½“å‰å€¼
                account_status[account_id] = optimized_predictions[account_id]
                
            print(f"âœ… ä¿æŒå¹¶ç¡®è®¤å…¨éƒ¨ {len(test_batch)} ä¸ªè´¦æˆ·")
            
            # å°†å‰©ä½™æ‰¹æ¬¡åŠ å…¥æ ˆç»§ç»­å¤„ç†
            if remaining_batch:
                processing_stack.append(remaining_batch)
                print(f"  ğŸ“‹ å‰©ä½™ {len(remaining_batch)} ä¸ªè´¦æˆ·åŠ å…¥å¤„ç†æ ˆ")
            
        else:  # "continue_binary"
            # ç»§ç»­äºŒåˆ†ï¼šå°†ä¸¤ä¸ªå­æ‰¹æ¬¡éƒ½åŠ å…¥æ ˆ
            processing_stack.append(test_batch)
            if remaining_batch:
                processing_stack.append(remaining_batch)
            print(f"  ğŸ”„ ç»§ç»­äºŒåˆ†ï¼Œ{len(test_batch)} å’Œ {len(remaining_batch)} ä¸ªè´¦æˆ·åˆ†åˆ«åŠ å…¥å¤„ç†æ ˆ")
    
        # æ˜¾ç¤ºè¿›åº¦
        confirmed_count = sum(1 for status in account_status.values() if status != -1)
        print(f"  ğŸ“ˆ è¿­ä»£{iteration}: ç¡®è®¤ {confirmed_count}/{len(account_list)}")
    
    print(f"\n=== äºŒåˆ†æ³•ä¼˜åŒ–å®Œæˆ ===")
    print(f"æ€»è¿­ä»£æ¬¡æ•°: {iteration}")
    print(f"å·²ç¡®è®¤è´¦æˆ·: {sum(1 for status in account_status.values() if status != -1)}")
    print(f"å‰©ä½™æœªå¤„ç†æ‰¹æ¬¡: {len(processing_stack)}")
    if processing_stack:
        remaining_accounts = sum(len(batch) for batch in processing_stack)
        print(f"å‰©ä½™æœªç¡®è®¤è´¦æˆ·: {remaining_accounts}")
    else:
        print(f"âœ… æ‰€æœ‰è´¦æˆ·å·²ç¡®è®¤")
    
    # ä¿å­˜ç»Ÿè®¡æ•°æ®åˆ°JSONæ–‡ä»¶
    if iteration_stats_list:
        import json
        stats_file = "/Users/mannormal/4011/Qi Zihan/v3/binary_search_stats.json"
        try:
            with open(stats_file, 'w') as f:
                json.dump({
                    'total_iterations': iteration,
                    'total_accounts': len(account_list),
                    'confirmed_accounts': sum(1 for status in account_status.values() if status != -1),
                    'iteration_details': iteration_stats_list
                }, f, indent=2)
            print(f"ğŸ“Š ç»Ÿè®¡æ•°æ®å·²ä¿å­˜åˆ°: {stats_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
    
    return optimized_predictions, account_status

def test_current_predictions(predictions, upload_func):
    """
    æµ‹è¯•å½“å‰é¢„æµ‹çš„F1åˆ†æ•°
    
    Args:
        predictions (dict): å½“å‰é¢„æµ‹ {account_id: 0/1}
        upload_func (function): ä¸Šä¼ å‡½æ•°
    
    Returns:
        float: F1åˆ†æ•°ï¼Œå¤±è´¥è¿”å›None
    """
    
    # åˆ›å»ºä¸´æ—¶CSVæ–‡ä»¶
    temp_file = "/Users/mannormal/4011/Qi Zihan/v3/temp_test.csv"
    
    predictions_list = []
    for account_id, predict in predictions.items():
        predictions_list.append({"ID": account_id, "Predict": predict})
    
    df = pd.DataFrame(predictions_list)
    df.to_csv(temp_file, index=False)
    
    # ä¸Šä¼ æµ‹è¯•
    f1_score = upload_func(temp_file)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    import os
    if os.path.exists(temp_file):
        os.remove(temp_file)
    
    return f1_score

def test_batch_flip_with_confusion(test_batch, current_predictions, upload_func, baseline_f1, 
                                  baseline_confusion, total_good, total_bad):
    """
    åŸºäºæ··æ·†çŸ©é˜µæ¨æ–­æµ‹è¯•æ‰¹æ¬¡ï¼Œå†³å®šæ˜¯å¦ç»§ç»­äºŒåˆ†
    
    Args:
        test_batch (list): æµ‹è¯•è´¦æˆ·åˆ—è¡¨
        current_predictions (dict): å½“å‰é¢„æµ‹
        upload_func (function): ä¸Šä¼ å‡½æ•°
        baseline_f1 (float): åŸºå‡†F1åˆ†æ•°
        baseline_confusion (dict): åŸºå‡†æ··æ·†çŸ©é˜µ
        total_good (int): æ€»çœŸå®goodæ•°é‡
        total_bad (int): æ€»çœŸå®badæ•°é‡
    
    Returns:
        str: "flip_all", "keep_all", æˆ– "continue_binary"
    """
    
    # æµ‹è¯•ç¿»è½¬æ•ˆæœ
    flipped_predictions = current_predictions.copy()
    for account_id in test_batch:
        flipped_predictions[account_id] = 1 - flipped_predictions[account_id]
    
    # è·å–ç¿»è½¬åçš„F1åˆ†æ•°
    flipped_f1 = test_current_predictions(flipped_predictions, upload_func)
    if flipped_f1 is None:
        print("  âŒ æ— æ³•è·å–ç¿»è½¬åF1åˆ†æ•°ï¼Œç»§ç»­äºŒåˆ†")
        return "continue_binary"
    
    # è®¡ç®—ç¿»è½¬åçš„æ··æ·†çŸ©é˜µ
    from confusion_calculator import calculate_confusion_from_f1
    flipped_bad_count = sum(1 for pred in flipped_predictions.values() if pred == 1)
    flipped_confusion = calculate_confusion_from_f1(flipped_f1, flipped_bad_count)
    
    if not flipped_confusion:
        print("  âŒ æ— æ³•è®¡ç®—ç¿»è½¬åæ··æ·†çŸ©é˜µï¼Œç»§ç»­äºŒåˆ†")
        return "continue_binary"
    
    print(f"  ğŸ“Š æ‰¹æ¬¡ç¿»è½¬æµ‹è¯• ({len(test_batch)}ä¸ªè´¦æˆ·):")
    print(f"      å½“å‰F1: {baseline_f1:.6f}")
    print(f"      ç¿»è½¬F1: {flipped_f1:.6f}")
    print(f"      F1æ”¹è¿›: {flipped_f1 - baseline_f1:.6f}")
    
    # ä½¿ç”¨analyze_binary_splitåˆ†æç»“æœ
    a_status, b_status, block_stats = analyze_binary_split(
        baseline_confusion, flipped_confusion, len(test_batch), 
        total_good, total_bad, current_predictions, test_batch
    )
    
    print(f"      æ¨æ–­çŠ¶æ€: block_a={a_status}, block_b={b_status}")
    print(f"      ç»Ÿè®¡: æ­£ç¡®={block_stats['correct']}, é”™è¯¯={block_stats['wrong']}")
    
    # å†³ç­–é€»è¾‘
    if flipped_f1 > baseline_f1 + 0.001:  # æ˜¾è‘—æ”¹è¿›
        if b_status == "ALL_GOOD" or b_status == "ALL_BAD":
            print(f"  âœ… F1æ˜¾è‘—æ”¹è¿›ä¸”çŠ¶æ€çº¯å‡€({b_status})ï¼Œç¿»è½¬å¹¶ç¡®è®¤")
            return "flip_all"
        else:
            print(f"  ğŸ”„ F1æ”¹è¿›ä½†çŠ¶æ€æ··åˆ({b_status})ï¼Œç»§ç»­äºŒåˆ†")
            return "continue_binary"
    elif abs(flipped_f1 - baseline_f1) < 0.001:  # åŸºæœ¬æ— å˜åŒ–
        if b_status == "ALL_GOOD" or b_status == "ALL_BAD":
            print(f"  âœ… F1æ— å˜åŒ–ä¸”çŠ¶æ€çº¯å‡€({b_status})ï¼Œä¿æŒå¹¶ç¡®è®¤")
            return "keep_all"
        else:
            print(f"  ğŸ”„ F1æ— å˜åŒ–ä½†çŠ¶æ€æ··åˆ({b_status})ï¼Œç»§ç»­äºŒåˆ†")
            return "continue_binary"
    else:  # F1ä¸‹é™
        print(f"  ğŸ”„ F1ä¸‹é™ï¼Œç»§ç»­äºŒåˆ†å¯»æ‰¾æœ€ä¼˜åˆ†å‰²")
        return "continue_binary"


def test_batch_flip(test_batch, current_predictions, upload_func, baseline_f1):
    """
    ç®€åŒ–ç‰ˆæœ¬çš„æ‰¹æ¬¡æµ‹è¯•ï¼ˆå‘åå…¼å®¹ï¼‰
    """
    print(f"  âš ï¸  ä½¿ç”¨ç®€åŒ–æµ‹è¯•æ¨¡å¼ï¼Œå»ºè®®ä½¿ç”¨test_batch_flip_with_confusion")
    
    # ç®€å•ç­–ç•¥ï¼šå¦‚æœæ‰¹æ¬¡è¾ƒå°ï¼Œç»§ç»­äºŒåˆ†ï¼›å¦‚æœè¾ƒå¤§ï¼Œéšæœºå†³ç­–
    if len(test_batch) <= 2:
        return "continue_binary"
    elif len(test_batch) >= 20:
        # å¯¹äºå¤§æ‰¹æ¬¡ï¼Œæµ‹è¯•ç¿»è½¬æ•ˆæœ
        flipped_predictions = current_predictions.copy()
        for account_id in test_batch:
            flipped_predictions[account_id] = 1 - flipped_predictions[account_id]
        
        flipped_f1 = test_current_predictions(flipped_predictions, upload_func)
        if flipped_f1 and flipped_f1 > baseline_f1:
            return "flip_all"
        else:
            return "keep_all"
    else:
        return "continue_binary"


def optimize_single_account(account_id, current_predictions, upload_func):
    """
    ä¼˜åŒ–å•ä¸ªè´¦æˆ· - åŸºäºF1åˆ†æ•°å˜åŒ–
    
    Args:
        account_id (str): è´¦æˆ·ID
        current_predictions (dict): å½“å‰é¢„æµ‹
        upload_func (function): ä¸Šä¼ å‡½æ•°
    
    Returns:
        int: æœ€ä¼˜é¢„æµ‹å€¼ (0 æˆ– 1)
    """
    
    print(f"ä¼˜åŒ–å•ä¸ªè´¦æˆ·: {account_id}")
    
    current_pred = current_predictions[account_id]
    
    # æµ‹è¯•ç¿»è½¬æ•ˆæœ
    test_predictions = current_predictions.copy()
    test_predictions[account_id] = 1 - current_pred
    
    current_f1 = test_current_predictions(current_predictions, upload_func)
    flipped_f1 = test_current_predictions(test_predictions, upload_func)
    
    if current_f1 is None or flipped_f1 is None:
        print(f"âŒ æ— æ³•è·å–F1åˆ†æ•°ï¼Œä¿æŒåŸå€¼")
        return current_pred
    
    print(f"å½“å‰é¢„æµ‹ {current_pred}: F1 = {current_f1:.6f}")
    print(f"ç¿»è½¬é¢„æµ‹ {1-current_pred}: F1 = {flipped_f1:.6f}")
    
    # é€‰æ‹©F1æ›´é«˜çš„é¢„æµ‹å€¼
    if flipped_f1 > current_f1:
        print(f"âœ… é€‰æ‹©ç¿»è½¬å€¼: {1-current_pred}")
        return 1 - current_pred
    else:
        print(f"âœ… ä¿æŒåŸå€¼: {current_pred}")
        return current_pred

def select_accounts_for_optimization(scores_df, selection_strategy="high_uncertainty", top_n=50):
    """
    é€‰æ‹©éœ€è¦ä¼˜åŒ–çš„è´¦æˆ·
    
    Args:
        scores_df (pd.DataFrame): è´¦æˆ·åˆ†æ•°DataFrame
        selection_strategy (str): é€‰æ‹©ç­–ç•¥
        top_n (int): é€‰æ‹©çš„è´¦æˆ·æ•°é‡
    
    Returns:
        list: é€‰æ‹©çš„è´¦æˆ·IDåˆ—è¡¨
    """
    
    if selection_strategy == "high_uncertainty":
        # é€‰æ‹©åˆ†æ•°æ¥è¿‘0.5çš„è´¦æˆ·ï¼ˆä¸ç¡®å®šæ€§æœ€é«˜ï¼‰
        scores_df['uncertainty'] = abs(scores_df['predict'] - 0.5)
        selected = scores_df.nsmallest(top_n, 'uncertainty')
        
    elif selection_strategy == "high_score":
        # é€‰æ‹©åˆ†æ•°æœ€é«˜çš„è´¦æˆ·
        selected = scores_df.nlargest(top_n, 'predict')
        
    elif selection_strategy == "random":
        # éšæœºé€‰æ‹©
        selected = scores_df.sample(n=min(top_n, len(scores_df)))
        
    else:
        print(f"âŒ æœªçŸ¥é€‰æ‹©ç­–ç•¥: {selection_strategy}")
        return []
    
    selected_ids = selected['ID'].tolist()
    print(f"é€‰æ‹©ç­–ç•¥ '{selection_strategy}': {len(selected_ids)} ä¸ªè´¦æˆ·")
    
    return selected_ids
