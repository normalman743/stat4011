#!/usr/bin/env python3
"""
ğŸ” é¢„æµ‹ä¸€è‡´æ€§æ·±åº¦åˆ†æå™¨
åˆ†æé«˜è´¨é‡æ¨¡å‹çš„é¢„æµ‹ä¸€è‡´æ€§ï¼Œæ‰¾å‡ºï¼š
1. 100%ä¸€è‡´çš„è´¦æˆ·ï¼ˆæ‰€æœ‰æ¨¡å‹éƒ½åŒæ„ï¼‰
2. é«˜åº¦åˆ†æ­§çš„è´¦æˆ·ï¼ˆæ¨¡å‹æ„è§ä¸ç»Ÿä¸€ï¼‰
3. å…³é”®åˆ†æ­§ç‚¹çš„è¯¦ç»†åˆ†æ
4. æä¾›ç²¾å‡†ä¿®æ”¹å»ºè®®
"""
import pandas as pd
import numpy as np
from pathlib import Path
from collections import Counter, defaultdict
import json

def load_top_quality_predictions():
    """åŠ è½½æœ€é«˜è´¨é‡çš„é¢„æµ‹æ–‡ä»¶"""
    high_score_dir = Path("/Users/mannormal/4011/Qi Zihan/v2/results/high_score_predictions")
    
    # é€‰æ‹©å·²éªŒè¯çš„é¡¶çº§æ¨¡å‹ï¼ˆREAL F1 > 0.74ï¼‰
    top_models = {
        # å•æ¨¡å‹é¡¶çº§
        'v3.2refined_fold1_REAL_F1_0.7549378200438918.csv': {
            'score': 0.7549, 'type': 'Single_V3.2', 'seed': 13
        },
        'v3.2refined_fold4_REAL_F1_0.7525325615050651_REAL_F1_0.7525325615050651.csv': {
            'score': 0.7525, 'type': 'Single_V3.2', 'seed': 13
        },
        
        # èåˆæˆåŠŸæ¡ˆä¾‹  
        'AGGRESSIVE_AGGRESSIVE_VOTING_REAL_F1_0.7521489971346705.csv': {
            'score': 0.7521, 'type': 'Fusion_Aggressive', 'method': 'voting'
        },
        'FUSION_WEIGHTED_090_REAL_F1_0.7446102819237148.csv': {
            'score': 0.7446, 'type': 'Fusion_Conservative', 'method': 'weighted'
        },
        'AGGRESSIVE_DISTRIBUTION_MATCHING_REAL_F1_0.7435897435897436.csv': {
            'score': 0.7436, 'type': 'Fusion_Distribution', 'method': 'matching'
        },
        'AGGRESSIVE_TOP_MODEL_AGGRESSIVE_REAL_F1_0.7421052631578947.csv': {
            'score': 0.7421, 'type': 'Fusion_TopModel', 'method': 'aggressive'
        },
    }
    
    predictions = {}
    model_info = {}
    
    print("ğŸ” åŠ è½½é¡¶çº§è´¨é‡é¢„æµ‹æ–‡ä»¶ï¼ˆREAL F1 > 0.74ï¼‰...")
    
    loaded_count = 0
    for filename, info in top_models.items():
        filepath = high_score_dir / filename
        if filepath.exists():
            try:
                df = pd.read_csv(filepath)
                if 'ID' in df.columns and 'Predict' in df.columns:
                    model_key = f"M{loaded_count+1}_{info['type']}"
                    predictions[model_key] = dict(zip(df['ID'], df['Predict']))
                    model_info[model_key] = {
                        'filename': filename,
                        'score': info['score'],
                        'bad_rate': df['Predict'].mean(),
                        'total_predictions': len(df),
                        **info
                    }
                    loaded_count += 1
                    print(f"âœ… {model_key:<20} | Score: {info['score']:.4f} | Badç‡: {df['Predict'].mean():.3f} | {info['type']}")
            except Exception as e:
                print(f"âŒ {filename}: {e}")
    
    print(f"ğŸ“Š æˆåŠŸåŠ è½½ {len(predictions)} ä¸ªé¡¶çº§æ¨¡å‹")
    return predictions, model_info

def analyze_consensus_patterns(predictions, model_info):
    """åˆ†æé¢„æµ‹ä¸€è‡´æ€§æ¨¡å¼"""
    print("\nğŸ¯ æ·±åº¦åˆ†æé¢„æµ‹ä¸€è‡´æ€§æ¨¡å¼...")
    
    # è·å–æ‰€æœ‰è´¦æˆ·ID
    all_ids = set()
    for pred_dict in predictions.values():
        all_ids.update(pred_dict.keys())
    all_ids = sorted(all_ids)
    
    model_names = list(predictions.keys())
    n_models = len(model_names)
    
    print(f"ğŸ“Š åˆ†æèŒƒå›´: {len(all_ids)} ä¸ªè´¦æˆ· Ã— {n_models} ä¸ªé¡¶çº§æ¨¡å‹")
    
    # ä¸ºæ¯ä¸ªè´¦æˆ·åˆ†æé¢„æµ‹æ¨¡å¼
    account_analysis = []
    consensus_stats = {
        'unanimous_good': [],      # æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹Good (100%ä¸€è‡´)
        'unanimous_bad': [],       # æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹Bad (100%ä¸€è‡´)
        'near_unanimous_good': [], # å‡ ä¹ä¸€è‡´Good (1ä¸ªæ¨¡å‹åˆ†æ­§)
        'near_unanimous_bad': [],  # å‡ ä¹ä¸€è‡´Bad (1ä¸ªæ¨¡å‹åˆ†æ­§)
        'split_decisions': [],     # ä¸¥é‡åˆ†æ­§ (2-4ä¸ªæ¨¡å‹åˆ†æ­§)
        'disputed': []             # é«˜åº¦äº‰è®® (æ¥è¿‘50-50åˆ†å‰²)
    }
    
    for account_id in all_ids:
        # æ”¶é›†æ‰€æœ‰æ¨¡å‹å¯¹æ­¤è´¦æˆ·çš„é¢„æµ‹
        account_votes = []
        missing_predictions = []
        
        for model in model_names:
            if account_id in predictions[model]:
                account_votes.append(predictions[model][account_id])
            else:
                missing_predictions.append(model)
        
        if not account_votes:  # å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½æ²¡æœ‰æ­¤è´¦æˆ·çš„é¢„æµ‹
            continue
            
        # ç»Ÿè®¡æŠ•ç¥¨ç»“æœ
        positive_votes = sum(account_votes)  # Badçš„ç¥¨æ•°
        total_votes = len(account_votes)
        negative_votes = total_votes - positive_votes  # Goodçš„ç¥¨æ•°
        
        # è®¡ç®—ä¸€è‡´æ€§
        consensus_ratio = max(positive_votes, negative_votes) / total_votes
        
        # åˆ›å»ºæŠ•ç¥¨æ¨¡å¼å­—ç¬¦ä¸²
        vote_pattern = ''.join(str(v) for v in account_votes)
        
        account_data = {
            'account_id': account_id,
            'positive_votes': positive_votes,
            'negative_votes': negative_votes,
            'total_votes': total_votes,
            'consensus_ratio': consensus_ratio,
            'vote_pattern': vote_pattern,
            'missing_models': missing_predictions,
            'final_prediction': 1 if positive_votes > negative_votes else 0,
            'confidence': consensus_ratio
        }
        
        account_analysis.append(account_data)
        
        # åˆ†ç±»è´¦æˆ·
        if positive_votes == 0:  # æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹Good
            consensus_stats['unanimous_good'].append(account_data)
        elif positive_votes == total_votes:  # æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹Bad
            consensus_stats['unanimous_bad'].append(account_data)
        elif positive_votes == 1 or negative_votes == 1:  # åªæœ‰1ä¸ªæ¨¡å‹ä¸åŒæ„
            if positive_votes == 1:
                consensus_stats['near_unanimous_good'].append(account_data)
            else:
                consensus_stats['near_unanimous_bad'].append(account_data)
        elif abs(positive_votes - negative_votes) <= 1:  # æ¥è¿‘å¹³åˆ†
            consensus_stats['disputed'].append(account_data)
        else:  # å…¶ä»–åˆ†æ­§æƒ…å†µ
            consensus_stats['split_decisions'].append(account_data)
    
    return account_analysis, consensus_stats, model_names

def detailed_consensus_analysis(consensus_stats, model_names, model_info):
    """è¯¦ç»†çš„ä¸€è‡´æ€§åˆ†æ"""
    print("\nğŸ“ˆ è¯¦ç»†ä¸€è‡´æ€§åˆ†ææŠ¥å‘Š:")
    print("=" * 80)
    
    total_accounts = sum(len(group) for group in consensus_stats.values())
    
    # ç»Ÿè®¡å„ç±»åˆ«
    categories = [
        ('unanimous_good', '100%ä¸€è‡´é¢„æµ‹Good', 'ğŸŸ¢'),
        ('unanimous_bad', '100%ä¸€è‡´é¢„æµ‹Bad', 'ğŸ”´'), 
        ('near_unanimous_good', 'è¿‘ä¹ä¸€è‡´Good(1ç¥¨åˆ†æ­§)', 'ğŸŸ¡'),
        ('near_unanimous_bad', 'è¿‘ä¹ä¸€è‡´Bad(1ç¥¨åˆ†æ­§)', 'ğŸŸ '),
        ('split_decisions', 'æ˜æ˜¾åˆ†æ­§(2-3ç¥¨åˆ†æ­§)', 'ğŸ”µ'),
        ('disputed', 'é«˜åº¦äº‰è®®(æ¥è¿‘å¹³åˆ†)', 'ğŸŸ£')
    ]
    
    for cat_key, cat_name, emoji in categories:
        count = len(consensus_stats[cat_key])
        percentage = count / total_accounts * 100 if total_accounts > 0 else 0
        print(f"{emoji} {cat_name:<25} | {count:4d} ä¸ªè´¦æˆ· ({percentage:5.1f}%)")
    
    print(f"\nğŸ“Š æ€»è®¡: {total_accounts} ä¸ªè´¦æˆ·")
    
    # åˆ†æ100%ä¸€è‡´çš„æƒ…å†µ
    print(f"\nğŸ¯ 100%ä¸€è‡´æ€§åˆ†æ:")
    unanimous_good = len(consensus_stats['unanimous_good'])
    unanimous_bad = len(consensus_stats['unanimous_bad'])
    total_unanimous = unanimous_good + unanimous_bad
    
    print(f"   ğŸŸ¢ 100%ä¸€è‡´Good: {unanimous_good:4d} ä¸ª ({unanimous_good/total_accounts*100:5.1f}%)")
    print(f"   ğŸ”´ 100%ä¸€è‡´Bad:  {unanimous_bad:4d} ä¸ª ({unanimous_bad/total_accounts*100:5.1f}%)")
    print(f"   âœ… æ€»ä¸€è‡´ç‡:     {total_unanimous:4d} ä¸ª ({total_unanimous/total_accounts*100:5.1f}%)")
    
    return total_accounts, total_unanimous

def analyze_disagreement_patterns(consensus_stats, model_names, model_info):
    """åˆ†æåˆ†æ­§æ¨¡å¼"""
    print(f"\nğŸ” åˆ†æ­§æ¨¡å¼æ·±åº¦åˆ†æ:")
    print("=" * 80)
    
    # åˆ†æå“ªäº›æ¨¡å‹æœ€å®¹æ˜“äº§ç”Ÿåˆ†æ­§
    disagreement_matrix = defaultdict(int)
    
    # ç»Ÿè®¡åˆ†æ­§è´¦æˆ·çš„æŠ•ç¥¨æ¨¡å¼
    disagreement_accounts = []
    disagreement_accounts.extend(consensus_stats['near_unanimous_good'])
    disagreement_accounts.extend(consensus_stats['near_unanimous_bad']) 
    disagreement_accounts.extend(consensus_stats['split_decisions'])
    disagreement_accounts.extend(consensus_stats['disputed'])
    
    print(f"ğŸ“Š åˆ†æ­§è´¦æˆ·æ€»æ•°: {len(disagreement_accounts)}")
    
    # åˆ†ææŠ•ç¥¨æ¨¡å¼é¢‘ç‡
    pattern_frequency = Counter()
    for account in disagreement_accounts:
        pattern_frequency[account['vote_pattern']] += 1
    
    print(f"\nğŸ­ æœ€å¸¸è§çš„åˆ†æ­§æ¨¡å¼ (å‰10):")
    print("   æ¨¡å¼    | é¢‘æ¬¡ | å«ä¹‰")
    print("   -------|------|----------------------------------")
    
    for pattern, count in pattern_frequency.most_common(10):
        bad_votes = sum(int(x) for x in pattern)
        total_votes = len(pattern)
        good_votes = total_votes - bad_votes
        meaning = f"{good_votes}ä¸ªGoodç¥¨, {bad_votes}ä¸ªBadç¥¨"
        print(f"   {pattern:<7} | {count:4d} | {meaning}")
    
    return disagreement_accounts, pattern_frequency

def generate_modification_recommendations(consensus_stats, disagreement_accounts, pattern_frequency, model_info):
    """ç”Ÿæˆä¿®æ”¹å»ºè®®"""
    print(f"\nğŸ’¡ ç²¾å‡†ä¿®æ”¹å»ºè®®:")
    print("=" * 80)
    
    recommendations = []
    
    # å»ºè®®1: åŸºäº100%ä¸€è‡´æ€§
    unanimous_good = len(consensus_stats['unanimous_good'])  
    unanimous_bad = len(consensus_stats['unanimous_bad'])
    
    rec1 = {
        'strategy': 'CONSENSUS_100',
        'description': 'åŸºäº100%ä¸€è‡´æ€§é¢„æµ‹',
        'logic': 'æ‰€æœ‰é¡¶çº§æ¨¡å‹ä¸€è‡´çš„è´¦æˆ·ç›´æ¥é‡‡çº³',
        'expected_changes': f"ç¡®å®šé¢„æµ‹ {unanimous_good + unanimous_bad} ä¸ªè´¦æˆ·",
        'confidence': 'æé«˜'
    }
    recommendations.append(rec1)
    
    # å»ºè®®2: å¤„ç†è¿‘ä¹ä¸€è‡´çš„æƒ…å†µ 
    near_unanimous = len(consensus_stats['near_unanimous_good']) + len(consensus_stats['near_unanimous_bad'])
    
    rec2 = {
        'strategy': 'CONSENSUS_83',  # 5ä¸ªæ¨¡å‹ä¸­4ä¸ªä¸€è‡´ = 83%
        'description': 'å¤„ç†83%ä¸€è‡´æ€§è´¦æˆ·',
        'logic': 'åªæœ‰1ä¸ªæ¨¡å‹åˆ†æ­§æ—¶ï¼Œè·Ÿéšå¤šæ•°',
        'expected_changes': f"é¢å¤–ç¡®å®š {near_unanimous} ä¸ªè´¦æˆ·",
        'confidence': 'é«˜'
    }
    recommendations.append(rec2)
    
    # å»ºè®®3: åŸºäºæœ€å¸¸è§åˆ†æ­§æ¨¡å¼çš„ä¼˜åŒ–
    if pattern_frequency:
        most_common_pattern = pattern_frequency.most_common(1)[0]
        pattern, freq = most_common_pattern
        
        rec3 = {
            'strategy': 'PATTERN_OPTIMIZATION',
            'description': f'ä¼˜åŒ–æœ€å¸¸è§åˆ†æ­§æ¨¡å¼ {pattern}',
            'logic': f'å¯¹æ¨¡å¼{pattern}çš„{freq}ä¸ªè´¦æˆ·ä½¿ç”¨ç‰¹æ®Šè§„åˆ™',
            'expected_changes': f"ä¼˜åŒ– {freq} ä¸ªäº‰è®®è´¦æˆ·",
            'confidence': 'ä¸­ç­‰'
        }
        recommendations.append(rec3)
    
    # å»ºè®®4: ä¿å®ˆ vs æ¿€è¿›ç­–ç•¥
    disputed_count = len(consensus_stats['disputed'])
    
    rec4 = {
        'strategy': 'DISPUTE_RESOLUTION',
        'description': 'äº‰è®®è´¦æˆ·è§£å†³æ–¹æ¡ˆ',
        'logic': f'{disputed_count}ä¸ªé«˜äº‰è®®è´¦æˆ·ä½¿ç”¨æœ€é«˜åˆ†æ¨¡å‹å†³å®š',
        'expected_changes': f"è§£å†³ {disputed_count} ä¸ªäº‰è®®æ¡ˆä¾‹", 
        'confidence': 'ä¸­ç­‰'
    }
    recommendations.append(rec4)
    
    print("ğŸ¯ æ¨èçš„ä¿®æ”¹ç­–ç•¥:")
    for i, rec in enumerate(recommendations, 1):
        print(f"\n{i}. {rec['strategy']}")
        print(f"   æè¿°: {rec['description']}")
        print(f"   é€»è¾‘: {rec['logic']}")
        print(f"   é¢„æœŸ: {rec['expected_changes']}")
        print(f"   ç½®ä¿¡åº¦: {rec['confidence']}")
    
    return recommendations

def implement_consensus_strategies(predictions, consensus_stats, model_info):
    """å®ç°åŸºäºä¸€è‡´æ€§åˆ†æçš„ç­–ç•¥"""
    print(f"\nğŸš€ å®ç°ä¸€è‡´æ€§ä¼˜åŒ–ç­–ç•¥...")
    
    all_ids = set()
    for pred_dict in predictions.values():
        all_ids.update(pred_dict.keys())
    all_ids = sorted(all_ids)
    
    strategies = {}
    
    # ç­–ç•¥1: 100%ä¸€è‡´æ€§ + 83%ä¸€è‡´æ€§
    consensus_pred = {}
    
    # 100%ä¸€è‡´çš„ç›´æ¥é‡‡çº³
    for account in consensus_stats['unanimous_good']:
        consensus_pred[account['account_id']] = 0
    
    for account in consensus_stats['unanimous_bad']:
        consensus_pred[account['account_id']] = 1
    
    # 83%ä¸€è‡´çš„è·Ÿéšå¤šæ•°
    for account in consensus_stats['near_unanimous_good']:
        consensus_pred[account['account_id']] = 0
        
    for account in consensus_stats['near_unanimous_bad']:
        consensus_pred[account['account_id']] = 1
    
    # å…¶ä»–è´¦æˆ·ä½¿ç”¨æœ€é«˜åˆ†æ¨¡å‹
    highest_score_model = max(model_info.items(), key=lambda x: x[1]['score'])[0]
    
    for account_id in all_ids:
        if account_id not in consensus_pred:
            if account_id in predictions[highest_score_model]:
                consensus_pred[account_id] = predictions[highest_score_model][account_id]
            else:
                consensus_pred[account_id] = 0  # é»˜è®¤Good
    
    strategies['CONSENSUS_OPTIMIZED'] = consensus_pred
    
    # ç­–ç•¥2: å®Œå…¨ä¸€è‡´æ€§ï¼ˆåªæœ‰100%ä¸€è‡´æ‰å†³å®šï¼‰
    strict_consensus_pred = {}
    
    for account in consensus_stats['unanimous_good']:
        strict_consensus_pred[account['account_id']] = 0
    
    for account in consensus_stats['unanimous_bad']:
        strict_consensus_pred[account['account_id']] = 1
        
    # å…¶ä»–æ‰€æœ‰äº‰è®®è´¦æˆ·éƒ½é¢„æµ‹ä¸ºGoodï¼ˆä¿å®ˆï¼‰
    for account_id in all_ids:
        if account_id not in strict_consensus_pred:
            strict_consensus_pred[account_id] = 0
    
    strategies['STRICT_CONSENSUS'] = strict_consensus_pred
    
    # æ‰“å°ç»Ÿè®¡
    print(f"\nğŸ“Š ä¸€è‡´æ€§ç­–ç•¥ç»“æœ:")
    for name, pred in strategies.items():
        counts = Counter(pred.values())
        bad_rate = counts[1] / len(pred)
        print(f"   {name:<20} | Bad: {counts[1]:4d} ({bad_rate:6.1%}) | Good: {counts[0]:4d} ({1-bad_rate:6.1%})")
    
    return strategies

def save_consensus_analysis(consensus_stats, disagreement_accounts, recommendations, strategies):
    """ä¿å­˜ä¸€è‡´æ€§åˆ†æç»“æœ"""
    results_dir = Path("/Users/mannormal/4011/Qi Zihan/v2/results/high_score_predictions")
    
    print(f"\nğŸ’¾ ä¿å­˜ä¸€è‡´æ€§åˆ†æç»“æœ...")
    
    # ä¿å­˜ç­–ç•¥é¢„æµ‹æ–‡ä»¶
    for strategy_name, predictions in strategies.items():
        df = pd.DataFrame({
            'ID': sorted(predictions.keys()),
            'Predict': [predictions[id] for id in sorted(predictions.keys())]
        })
        
        filename = f"CONSENSUS_{strategy_name}.csv"
        filepath = results_dir / filename
        df.to_csv(filepath, index=False)
        
        pred_counts = Counter(df['Predict'])
        bad_rate = pred_counts[1] / len(df)
        print(f"âœ… {filename}")
        print(f"   Bad (1):  {pred_counts[1]:4d} ({bad_rate:6.1%})")
        print(f"   Good (0): {pred_counts[0]:4d} ({1-bad_rate:6.1%})")
    
    # ä¿å­˜è¯¦ç»†åˆ†ææŠ¥å‘Š
    report = {
        'analysis_summary': {
            'total_accounts': sum(len(group) for group in consensus_stats.values()),
            'unanimous_decisions': len(consensus_stats['unanimous_good']) + len(consensus_stats['unanimous_bad']),
            'disputed_accounts': len(disagreement_accounts)
        },
        'consensus_breakdown': {
            category: len(accounts) for category, accounts in consensus_stats.items()
        },
        'recommendations': recommendations,
        'generated_strategies': list(strategies.keys())
    }
    
    report_file = results_dir / "consensus_analysis_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“‹ åˆ†ææŠ¥å‘Š: consensus_analysis_report.json")

def main():
    print("ğŸ”ğŸ’ é¢„æµ‹ä¸€è‡´æ€§æ·±åº¦åˆ†æå™¨ ğŸ’ğŸ”")
    print("=" * 60)
    print("ğŸ¯ ç›®æ ‡: åˆ†æé¡¶çº§æ¨¡å‹çš„ä¸€è‡´æ€§ï¼Œæ‰¾å‡ºç²¾å‡†ä¿®æ”¹ç‚¹")
    
    # 1. åŠ è½½é¡¶çº§é¢„æµ‹
    predictions, model_info = load_top_quality_predictions()
    
    if len(predictions) < 3:
        print("âŒ é¡¶çº§é¢„æµ‹æ–‡ä»¶ä¸è¶³")
        return
    
    # 2. åˆ†æä¸€è‡´æ€§æ¨¡å¼
    account_analysis, consensus_stats, model_names = analyze_consensus_patterns(predictions, model_info)
    
    # 3. è¯¦ç»†åˆ†æ
    total_accounts, total_unanimous = detailed_consensus_analysis(consensus_stats, model_names, model_info)
    
    # 4. åˆ†æ­§æ¨¡å¼åˆ†æ
    disagreement_accounts, pattern_frequency = analyze_disagreement_patterns(consensus_stats, model_names, model_info)
    
    # 5. ç”Ÿæˆä¿®æ”¹å»ºè®®
    recommendations = generate_modification_recommendations(consensus_stats, disagreement_accounts, pattern_frequency, model_info)
    
    # 6. å®ç°ä¼˜åŒ–ç­–ç•¥
    strategies = implement_consensus_strategies(predictions, consensus_stats, model_info)
    
    # 7. ä¿å­˜ç»“æœ
    save_consensus_analysis(consensus_stats, disagreement_accounts, recommendations, strategies)
    
    print(f"\nğŸ‰ ä¸€è‡´æ€§åˆ†æå®Œæˆï¼")
    print(f"\nğŸ¯ å…³é”®å‘ç°:")
    print(f"   ğŸ“Š æ€»è´¦æˆ·æ•°: {total_accounts}")
    print(f"   âœ… å®Œå…¨ä¸€è‡´: {total_unanimous} ({total_unanimous/total_accounts*100:.1f}%)")
    print(f"   ğŸ¤” å­˜åœ¨åˆ†æ­§: {len(disagreement_accounts)} ({len(disagreement_accounts)/total_accounts*100:.1f}%)")
    
    print(f"\nğŸ’¡ æ¨èæäº¤ç­–ç•¥:")
    print(f"   1. CONSENSUS_CONSENSUS_OPTIMIZED.csv (å¹³è¡¡ä¸€è‡´æ€§å’Œæ€§èƒ½)")
    print(f"   2. CONSENSUS_STRICT_CONSENSUS.csv (æåº¦ä¿å®ˆï¼Œåªä¿¡ä»»100%ä¸€è‡´)")
    
    print(f"\nğŸš€ è¿™äº›ç­–ç•¥åŸºäºé¡¶çº§æ¨¡å‹çš„æ·±åº¦ä¸€è‡´æ€§åˆ†æï¼")

if __name__ == "__main__":
    main()