#!/usr/bin/env python3
"""
ğŸ¯ ç²¾å‡†å¾®è°ƒèåˆ - åŸºäºæˆåŠŸç»éªŒï¼Œåœ¨æœ€ä¼˜Badç‡åŒºé—´(8.5%-9.5%)å¯»æ‰¾æ›´é«˜åˆ†æ•°
ç›®æ ‡: çªç ´0.8åˆ†æ•°å¤§å…³
"""
import pandas as pd
import numpy as np
from pathlib import Path
from collections import Counter

def load_best_predictions():
    """åŠ è½½å·²éªŒè¯çš„æœ€ä½³é¢„æµ‹"""
    high_score_dir = Path("/Users/mannormal/4011/Qi Zihan/v2/results/high_score_predictions")
    
    # åŸºäºå®æµ‹ç»“æœï¼Œé€‰æ‹©æœ€ä¼˜æ–‡ä»¶
    best_files = {
        # å•æ¨¡å‹æœ€ä½³
        'v3.2refined_fold1_bad_f1_0.7778_good_0.9765_bad_0.7778_macro_0.8771_weighted_0.9570_seed_13_REAL_F1_0.7549378200438918.csv': 0.7549,
        'v3.2refined_fold4_bad_f1_0.8250_good_0.9814_bad_0.8250_macro_0.9032_weighted_0.9661_seed_13_REAL_F1_0.7525325615050651_REAL_F1_0.7525325615050651.csv': 0.7525,
        
        # èåˆæˆåŠŸæ¡ˆä¾‹
        'FUSION_WEIGHTED_090_REAL_F1_0.7446102819237148.csv': 0.7446,
        'AGGRESSIVE_AGGRESSIVE_VOTING_REAL_F1_0.7521489971346705.csv': 0.7521,
        'AGGRESSIVE_DISTRIBUTION_MATCHING_REAL_F1_0.7435897435897436.csv': 0.7436,
        
        # é«˜è´¨é‡åŸºç¡€æ¨¡å‹
        'best_rf_badf1_0691_ratio_0.731.csv': 0.731,
        'voting_rf_badf1_0669_ratio_0.736.csv': 0.736,
        'v2ultra_resnet_meta_ann_rank1_fold3_macro_f1_0.8865_good_0.9771_bad_0.7958_macro_0.8865_weighted_0.9594_seed_3650.7432239657631955.csv': 0.743,
    }
    
    predictions = {}
    scores = {}
    
    print("ğŸ”¥ åŠ è½½æœ€ä½³é¢„æµ‹æ–‡ä»¶ (åŸºäºå®æµ‹REAL F1)...")
    
    for filename, score in best_files.items():
        filepath = high_score_dir / filename
        if filepath.exists():
            try:
                df = pd.read_csv(filepath)
                if 'ID' in df.columns and 'Predict' in df.columns:
                    model_name = filename.split('_')[0] + '_' + str(score)
                    predictions[model_name] = dict(zip(df['ID'], df['Predict']))
                    scores[model_name] = score
                    bad_rate = df['Predict'].mean()
                    print(f"âœ… {model_name:<25} | Score: {score:.4f} | Badç‡: {bad_rate:.3f}")
            except Exception as e:
                print(f"âŒ {filename}: {e}")
    
    print(f"ğŸ“Š æˆåŠŸåŠ è½½ {len(predictions)} ä¸ªæœ€ä½³æ¨¡å‹")
    return predictions, scores

def precision_fusion_strategies(predictions, scores):
    """ç²¾å‡†å¾®è°ƒèåˆç­–ç•¥"""
    print("\nğŸ¯ ç²¾å‡†å¾®è°ƒèåˆç­–ç•¥ - ç›®æ ‡Badç‡8.5%-9.5%...")
    
    all_ids = set()
    for pred_dict in predictions.values():
        all_ids.update(pred_dict.keys())
    all_ids = sorted(all_ids)
    
    # æŒ‰åˆ†æ•°æ’åºæ¨¡å‹
    sorted_models = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    
    results = {}
    
    # ç­–ç•¥1: ç²¾å‡†é˜ˆå€¼ä¼˜åŒ–
    print("\nğŸ¯ ç­–ç•¥1: PRECISION_THRESHOLD_085")
    print("   é€»è¾‘: åŠ æƒæ¦‚ç‡ç²¾å‡†è°ƒèŠ‚åˆ°Badç‡8.5%")
    
    # è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„åŠ æƒæ¦‚ç‡
    top_models = [name for name, _ in sorted_models[:6]]  # å‰6ä¸ªæœ€ä½³æ¨¡å‹
    weights = [score for _, score in sorted_models[:6]]
    total_weight = sum(weights)
    normalized_weights = [w/total_weight for w in weights]
    
    account_probs = {}
    for account_id in all_ids:
        weighted_sum = 0
        available_weight = 0
        for i, model in enumerate(top_models):
            if account_id in predictions[model]:
                weighted_sum += predictions[model][account_id] * normalized_weights[i]
                available_weight += normalized_weights[i]
        
        if available_weight > 0:
            account_probs[account_id] = weighted_sum / available_weight
        else:
            account_probs[account_id] = 0
    
    # æ‰¾åˆ°8.5% Badç‡å¯¹åº”çš„é˜ˆå€¼
    sorted_probs = sorted(account_probs.values(), reverse=True)
    threshold_85_idx = int(len(sorted_probs) * 0.085)
    threshold_85 = sorted_probs[threshold_85_idx] if threshold_85_idx < len(sorted_probs) else 0.5
    
    precision_85 = {aid: 1 if prob >= threshold_85 else 0 for aid, prob in account_probs.items()}
    results['PRECISION_THRESHOLD_085'] = precision_85
    
    # ç­–ç•¥2: ç²¾å‡†é˜ˆå€¼90
    print("\nğŸ¯ ç­–ç•¥2: PRECISION_THRESHOLD_090")
    print("   é€»è¾‘: åŠ æƒæ¦‚ç‡ç²¾å‡†è°ƒèŠ‚åˆ°Badç‡9.0%")
    
    threshold_90_idx = int(len(sorted_probs) * 0.090)
    threshold_90 = sorted_probs[threshold_90_idx] if threshold_90_idx < len(sorted_probs) else 0.5
    
    precision_90 = {aid: 1 if prob >= threshold_90 else 0 for aid, prob in account_probs.items()}
    results['PRECISION_THRESHOLD_090'] = precision_90
    
    # ç­–ç•¥3: ç²¾å‡†é˜ˆå€¼95
    print("\nğŸ¯ ç­–ç•¥3: PRECISION_THRESHOLD_095")
    print("   é€»è¾‘: åŠ æƒæ¦‚ç‡ç²¾å‡†è°ƒèŠ‚åˆ°Badç‡9.5%")
    
    threshold_95_idx = int(len(sorted_probs) * 0.095)
    threshold_95 = sorted_probs[threshold_95_idx] if threshold_95_idx < len(sorted_probs) else 0.5
    
    precision_95 = {aid: 1 if prob >= threshold_95 else 0 for aid, prob in account_probs.items()}
    results['PRECISION_THRESHOLD_095'] = precision_95
    
    # ç­–ç•¥4: é¡¶çº§æ¨¡å‹å¼ºåŒ–
    print("\nğŸ¯ ç­–ç•¥4: TOP_MODEL_ENHANCED")
    print("   é€»è¾‘: æœ€é«˜åˆ†æ¨¡å‹(0.7549)é¢„æµ‹æƒé‡åŠ å€")
    
    best_model = sorted_models[0][0]  # æœ€é«˜åˆ†æ¨¡å‹
    enhanced_weights = normalized_weights.copy()
    enhanced_weights[0] *= 2  # æœ€ä½³æ¨¡å‹æƒé‡ç¿»å€
    total_enhanced = sum(enhanced_weights)
    enhanced_weights = [w/total_enhanced for w in enhanced_weights]
    
    enhanced_probs = {}
    for account_id in all_ids:
        weighted_sum = 0
        available_weight = 0
        for i, model in enumerate(top_models):
            if account_id in predictions[model]:
                weighted_sum += predictions[model][account_id] * enhanced_weights[i]
                available_weight += enhanced_weights[i]
        
        if available_weight > 0:
            enhanced_probs[account_id] = weighted_sum / available_weight
        else:
            enhanced_probs[account_id] = 0
    
    # è°ƒèŠ‚åˆ°9%Badç‡
    sorted_enhanced = sorted(enhanced_probs.values(), reverse=True)
    enhanced_threshold_idx = int(len(sorted_enhanced) * 0.09)
    enhanced_threshold = sorted_enhanced[enhanced_threshold_idx] if enhanced_threshold_idx < len(sorted_enhanced) else 0.5
    
    enhanced_pred = {aid: 1 if prob >= enhanced_threshold else 0 for aid, prob in enhanced_probs.items()}
    results['TOP_MODEL_ENHANCED'] = enhanced_pred
    
    # ç­–ç•¥5: æ··åˆæœ€ä½³ç­–ç•¥
    print("\nğŸ¯ ç­–ç•¥5: HYBRID_BEST")  
    print("   é€»è¾‘: ç»“åˆæœ€æˆåŠŸçš„AGGRESSIVE_VOTINGå’ŒWEIGHTEDåŸç†")
    
    # ç»“åˆæŠ•ç¥¨æœºåˆ¶å’ŒåŠ æƒæ¦‚ç‡
    hybrid_pred = {}
    for account_id in all_ids:
        # æŠ•ç¥¨æœºåˆ¶
        votes = [predictions[model].get(account_id, 0) for model in top_models if account_id in predictions[model]]
        vote_score = sum(votes) / len(votes) if votes else 0
        
        # åŠ æƒæ¦‚ç‡
        weighted_prob = account_probs.get(account_id, 0)
        
        # æ··åˆç­–ç•¥ï¼šæŠ•ç¥¨æƒé‡0.4ï¼Œæ¦‚ç‡æƒé‡0.6
        hybrid_score = 0.4 * vote_score + 0.6 * weighted_prob
        
        hybrid_pred[account_id] = 1 if hybrid_score >= 0.42 else 0  # è°ƒèŠ‚é˜ˆå€¼åˆ°çº¦8.8%
    
    results['HYBRID_BEST'] = hybrid_pred
    
    # æ‰“å°ç»Ÿè®¡
    print("\nğŸ“Š ç²¾å‡†ç­–ç•¥ç»“æœç»Ÿè®¡:")
    for name, pred in results.items():
        counts = Counter(pred.values())
        bad_rate = counts[1] / len(pred)
        print(f"   {name:<25} | Bad: {counts[1]:4d} ({bad_rate:6.1%}) | Good: {counts[0]:4d} ({1-bad_rate:6.1%})")
    
    return results

def save_precision_results(results):
    """ä¿å­˜ç²¾å‡†èåˆç»“æœ"""
    print("\nğŸ’¾ ä¿å­˜ç²¾å‡†å¾®è°ƒç»“æœ...")
    
    results_dir = Path("/Users/mannormal/4011/Qi Zihan/v2/results/high_score_predictions")
    
    for strategy_name, predictions in results.items():
        df = pd.DataFrame({
            'ID': sorted(predictions.keys()),
            'Predict': [predictions[id] for id in sorted(predictions.keys())]
        })
        
        filename = f"PRECISION_{strategy_name}.csv"
        filepath = results_dir / filename
        df.to_csv(filepath, index=False)
        
        pred_counts = Counter(df['Predict'])
        bad_rate = pred_counts[1] / len(df)
        print(f"âœ… {filename}")
        print(f"   Bad (1):  {pred_counts[1]:4d} ({bad_rate:6.1%}) â† ç²¾å‡†è°ƒèŠ‚")
        print(f"   Good (0): {pred_counts[0]:4d} ({1-bad_rate:6.1%})")

def main():
    print("ğŸ¯ğŸ’ ç²¾å‡†å¾®è°ƒèåˆ - å†²å‡»0.8+åˆ†æ•°ï¼ ğŸ’ğŸ¯")
    print("=" * 60)
    print("ğŸ“Š åŸºäºæˆåŠŸç»éªŒï¼šBadç‡8.5%-9.5%æ˜¯æœ€ä¼˜åŒºé—´")
    print("ğŸ¯ ç›®æ ‡ï¼šåœ¨æœ€ä¼˜åŒºé—´å†…å¯»æ‰¾æ›´é«˜ç²¾åº¦çš„èåˆ")
    
    # 1. åŠ è½½æœ€ä½³é¢„æµ‹
    predictions, scores = load_best_predictions()
    
    if len(predictions) < 5:
        print("âŒ æœ€ä½³é¢„æµ‹æ–‡ä»¶ä¸è¶³")
        return
    
    # 2. æ‰§è¡Œç²¾å‡†ç­–ç•¥  
    results = precision_fusion_strategies(predictions, scores)
    
    # 3. ä¿å­˜ç»“æœ
    save_precision_results(results)
    
    print("\nğŸ‰ ç²¾å‡†å¾®è°ƒå®Œæˆï¼")
    print("\nğŸ¯ å»ºè®®æäº¤é¡ºåº (åŸºäºæœ€ä¼˜Badç‡åŒºé—´):")
    print("   1. PRECISION_HYBRID_BEST.csv (~8.8%Badç‡ï¼Œæ··åˆæœ€ä½³ç­–ç•¥)")
    print("   2. PRECISION_PRECISION_THRESHOLD_090.csv (ç²¾å‡†9.0%Badç‡)")
    print("   3. PRECISION_TOP_MODEL_ENHANCED.csv (é¡¶çº§æ¨¡å‹å¼ºåŒ–)")
    print("   4. PRECISION_PRECISION_THRESHOLD_085.csv (8.5%Badç‡)")
    print("   5. PRECISION_PRECISION_THRESHOLD_095.csv (9.5%Badç‡)")
    print("\nğŸš€ è¿™äº›ç­–ç•¥åŸºäºå·²éªŒè¯çš„æœ€ä½³æ¨¡å‹å’Œæœ€ä¼˜Badç‡åŒºé—´ï¼")
    print("ğŸ’ æœŸå¾…çªç ´0.8åˆ†æ•°å¤§å…³ï¼")

if __name__ == "__main__":
    main()