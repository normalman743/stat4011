#!/usr/bin/env python3
"""
ğŸ” é¢„æµ‹åˆ†æå™¨ - æ·±åº¦åˆ†æé«˜åˆ†é¢„æµ‹æ–‡ä»¶çš„å¼‚åŒ
æ‰¾å‡ºæœ€ä¼˜èåˆç­–ç•¥ä»¥è¾¾åˆ°0.9åˆ†æ•°
"""
import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
from collections import Counter, defaultdict
import seaborn as sns

def analyze_predictions():
    """åˆ†ææ‰€æœ‰é«˜åˆ†é¢„æµ‹æ–‡ä»¶"""
    high_score_dir = Path("/Users/mannormal/4011/Qi Zihan/v2/results/high_score_predictions")
    
    print("ğŸ” åŠ è½½æ‰€æœ‰é«˜åˆ†é¢„æµ‹æ–‡ä»¶...")
    
    # åŠ è½½æ‰€æœ‰é¢„æµ‹
    predictions = {}
    file_info = {}
    
    for csv_file in high_score_dir.glob("*.csv"):
        try:
            df = pd.read_csv(csv_file)
            if 'ID' in df.columns and 'Predict' in df.columns:
                model_name = csv_file.stem[:50]  # ç®€åŒ–æ–‡ä»¶å
                predictions[model_name] = df.set_index('ID')['Predict'].to_dict()
                
                # æå–åˆ†æ•°ä¿¡æ¯
                score = extract_score_from_filename(csv_file.name)
                file_info[model_name] = {
                    'filename': csv_file.name,
                    'score': score,
                    'predict_1_count': df['Predict'].sum(),
                    'predict_1_ratio': df['Predict'].mean(),
                    'total_accounts': len(df)
                }
                print(f"âœ… {model_name} | Score: {score:.4f} | Badç‡: {df['Predict'].mean():.3f}")
        except Exception as e:
            print(f"âŒ è·³è¿‡ {csv_file.name}: {e}")
    
    print(f"\nğŸ“Š æˆåŠŸåŠ è½½ {len(predictions)} ä¸ªé¢„æµ‹æ–‡ä»¶")
    return predictions, file_info

def extract_score_from_filename(filename):
    """ä»æ–‡ä»¶åæå–åˆ†æ•°"""
    import re
    # REAL_F1åˆ†æ•°
    if 'REAL_F1_' in filename:
        match = re.search(r'REAL_F1_([0-9.]+)', filename)
        if match:
            return float(match.group(1))
    
    # å…¶ä»–åˆ†æ•°ä¼°ç®—
    if 'best_cv_f1_score_0.9121' in filename:
        return 0.733
    elif 'best_cv_f1_score_0.9314' in filename:
        return 0.713
    elif 'macro_f1_0.9735' in filename:
        return 0.703
    elif 'macro_f1_0.9590' in filename:
        return 0.720
    elif 'weighted_f1_0.9746' in filename:
        return 0.735
    elif 'weighted_f1_0.9733' in filename:
        return 0.736
    elif 'weighted_f1_0.9680' in filename:
        return 0.741
    elif 'badf1_0691' in filename:
        return 0.731
    elif 'voting_rf' in filename:
        return 0.736
    elif 'v2ultra_resnet' in filename:
        return 0.743
    else:
        return 0.700  # é»˜è®¤ä¼°è®¡

def analyze_agreement_patterns(predictions, file_info):
    """åˆ†æé¢„æµ‹ä¸€è‡´æ€§æ¨¡å¼"""
    print("\nğŸ¯ åˆ†æé¢„æµ‹ä¸€è‡´æ€§æ¨¡å¼...")
    
    # è·å–æ‰€æœ‰è´¦æˆ·ID
    all_ids = set()
    for pred_dict in predictions.values():
        all_ids.update(pred_dict.keys())
    all_ids = sorted(all_ids)
    
    # åˆ›å»ºé¢„æµ‹çŸ©é˜µ
    model_names = list(predictions.keys())
    pred_matrix = np.zeros((len(all_ids), len(model_names)), dtype=int)
    
    for j, model in enumerate(model_names):
        for i, account_id in enumerate(all_ids):
            pred_matrix[i, j] = predictions[model].get(account_id, 0)
    
    # åˆ†ææ¯ä¸ªè´¦æˆ·çš„é¢„æµ‹æ¨¡å¼
    account_analysis = []
    for i, account_id in enumerate(all_ids):
        account_preds = pred_matrix[i, :]
        positive_votes = account_preds.sum()
        total_votes = len(account_preds)
        agreement_ratio = positive_votes / total_votes
        
        account_analysis.append({
            'account_id': account_id,
            'positive_votes': positive_votes,
            'total_votes': total_votes,
            'agreement_ratio': agreement_ratio,
            'prediction_pattern': ''.join(map(str, account_preds))
        })
    
    # æŒ‰ä¸€è‡´æ€§åˆ†ç»„
    unanimous_good = [a for a in account_analysis if a['positive_votes'] == 0]
    unanimous_bad = [a for a in account_analysis if a['positive_votes'] == a['total_votes']]
    high_consensus_bad = [a for a in account_analysis if a['agreement_ratio'] >= 0.8 and a['positive_votes'] > 0]
    high_consensus_good = [a for a in account_analysis if a['agreement_ratio'] <= 0.2 and a['positive_votes'] < a['total_votes']]
    disputed = [a for a in account_analysis if 0.3 <= a['agreement_ratio'] <= 0.7]
    
    print(f"\nğŸ“ˆ é¢„æµ‹ä¸€è‡´æ€§ç»Ÿè®¡:")
    print(f"   ä¸€è‡´é¢„æµ‹Good (0ç¥¨): {len(unanimous_good):4d} ({len(unanimous_good)/len(all_ids)*100:5.1f}%)")
    print(f"   ä¸€è‡´é¢„æµ‹Bad (æ»¡ç¥¨): {len(unanimous_bad):4d} ({len(unanimous_bad)/len(all_ids)*100:5.1f}%)")
    print(f"   é«˜åº¦ä¸€è‡´Good (â‰¤20%): {len(high_consensus_good):4d} ({len(high_consensus_good)/len(all_ids)*100:5.1f}%)")
    print(f"   é«˜åº¦ä¸€è‡´Bad (â‰¥80%): {len(high_consensus_bad):4d} ({len(high_consensus_bad)/len(all_ids)*100:5.1f}%)")
    print(f"   äº‰è®®è´¦æˆ· (30%-70%): {len(disputed):4d} ({len(disputed)/len(all_ids)*100:5.1f}%)")
    
    return {
        'all_ids': all_ids,
        'pred_matrix': pred_matrix,
        'model_names': model_names,
        'account_analysis': account_analysis,
        'unanimous_good': unanimous_good,
        'unanimous_bad': unanimous_bad,
        'high_consensus_good': high_consensus_good,
        'high_consensus_bad': high_consensus_bad,
        'disputed': disputed
    }

def analyze_model_similarities(predictions, file_info):
    """åˆ†ææ¨¡å‹é—´ç›¸ä¼¼æ€§"""
    print("\nğŸ”— åˆ†ææ¨¡å‹é—´ç›¸ä¼¼æ€§...")
    
    model_names = list(predictions.keys())
    n_models = len(model_names)
    
    # è®¡ç®—æ¨¡å‹é—´ç›¸ä¼¼æ€§çŸ©é˜µ
    similarity_matrix = np.zeros((n_models, n_models))
    
    all_ids = set()
    for pred_dict in predictions.values():
        all_ids.update(pred_dict.keys())
    all_ids = sorted(all_ids)
    
    for i, model1 in enumerate(model_names):
        for j, model2 in enumerate(model_names):
            if i == j:
                similarity_matrix[i, j] = 1.0
            else:
                # è®¡ç®—é¢„æµ‹ä¸€è‡´æ€§
                agreements = 0
                total = 0
                for account_id in all_ids:
                    if account_id in predictions[model1] and account_id in predictions[model2]:
                        if predictions[model1][account_id] == predictions[model2][account_id]:
                            agreements += 1
                        total += 1
                
                similarity_matrix[i, j] = agreements / total if total > 0 else 0
    
    # æ‰¾å‡ºæœ€ç›¸ä¼¼å’Œæœ€ä¸åŒçš„æ¨¡å‹å¯¹
    print(f"\nğŸ“Š æ¨¡å‹ç›¸ä¼¼æ€§åˆ†æ:")
    similarities = []
    for i in range(n_models):
        for j in range(i+1, n_models):
            sim = similarity_matrix[i, j]
            similarities.append((sim, model_names[i][:30], model_names[j][:30]))
    
    similarities.sort(reverse=True)
    print(f"   æœ€ç›¸ä¼¼çš„æ¨¡å‹å¯¹:")
    for sim, m1, m2 in similarities[:3]:
        print(f"     {sim:.4f} - {m1} vs {m2}")
    
    print(f"   æœ€ä¸åŒçš„æ¨¡å‹å¯¹:")
    for sim, m1, m2 in similarities[-3:]:
        print(f"     {sim:.4f} - {m1} vs {m2}")
    
    return similarity_matrix, similarities

def generate_fusion_strategies(analysis_result, file_info):
    """ç”Ÿæˆèåˆç­–ç•¥"""
    print("\nğŸ¯ ç”Ÿæˆç²¾ç¡®èåˆç­–ç•¥...")
    
    # æŒ‰åˆ†æ•°æ’åºæ¨¡å‹
    scored_models = [(name, info['score']) for name, info in file_info.items()]
    scored_models.sort(key=lambda x: x[1], reverse=True)
    
    print(f"ğŸ“Š æ¨¡å‹è´¨é‡æ’åº (å‰10):")
    for i, (name, score) in enumerate(scored_models[:10], 1):
        bad_ratio = file_info[name]['predict_1_ratio']
        print(f"   {i:2d}. {score:.4f} | Badç‡:{bad_ratio:.3f} | {name[:50]}...")
    
    # ç­–ç•¥1: ä¿å®ˆèåˆ - é’ˆå¯¹0.9åˆ†æ•°ç›®æ ‡
    conservative_strategy = {
        'name': 'CONSERVATIVE_090',
        'description': 'ä¿å®ˆç­–ç•¥ï¼Œåªæœ‰é«˜è´¨é‡æ¨¡å‹å¼ºçƒˆä¸€è‡´æ—¶æ‰é¢„æµ‹ä¸ºBad',
        'logic': 'å‰6ä¸ªé«˜åˆ†æ¨¡å‹ä¸­â‰¥5ä¸ªé¢„æµ‹Badæ‰è¾“å‡ºBad',
        'target_bad_ratio': 0.08,  # æœŸæœ›Badç‡8%å·¦å³
        'models': [name for name, _ in scored_models[:6]]
    }
    
    # ç­–ç•¥2: åŠ æƒèåˆ - åŸºäºåˆ†æ•°åŠ æƒ
    weighted_strategy = {
        'name': 'WEIGHTED_090',
        'description': 'åŸºäºREAL F1åˆ†æ•°çš„åŠ æƒèåˆ',
        'logic': 'æŒ‰åˆ†æ•°åŠ æƒï¼Œé˜ˆå€¼0.65',
        'target_bad_ratio': 0.10,
        'models': [name for name, _ in scored_models[:8]],
        'weights': [score for _, score in scored_models[:8]]
    }
    
    # ç­–ç•¥3: äº‰è®®è´¦æˆ·ä¸“é—¨å¤„ç†
    dispute_strategy = {
        'name': 'DISPUTE_FOCUSED_090',
        'description': 'å¯¹äº‰è®®è´¦æˆ·ä½¿ç”¨é¡¶çº§æ¨¡å‹å†³å®š',
        'logic': 'ä¸€è‡´è´¦æˆ·ç›´æ¥å†³å®šï¼Œäº‰è®®è´¦æˆ·åªçœ‹å‰3ä¸ªæœ€é«˜åˆ†æ¨¡å‹',
        'target_bad_ratio': 0.09,
        'models': [name for name, _ in scored_models[:3]]
    }
    
    strategies = [conservative_strategy, weighted_strategy, dispute_strategy]
    
    print(f"\nğŸ’¡ æ¨èèåˆç­–ç•¥:")
    for i, strategy in enumerate(strategies, 1):
        print(f"   {i}. {strategy['name']}")
        print(f"      æè¿°: {strategy['description']}")
        print(f"      é€»è¾‘: {strategy['logic']}")
        print(f"      ç›®æ ‡Badç‡: {strategy['target_bad_ratio']:.1%}")
        print()
    
    return strategies

def implement_strategies(predictions, file_info, analysis_result, strategies):
    """å®ç°èåˆç­–ç•¥"""
    print("ğŸš€ å®ç°èåˆç­–ç•¥...")
    
    all_ids = analysis_result['all_ids']
    results = {}
    
    for strategy in strategies:
        print(f"\nğŸ² æ‰§è¡Œç­–ç•¥: {strategy['name']}")
        
        fusion_pred = {}
        
        if strategy['name'] == 'CONSERVATIVE_090':
            # ä¿å®ˆç­–ç•¥ï¼šå‰6ä¸ªæ¨¡å‹ä¸­â‰¥5ä¸ªé¢„æµ‹Bad
            top_models = strategy['models'][:6]
            for account_id in all_ids:
                votes = [predictions[model].get(account_id, 0) for model in top_models if account_id in predictions[model]]
                if len(votes) >= 5:  # è‡³å°‘5ä¸ªæ¨¡å‹æœ‰é¢„æµ‹
                    fusion_pred[account_id] = 1 if sum(votes) >= 5 else 0
                else:
                    fusion_pred[account_id] = 0
        
        elif strategy['name'] == 'WEIGHTED_090':
            # åŠ æƒç­–ç•¥
            top_models = strategy['models'][:8]
            weights = [info['score'] for name, info in file_info.items() if name in top_models]
            total_weight = sum(weights)
            normalized_weights = [w/total_weight for w in weights]
            
            for account_id in all_ids:
                weighted_sum = 0
                available_weight = 0
                for i, model in enumerate(top_models):
                    if account_id in predictions[model]:
                        weighted_sum += predictions[model][account_id] * normalized_weights[i]
                        available_weight += normalized_weights[i]
                
                if available_weight > 0:
                    fusion_pred[account_id] = 1 if weighted_sum / available_weight >= 0.65 else 0
                else:
                    fusion_pred[account_id] = 0
        
        elif strategy['name'] == 'DISPUTE_FOCUSED_090':
            # äº‰è®®å¤„ç†ç­–ç•¥
            unanimous_good_ids = {a['account_id'] for a in analysis_result['unanimous_good']}
            unanimous_bad_ids = {a['account_id'] for a in analysis_result['unanimous_bad']}
            high_consensus_good_ids = {a['account_id'] for a in analysis_result['high_consensus_good']}
            high_consensus_bad_ids = {a['account_id'] for a in analysis_result['high_consensus_bad']}
            disputed_ids = {a['account_id'] for a in analysis_result['disputed']}
            
            top3_models = strategy['models'][:3]
            
            for account_id in all_ids:
                if account_id in unanimous_good_ids or account_id in high_consensus_good_ids:
                    fusion_pred[account_id] = 0
                elif account_id in unanimous_bad_ids or account_id in high_consensus_bad_ids:
                    fusion_pred[account_id] = 1
                elif account_id in disputed_ids:
                    # äº‰è®®è´¦æˆ·ï¼šåªçœ‹å‰3ä¸ªæœ€é«˜åˆ†æ¨¡å‹
                    votes = [predictions[model].get(account_id, 0) for model in top3_models if account_id in predictions[model]]
                    fusion_pred[account_id] = 1 if sum(votes) >= 2 else 0
                else:
                    fusion_pred[account_id] = 0
        
        results[strategy['name']] = fusion_pred
        
        # ç»Ÿè®¡ç»“æœ
        pred_counts = Counter(fusion_pred.values())
        bad_ratio = pred_counts[1] / len(fusion_pred)
        print(f"   ç»“æœ: Bad {pred_counts[1]} ({bad_ratio:.3f}), Good {pred_counts[0]} ({1-bad_ratio:.3f})")
    
    return results

def save_fusion_results(results):
    """ä¿å­˜èåˆç»“æœ"""
    print("\nğŸ’¾ ä¿å­˜èåˆç»“æœ...")
    
    results_dir = Path("/Users/mannormal/4011/Qi Zihan/v2/results/high_score_predictions")
    
    for strategy_name, predictions in results.items():
        df = pd.DataFrame({
            'ID': sorted(predictions.keys()),
            'Predict': [predictions[id] for id in sorted(predictions.keys())]
        })
        
        filename = f"FUSION_{strategy_name}.csv"
        filepath = results_dir / filename
        df.to_csv(filepath, index=False)
        
        pred_counts = Counter(df['Predict'])
        print(f"âœ… {filename}")
        print(f"   Good (0): {pred_counts[0]} ({pred_counts[0]/len(df)*100:.1f}%)")
        print(f"   Bad (1):  {pred_counts[1]} ({pred_counts[1]/len(df)*100:.1f}%)")

def main():
    print("ğŸ¯ğŸ”ğŸ¯ æ·±åº¦é¢„æµ‹åˆ†æå™¨ - ç›®æ ‡0.9åˆ†æ•°! ğŸ¯ğŸ”ğŸ¯")
    print("=" * 60)
    
    # 1. åŠ è½½é¢„æµ‹
    predictions, file_info = analyze_predictions()
    
    # 2. åˆ†æä¸€è‡´æ€§æ¨¡å¼
    analysis_result = analyze_agreement_patterns(predictions, file_info)
    
    # 3. åˆ†ææ¨¡å‹ç›¸ä¼¼æ€§
    similarity_matrix, similarities = analyze_model_similarities(predictions, file_info)
    
    # 4. ç”Ÿæˆèåˆç­–ç•¥
    strategies = generate_fusion_strategies(analysis_result, file_info)
    
    # 5. å®ç°èåˆç­–ç•¥
    fusion_results = implement_strategies(predictions, file_info, analysis_result, strategies)
    
    # 6. ä¿å­˜ç»“æœ
    save_fusion_results(fusion_results)
    
    print("\nğŸ‰ åˆ†æå®Œæˆï¼")
    print("\nğŸ’¡ å»ºè®®æäº¤é¡ºåº:")
    print("   1. FUSION_CONSERVATIVE_090.csv (æœ€ä¿å®ˆï¼ŒBadç‡æœ€ä½)")
    print("   2. FUSION_DISPUTE_FOCUSED_090.csv (å¤„ç†äº‰è®®è´¦æˆ·)")  
    print("   3. FUSION_WEIGHTED_090.csv (å¦‚æœå‰é¢æ•ˆæœå¥½)")
    print("\nğŸ¯ æœŸå¾…çªç ´0.9åˆ†æ•°ï¼")

if __name__ == "__main__":
    main()