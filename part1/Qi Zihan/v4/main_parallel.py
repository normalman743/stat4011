#!/usr/bin/env python3
"""
å¹¶è¡ŒäºŒåˆ†æ³•ä¼˜åŒ–ç³»ç»Ÿ - ä¸»ç¨‹åº
ä½¿ç”¨ä»»åŠ¡ç®¡ç†å™¨å’Œå·¥ä½œçº¿ç¨‹æ± è¿›è¡Œå¹¶è¡Œä¼˜åŒ–
"""
import pandas as pd
import time
import os
import threading
import queue
import json
import uuid
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional
from confusion_calculator import calculate_confusion_from_f1
#from upload_module import upload_file  # æ­£å¼realcase
from simulator import simulate_f1 as upload_file  # æ¨¡æ‹Ÿ


# æ·»åŠ æ‰“å°é”å’ŒçŠ¶æ€æ‰“å°å‡½æ•°
print_lock = threading.Lock()

def print_status(confirmed_good, confirmed_bad, unconfirmed, 
                block_good, block_bad, correct_good, correct_bad, 
                wrong_good, wrong_bad, f1_score=None, worker_id=None, 
                description="", current_block=None, pending_blocks=None):
    """æ‰“å°çŠ¶æ€è¡¨æ ¼ - åŒ…å«blockè¯¦ç»†ä¿¡æ¯"""
    with print_lock:
        # æ˜¾ç¤ºå½“å‰å¤„ç†çš„block
        if current_block:
            print(f"ğŸ“Š Worker-{worker_id} Block[æ­£åœ¨å¤„ç†]: {len(current_block.accounts)} ä¸ªè´¦æˆ· "
                  f"(æ­£ç¡®: {current_block.estimated_correct}, é”™è¯¯: {current_block.estimated_wrong}) â† å½“å‰å¤„ç†")
            
            # æ˜¾ç¤ºå¾…å¤„ç†çš„block
            if pending_blocks and len(pending_blocks) > 0:
                for i, block in enumerate(pending_blocks[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªå¾…å¤„ç†
                    print(f"    - Block[å¾…å¤„ç†-{i+1}]: {len(block.accounts)} ä¸ªè´¦æˆ· "
                          f"(é¢„ä¼°æ­£ç¡®: {block.estimated_correct}, é”™è¯¯: {block.estimated_wrong})")
        else:
            print(f"\nğŸ“Š Worker-{worker_id} {description}" if worker_id else f"\nğŸ“Š {description}")
        
        print(f"                good     bad")
        print(f"æ€»å…±æ•°é‡ï¼š      6831     727")
        print(f"å·²ç»ç¡®è®¤ï¼š      {confirmed_good}        {confirmed_bad}")  
        print(f"ç­‰å¾…ç¡®è®¤ï¼š      {unconfirmed}")
        print(f"æœ¬æ¬¡çŒœæµ‹ï¼š      {block_good}      {block_bad}")
        print(f"æ­£ç¡®çŒœæµ‹ï¼š      {correct_good}      {correct_bad}")
        print(f"é”™è¯¯çŒœæµ‹ï¼š      {wrong_good}      {wrong_bad}")
        if f1_score:
            print(f"å½“å‰F1ï¼š        {f1_score:.6f}")


@dataclass
class Block:
    id: str
    accounts: List[str]
    layer_id: int
    priority: int
    parent_id: Optional[str] = None
    created_time: float = None
    # æ–°å¢é¢„ä¼°ç»Ÿè®¡
    estimated_correct: int = 0
    estimated_wrong: int = 0
    status: str = "pending"  # pending, processing, completed
    
    def __post_init__(self):
        if self.created_time is None:
            self.created_time = time.time()
    
    @property
    def size(self) -> int:
        return len(self.accounts)
    
    def __lt__(self, other):
        # ç”¨äºä¼˜å…ˆçº§é˜Ÿåˆ—æ’åºï¼šä¼˜å…ˆçº§å°çš„å…ˆå¤„ç†ï¼ŒåŒä¼˜å…ˆçº§æŒ‰å¤§å°æ’åº
        return (self.priority, -self.size) < (other.priority, -other.size)


def generate_block_id() -> str:
    """ç”Ÿæˆå”¯ä¸€çš„block ID"""
    return str(uuid.uuid4())[:8]


class TaskManager:
    def __init__(self, state_file="/Users/mannormal/4011/Qi Zihan/v4/parallel_state.json"):
        # ä»»åŠ¡é˜Ÿåˆ—å’ŒçŠ¶æ€
        self.task_queue = queue.PriorityQueue()  # å†…ç½®çº¿ç¨‹å®‰å…¨
        self.completed_blocks = {}  # {block_id: result}
        self.active_blocks = set()  # æ­£åœ¨å¤„ç†çš„block_idé›†åˆ
        
        # å…¨å±€çŠ¶æ€ - æ— é”
        self.global_predictions = {}  # {account_id: 0/1}
        self.account_status = {}      # {account_id: -1/0/1} -1=æœªç¡®è®¤
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_iterations = 0
        
        # æ–°å¢ï¼šå±‚çº§åŠ¨æ€ç»Ÿè®¡
        self.layer_stats = {}  # {layer_id: {'total_processed': 0, 'total_correct': 0, 'correct_rate': 0.5}}
        
        # çŠ¶æ€æŒä¹…åŒ–
        self.state_file = state_file
        
        # å®Œæˆæ ‡å¿—
        self.shutdown_event = threading.Event()
        
        print("ğŸ”§ TaskManageråˆå§‹åŒ–å®Œæˆ")
    
    def estimate_block_performance(self, block: Block):
        """åŸºäºå±‚ç»Ÿè®¡é¢„ä¼°blockè¡¨ç°"""
        layer_stat = self.layer_stats.get(block.layer_id, {'correct_rate': 0.5})
        estimated_correct = int(len(block.accounts) * layer_stat['correct_rate'])
        block.estimated_correct = estimated_correct
        block.estimated_wrong = len(block.accounts) - estimated_correct
    
    def update_layer_stats(self, layer_id: int, actual_correct: int, block_size: int):
        """åŸºäºçœŸå®è¡¨ç°æ›´æ–°å±‚ç»Ÿè®¡"""
        if layer_id not in self.layer_stats:
            self.layer_stats[layer_id] = {'total_processed': 0, 'total_correct': 0, 'correct_rate': 0.5}
        
        self.layer_stats[layer_id]['total_processed'] += block_size
        self.layer_stats[layer_id]['total_correct'] += actual_correct
        self.layer_stats[layer_id]['correct_rate'] = (
            self.layer_stats[layer_id]['total_correct'] / 
            self.layer_stats[layer_id]['total_processed']
        )
        
        # æ›´æ–°åŒå±‚å…¶ä»–pending blocksçš„é¢„ä¼°
        self._update_pending_blocks_estimates(layer_id)
    
    def _update_pending_blocks_estimates(self, layer_id: int):
        """æ›´æ–°åŒå±‚å¾…å¤„ç†blocksçš„é¢„ä¼°"""
        # æ”¶é›†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        temp_tasks = []
        while not self.task_queue.empty():
            try:
                task = self.task_queue.get_nowait()
                temp_tasks.append(task)
            except queue.Empty:
                break
        
        # æ›´æ–°åŒå±‚blockçš„é¢„ä¼°
        for priority_tuple, block in temp_tasks:
            if block.layer_id == layer_id:
                self.estimate_block_performance(block)
        
        # é‡æ–°æ”¾å›é˜Ÿåˆ—
        for task in temp_tasks:
            self.task_queue.put(task)
    
    def get_pending_blocks_preview(self, limit: int = 3) -> List[Block]:
        """è·å–å¾…å¤„ç†blocksçš„é¢„è§ˆï¼ˆä¸ç§»é™¤ï¼‰"""
        temp_tasks = []
        pending_blocks = []
        
        try:
            while not self.task_queue.empty() and len(pending_blocks) < limit:
                task = self.task_queue.get_nowait()
                temp_tasks.append(task)
                pending_blocks.append(task[1])  # task[1] is the Block
        except queue.Empty:
            pass
        
        # é‡æ–°æ”¾å›é˜Ÿåˆ—
        for task in temp_tasks:
            self.task_queue.put(task)
        
        return pending_blocks
    
    def add_block(self, block: Block):
        """æ·»åŠ æ–°çš„blockä»»åŠ¡"""
        # é¢„ä¼°blockè¡¨ç°
        self.estimate_block_performance(block)
        
        priority_tuple = (block.priority, -block.size, block.created_time)
        self.task_queue.put((priority_tuple, block))
    
    def get_next_task(self, preferred_layer_id: int, timeout=1.0) -> Optional[Block]:
        """è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼Œä¼˜å…ˆè·å–æŒ‡å®šå±‚çš„ä»»åŠ¡"""
        temp_tasks = []
        found_preferred = None
        try:
            while not self.task_queue.empty():
                priority_tuple, block = self.task_queue.get_nowait()
                if block.layer_id == preferred_layer_id and found_preferred is None:
                    found_preferred = block
                else:
                    temp_tasks.append((priority_tuple, block))
            for task in temp_tasks:
                self.task_queue.put(task)
            if found_preferred:
                found_preferred.status = "processing"
                self.active_blocks.add(found_preferred.id)
                return found_preferred
            if not self.task_queue.empty():
                priority_tuple, block = self.task_queue.get(timeout=timeout)
                block.status = "processing"
                self.active_blocks.add(block.id)
                return block
        except queue.Empty:
            pass
        return None
    
    def complete_block(self, block_id: str, result_type: str, new_blocks: List[Block] = None):
        """å®Œæˆä¸€ä¸ªblockçš„å¤„ç†"""
        self.completed_blocks[block_id] = {
            'result': result_type,
            'completed_time': time.time(),
            'new_blocks_count': len(new_blocks) if new_blocks else 0
        }
        
        self.active_blocks.discard(block_id)
        self.total_iterations += 1
        
        if new_blocks:
            for new_block in new_blocks:
                self.add_block(new_block)
    
    def update_global_predictions(self, account_updates: Dict[str, int]):
        """æ›´æ–°å…¨å±€é¢„æµ‹"""
        self.global_predictions.update(account_updates)
    
    def update_account_status(self, status_updates: Dict[str, int]):
        """æ›´æ–°è´¦æˆ·ç¡®è®¤çŠ¶æ€"""
        self.account_status.update(status_updates)
    
    def get_global_predictions_copy(self) -> Dict[str, int]:
        """è·å–å…¨å±€é¢„æµ‹çš„å‰¯æœ¬"""
        return self.global_predictions.copy()
    
    def get_account_status_copy(self) -> Dict[str, int]:
        """è·å–è´¦æˆ·çŠ¶æ€çš„å‰¯æœ¬"""
        return self.account_status.copy()
    
    def confirm_accounts(self, accounts: List[str], predictions: Dict[str, int]):
        """ç¡®è®¤è´¦æˆ·çš„é¢„æµ‹å’ŒçŠ¶æ€"""
        self.update_global_predictions(predictions)
        status_updates = {aid: predictions[aid] for aid in accounts}
        self.update_account_status(status_updates)
    
    def is_all_complete(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆ"""
        if self.shutdown_event.is_set():
            return True
        
        queue_empty = self.task_queue.empty()
        active_empty = len(self.active_blocks) == 0
        
        return queue_empty and active_empty
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_accounts = len(self.account_status)
        confirmed_accounts = sum(1 for status in self.account_status.values() if status != -1)
        pending_tasks = self.task_queue.qsize()
        active_tasks = len(self.active_blocks)
        return {
            'total_iterations': self.total_iterations,
            'total_accounts': total_accounts,
            'confirmed_accounts': confirmed_accounts,
            'pending_tasks': pending_tasks,
            'active_tasks': active_tasks,
            'completion_rate': confirmed_accounts / total_accounts if total_accounts > 0 else 0
        }
    
    def save_state(self):
        """ä¿å­˜å½“å‰çŠ¶æ€åˆ°JSONæ–‡ä»¶"""
        try:
            # æ”¶é›†æ‰€æœ‰å¾…å¤„ç†ä»»åŠ¡
            temp_tasks = []
            while not self.task_queue.empty():
                try:
                    task = self.task_queue.get_nowait()
                    temp_tasks.append(task)
                except queue.Empty:
                    break
            
            # å‡†å¤‡çŠ¶æ€æ•°æ®
            state_data = {
                'global_predictions': self.global_predictions,
                'account_status': self.account_status,
                'total_iterations': self.total_iterations,
                'completed_blocks': self.completed_blocks,
                'layer_stats': self.layer_stats,  # ä¿å­˜å±‚ç»Ÿè®¡
                'pending_tasks': [
                    {
                        'id': block.id,
                        'accounts': block.accounts,
                        'layer_id': block.layer_id,
                        'priority': block.priority,
                        'parent_id': block.parent_id,
                        'estimated_correct': block.estimated_correct,
                        'estimated_wrong': block.estimated_wrong
                    }
                    for _, block in temp_tasks
                ],
                'saved_time': time.time()
            }
            
            # æ¢å¤é˜Ÿåˆ—
            for task in temp_tasks:
                self.task_queue.put(task)
            
            # å†™å…¥æ–‡ä»¶
            with open(self.state_file, 'w') as f:
                json.dump(state_data, f, indent=2)
            
            print(f"ğŸ’¾ çŠ¶æ€å·²ä¿å­˜åˆ° {self.state_file}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")
    
    def load_state(self) -> bool:
        """ä»JSONæ–‡ä»¶æ¢å¤çŠ¶æ€"""
        try:
            with open(self.state_file, 'r') as f:
                state_data = json.load(f)
            
            self.global_predictions = state_data.get('global_predictions', {})
            self.account_status = state_data.get('account_status', {})
            self.total_iterations = state_data.get('total_iterations', 0)
            self.completed_blocks = state_data.get('completed_blocks', {})
            self.layer_stats = state_data.get('layer_stats', {})  # æ¢å¤å±‚ç»Ÿè®¡
            
            # æ¢å¤å¾…å¤„ç†ä»»åŠ¡
            pending_tasks = state_data.get('pending_tasks', [])
            for task_data in pending_tasks:
                block = Block(
                    id=task_data['id'],
                    accounts=task_data['accounts'],
                    layer_id=task_data['layer_id'],
                    priority=task_data['priority'],
                    parent_id=task_data.get('parent_id')
                )
                # æ¢å¤é¢„ä¼°ç»Ÿè®¡
                block.estimated_correct = task_data.get('estimated_correct', 0)
                block.estimated_wrong = task_data.get('estimated_wrong', 0)
                self.add_block(block)
            
            saved_time = state_data.get('saved_time', 0)
            print(f"ğŸ“‚ çŠ¶æ€å·²æ¢å¤ (ä¿å­˜æ—¶é—´: {time.ctime(saved_time)})")
            print(f"   æ€»è¿­ä»£: {self.total_iterations}, å¾…å¤„ç†ä»»åŠ¡: {len(pending_tasks)}")
            
            return True
            
        except FileNotFoundError:
            print("ğŸ“‚ æœªæ‰¾åˆ°çŠ¶æ€æ–‡ä»¶ï¼Œä»å¤´å¼€å§‹")
            return False
        except Exception as e:
            print(f"âŒ æ¢å¤çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def shutdown(self):
        """ä¼˜é›…å…³é—­"""
        print("ğŸ›‘ TaskManageræ­£åœ¨å…³é—­...")
        self.shutdown_event.set()
        self.save_state()
        print("âœ… TaskManagerå·²å…³é—­")


class BinaryOptimizer:
    """äºŒåˆ†ä¼˜åŒ–å™¨"""
    
    def __init__(self, task_manager: TaskManager):
        self.task_manager = task_manager
        
        # å±‚åŸºå‡†ä¿¡æ¯
        self.layer_baselines = {
            1: {'bad': 154, 'good': 6626, 'total': 6780},
            2: {'bad': 30, 'good': 45, 'total': 75},
            3: {'bad': 43, 'good': 61, 'total': 104},
            4: {'bad': 51, 'good': 62, 'total': 113},
            5: {'bad': 449, 'good': 37, 'total': 486}
        }
    
    def process_block(self, block: Block, worker_id: int) -> str:
        """
        å¤„ç†å•ä¸ªblock
        
        Args:
            block: è¦å¤„ç†çš„block
            worker_id: å·¥ä½œçº¿ç¨‹ID
            
        Returns:
            å¤„ç†ç»“æœç±»å‹
        """
        
        if block.size == 1:
            return self._process_single_account(block, worker_id)
        else:
            return self._process_batch_binary(block, worker_id)
    
    def _save_predictions_to_csv(self, predictions: Dict[str, int], filepath: str):
        """ä¿å­˜é¢„æµ‹åˆ°CSVæ–‡ä»¶"""
        import pandas as pd
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        predictions_list = [{"ID": aid, "Predict": pred} for aid, pred in predictions.items()]
        df = pd.DataFrame(predictions_list)
        df.to_csv(filepath, index=False)

    def _test_predictions(self, predictions: Dict[str, int], description: str, worker_id: int) -> float:
        """æµ‹è¯•é¢„æµ‹å¹¶è¿”å›F1åˆ†æ•°"""
        temp_dir = "/Users/mannormal/4011/Qi Zihan/v4/temp"
        os.makedirs(temp_dir, exist_ok=True)
        temp_file = f"{temp_dir}/test_{worker_id}_{int(time.time() * 1000)}.csv"
        try:
            self._save_predictions_to_csv(predictions, temp_file)
            f1_score = upload_file(temp_file)
            return f1_score
        finally:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except Exception as e:
                print(f"è­¦å‘Šï¼šæ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {temp_file}: {e}")

    def _create_test_batch_predictions(self, base_predictions: Dict[str, int], 
                                      test_batch: List[str], flip: bool = True) -> Dict[str, int]:
        """åˆ›å»ºæµ‹è¯•æ‰¹æ¬¡çš„é¢„æµ‹ï¼ˆç¿»è½¬æˆ–ä¿æŒï¼‰"""
        test_predictions = base_predictions.copy()
        if flip:
            for account_id in test_batch:
                test_predictions[account_id] = 1 - test_predictions[account_id]
        return test_predictions

    def analyze_binary_split(self, confusion_baseline, confusion_flipped, n_b, total_good, total_bad, 
                           base_predictions, parent_block):
        """
        åˆ†æäºŒåˆ†ç»“æœ
        
        Returns:
            (a_status, b_status, block_stats): ä¸¤ä¸ªblockçš„çŠ¶æ€åˆ¤æ–­å’Œç»Ÿè®¡ä¿¡æ¯
        """
        # è®¡ç®—å˜åŒ–é‡
        delta_tp = confusion_flipped['TP'] - confusion_baseline['TP']
        delta_fp = confusion_flipped['FP'] - confusion_baseline['FP']
        
        # æ¨æ–­block_bçš„çœŸå®åˆ†å¸ƒ
        b_bad = delta_tp
        b_good = delta_fp
        
        # éªŒè¯ä¸€è‡´æ€§
        if b_bad + b_good != n_b:
            return "MIXED", "MIXED", {'correct': 0, 'wrong': len(parent_block.accounts), 'pred_good': 0, 'pred_bad': 0}
        
        # åˆ¤å®šblock_b
        if b_bad == n_b:
            b_status = "ALL_BAD"
        elif b_good == n_b:
            b_status = "ALL_GOOD"
        else:
            b_status = "MIXED"
        
        # åˆ¤å®šblock_aï¼ˆå‰©ä¸‹çš„ï¼‰
        a_bad = total_bad - b_bad
        a_good = total_good - b_good
        
        if a_bad == 0:
            a_status = "ALL_GOOD"
        elif a_good == 0:
            a_status = "ALL_BAD"
        else:
            a_status = "MIXED"
        
        # è®¡ç®—parent_blockçš„çœŸå®åˆ†å¸ƒå’Œæ­£ç¡®é¢„æµ‹ç»Ÿè®¡
        parent_true_good = a_good + b_good  
        parent_true_bad = a_bad + b_bad
        
        # è®¡ç®—å®é™…æ­£ç¡®é¢„æµ‹
        pred_good_count = sum(1 for aid in parent_block.accounts if base_predictions[aid] == 0)
        pred_bad_count = len(parent_block.accounts) - pred_good_count
        
        actual_correct = min(pred_good_count, parent_true_good) + min(pred_bad_count, parent_true_bad)
        actual_wrong = len(parent_block.accounts) - actual_correct
        
        # æ›´æ–°å±‚ç»Ÿè®¡
        self.task_manager.update_layer_stats(parent_block.layer_id, actual_correct, len(parent_block.accounts))
        
        # è¿”å›ç»Ÿè®¡ä¿¡æ¯
        block_stats = {
            'correct': actual_correct,
            'wrong': actual_wrong,
            'pred_good': pred_good_count,
            'pred_bad': pred_bad_count
        }
        
        return a_status, b_status, block_stats

    def execute_split_decisions(self, a_status, b_status, block_a, block_b, 
                              base_predictions, parent_block):
        """
        æ‰§è¡Œåˆ†å‰²å†³ç­–
        """
        new_blocks = []
        
        # å¤„ç†block_a
        if a_status == "ALL_GOOD":
            predictions = {aid: base_predictions[aid] for aid in block_a}
            self.task_manager.confirm_accounts(block_a, predictions)
            
        elif a_status == "ALL_BAD":
            predictions = {aid: 1 - base_predictions[aid] for aid in block_a}
            self.task_manager.confirm_accounts(block_a, predictions)
            
        else:  # "MIXED"
            if len(block_a) > 1:
                mid_a = len(block_a) // 2
                new_blocks.append(Block(
                    generate_block_id(),
                    block_a[:mid_a],
                    parent_block.layer_id,
                    parent_block.priority,
                    parent_block.id
                ))
                new_blocks.append(Block(
                    generate_block_id(),
                    block_a[mid_a:],
                    parent_block.layer_id,
                    parent_block.priority,
                    parent_block.id
                ))
        
        # å¤„ç†block_b
        if b_status == "ALL_GOOD":
            predictions = {aid: base_predictions[aid] for aid in block_b}
            self.task_manager.confirm_accounts(block_b, predictions)
            
        elif b_status == "ALL_BAD":
            predictions = {aid: 1 - base_predictions[aid] for aid in block_b}
            self.task_manager.confirm_accounts(block_b, predictions)
            
        else:  # "MIXED"
            if len(block_b) > 1:
                mid_b = len(block_b) // 2
                new_blocks.append(Block(
                    generate_block_id(),
                    block_b[:mid_b],
                    parent_block.layer_id,
                    parent_block.priority,
                    parent_block.id
                ))
                new_blocks.append(Block(
                    generate_block_id(),
                    block_b[mid_b:],
                    parent_block.layer_id,
                    parent_block.priority,
                    parent_block.id
                ))
        
        return new_blocks

    def _process_single_account(self, block: Block, worker_id: int) -> str:
        """å¤„ç†å•ä¸ªè´¦æˆ·"""
        account_id = block.accounts[0]
        
        base_predictions = self.task_manager.get_global_predictions_copy()
        current_pred = base_predictions[account_id]

        # æµ‹è¯•åŸå§‹é¢„æµ‹
        f1_original = self._test_predictions(base_predictions, f"å•è´¦æˆ·{account_id}åŸå€¼", worker_id)
        # æµ‹è¯•ç¿»è½¬é¢„æµ‹
        flipped_predictions = self._create_test_batch_predictions(base_predictions, [account_id], flip=True)
        f1_flipped = self._test_predictions(flipped_predictions, f"å•è´¦æˆ·{account_id}ç¿»è½¬", worker_id)

        if f1_flipped is None or f1_original is None:
            print(f"âŒ Worker-{worker_id} å•è´¦æˆ·{account_id}æµ‹è¯•å¤±è´¥")
            return "SINGLE_FAILED"

        if f1_flipped > f1_original:
            new_pred = 1 - current_pred
            predictions = {account_id: new_pred}
            self.task_manager.confirm_accounts([account_id], predictions)
            result_type = "SINGLE_FLIPPED"
        else:
            predictions = {account_id: current_pred}
            self.task_manager.confirm_accounts([account_id], predictions)
            result_type = "SINGLE_CONFIRMED"

        self.task_manager.complete_block(block.id, result_type)
        return result_type
    
    def _process_batch_binary(self, block: Block, worker_id: int) -> str:
        """å¤„ç†æ‰¹æ¬¡äºŒåˆ†"""
        
        # äºŒåˆ†è´¦æˆ·åˆ—è¡¨
        mid_point = block.size // 2
        batch_A = block.accounts[:mid_point]
        batch_B = block.accounts[mid_point:]
        
        # ä½¿ç”¨æ–°çš„æ··æ·†çŸ©é˜µåˆ†ææ–¹æ³•
        decision, new_blocks = self._test_binary_split_confusion_based(
            batch_A, batch_B, block, worker_id
        )
        
        # å®Œæˆå¤„ç†å¹¶æ·»åŠ æ–°å—
        self.task_manager.complete_block(block.id, decision, new_blocks)
        
        return decision
    
    def _test_binary_split_confusion_based(self, batch_A: List[str], batch_B: List[str], 
                                         parent_block: Block, worker_id: int) -> Tuple[str, List[Block]]:
        """
        åŸºäºæ··æ·†çŸ©é˜µåˆ†æçš„äºŒåˆ†æµ‹è¯•
        
        Returns:
            (å†³ç­–ç»“æœ, æ–°äº§ç”Ÿçš„blocksåˆ—è¡¨)
        """
        
        base_predictions = self.task_manager.get_global_predictions_copy()
        
        # æµ‹è¯•åŸºå‡†
        f1_baseline = self._test_predictions(base_predictions, f"Block{parent_block.id[:8]}åŸºå‡†", worker_id)
        if f1_baseline is None:
            print(f"âŒ Worker-{worker_id} è·å–åŸºå‡†F1å¤±è´¥")
            return "BASELINE_FAILED", []
        
        # æµ‹è¯•batch_Bç¿»è½¬ï¼ˆæˆ‘ä»¬åˆ†æbatch_Bï¼‰
        B_flipped_predictions = self._create_test_batch_predictions(base_predictions, batch_B, flip=True)
        f1_B_flipped = self._test_predictions(B_flipped_predictions, f"BatchBç¿»è½¬", worker_id)
        if f1_B_flipped is None:
            print(f"âŒ Worker-{worker_id} BatchBç¿»è½¬æµ‹è¯•å¤±è´¥")
            return "BATCH_B_FAILED", []
        
        # è·å–æ··æ·†çŸ©é˜µ
        predicted_bad_baseline = sum(base_predictions.values())
        predicted_bad_B_flipped = predicted_bad_baseline
        for aid in batch_B:
            if base_predictions[aid] == 1:  # åŸæ¥æ˜¯badï¼Œç¿»è½¬åæ˜¯good
                predicted_bad_B_flipped -= 1
            else:  # åŸæ¥æ˜¯goodï¼Œç¿»è½¬åæ˜¯bad
                predicted_bad_B_flipped += 1
        
        confusion_baseline = calculate_confusion_from_f1(f1_baseline, predicted_bad_baseline)
        confusion_B_flipped = calculate_confusion_from_f1(f1_B_flipped, predicted_bad_B_flipped)
        
        if not confusion_baseline or not confusion_B_flipped:
            print(f"âŒ Worker-{worker_id} æ··æ·†çŸ©é˜µè®¡ç®—å¤±è´¥")
            return "CONFUSION_FAILED", []
        
        # è·å–å±‚åŸºå‡†ä¿¡æ¯
        layer_info = self.layer_baselines[parent_block.layer_id]
        total_good = layer_info['good']
        total_bad = layer_info['bad']
        
        # åˆ†æäºŒåˆ†ç»“æœå¹¶è·å–ç»Ÿè®¡ä¿¡æ¯
        a_status, b_status, block_stats = self.analyze_binary_split(
            confusion_baseline, confusion_B_flipped, len(batch_B), total_good, total_bad,
            base_predictions, parent_block
        )
        
        # ğŸ“ æ˜¾ç¤ºçŠ¶æ€ - åªæ˜¾ç¤ºå½“å‰å¤„ç†å’Œå¾…å¤„ç†çš„blocks
        account_status = self.task_manager.get_account_status_copy()
        confirmed_good = sum(1 for s in account_status.values() if s == 0)
        confirmed_bad = sum(1 for s in account_status.values() if s == 1)
        unconfirmed = sum(1 for s in account_status.values() if s == -1)
        
        # è·å–å¾…å¤„ç†blocksé¢„è§ˆ
        pending_blocks = self.task_manager.get_pending_blocks_preview(3)
        
        print_status(confirmed_good, confirmed_bad, unconfirmed,
                     block_stats['pred_good'], block_stats['pred_bad'], 
                     block_stats['correct'], 0,  # å½“å‰blockæ­£ç¡®é¢„æµ‹çš„goodå’Œbad
                     block_stats['wrong'], 0,     # å½“å‰blocké”™è¯¯é¢„æµ‹çš„goodå’Œbad
                     f1_baseline, worker_id, f"Block {parent_block.id[:8]} åŸºå‡†çŠ¶æ€",
                     current_block=parent_block, pending_blocks=pending_blocks)
        
        # æ‰§è¡Œå†³ç­–
        new_blocks = self.execute_split_decisions(
            a_status, b_status, batch_A, batch_B, base_predictions, parent_block
        )
        
        decision_summary = f"A_{a_status}_B_{b_status}"
        
        return decision_summary, new_blocks


def main():
    print("=== å¹¶è¡ŒäºŒåˆ†æ³•ä¼˜åŒ–ç³»ç»Ÿ ===")
    
    # 1. åˆå§‹åŒ–TaskManager
    task_manager = TaskManager()
    
    # 2. å°è¯•æ¢å¤çŠ¶æ€
    if task_manager.load_state():
        print("ğŸ“‚ ä»ä¿å­˜çŠ¶æ€æ¢å¤")
    else:
        print("ğŸ†• ä»å¤´å¼€å§‹")
        
        # 3. è¯»å–æ•°æ®å¹¶åˆå§‹åŒ–
        scores_df = pd.read_csv("/Users/mannormal/4011/account_scores.csv")
        initialize_global_state(task_manager, scores_df)
        create_initial_blocks(task_manager, scores_df)
    
    # 4. å¯åŠ¨å·¥ä½œçº¿ç¨‹æ± 
    print("\nğŸ­ å¯åŠ¨å·¥ä½œçº¿ç¨‹æ± ...")
    num_workers = 10
    workers = []
    
    for worker_id in range(num_workers):
        preferred_layer = (worker_id % 5) + 1
        
        worker = threading.Thread(
            target=worker_thread,
            args=(worker_id, preferred_layer, task_manager),
            daemon=True
        )
        worker.start()
        workers.append(worker)
    
    print(f"âœ… å¯åŠ¨{num_workers}ä¸ªå·¥ä½œçº¿ç¨‹")
    
    # 5. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    for worker in workers:
        worker.join()
    
    # 6. æµ‹è¯•æœ€ç»ˆç»“æœ
    final_f1 = test_final_result(task_manager)
    
    # 7. ä¿å­˜ç»“æœ
    save_final_result(task_manager, final_f1)
    
    print(f"âœ… ä¼˜åŒ–å®Œæˆ: F1={final_f1:.6f}")


def initialize_global_state(task_manager, scores_df):
    """åˆå§‹åŒ–å…¨å±€é¢„æµ‹çŠ¶æ€"""
    global_predictions = {}
    account_status = {}
    
    for _, row in scores_df.iterrows():
        account_id = row['ID']
        # åˆå§‹é¢„æµ‹åŸºäº0.5é˜ˆå€¼
        global_predictions[account_id] = 1 if row['predict'] > 0.5 else 0
        account_status[account_id] = -1  # æœªç¡®è®¤
    
    task_manager.update_global_predictions(global_predictions)
    task_manager.update_account_status(account_status)


def create_initial_blocks(task_manager, scores_df):
    """åˆ›å»º5å±‚åˆå§‹Block"""
    layers = [
        {"id": 1, "range": (0.0, 0.1), "info": {'bad': 154, 'good': 6626}},
        {"id": 2, "range": (0.1, 0.2), "info": {'bad': 30, 'good': 45}},
        {"id": 3, "range": (0.2, 0.5), "info": {'bad': 43, 'good': 61}},
        {"id": 4, "range": (0.5, 0.8), "info": {'bad': 51, 'good': 62}},
        {"id": 5, "range": (0.8, 1.0), "info": {'bad': 449, 'good': 37}}
    ]
    
    for layer in layers:
        # è·å–å±‚å†…è´¦æˆ·
        min_score, max_score = layer["range"]
        if max_score == 1.0:
            layer_df = scores_df[(scores_df['predict'] >= min_score) & (scores_df['predict'] <= max_score)]
        else:
            layer_df = scores_df[(scores_df['predict'] >= min_score) & (scores_df['predict'] < max_score)]
        
        layer_accounts = layer_df['ID'].tolist()
        
        if len(layer_accounts) > 0:
            block = Block(
                id=generate_block_id(),
                accounts=layer_accounts,
                layer_id=layer['id'],
                priority=layer['id']
            )
            task_manager.add_block(block)
            print(f"âœ… åˆ›å»ºLayer {layer['id']}: {len(layer_accounts)}ä¸ªè´¦æˆ·")


def worker_thread(worker_id: int, preferred_layer_id: int, task_manager: TaskManager):
    """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
    thread_name = f"Worker-{worker_id}"
    threading.current_thread().name = thread_name
    
    print(f"ğŸš€ {thread_name} å¯åŠ¨ (ä¼˜å…ˆLayer {preferred_layer_id})")
    
    optimizer = BinaryOptimizer(task_manager)
    processed_count = 0
    idle_count = 0
    max_idle = 30  # æœ€å¤§ç©ºé—²æ¬¡æ•°
    
    try:
        while not task_manager.is_all_complete():
            # è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡
            block = task_manager.get_next_task(preferred_layer_id, timeout=2.0)
            
            if block is None:
                idle_count += 1
                if idle_count >= max_idle:
                    if task_manager.is_all_complete():
                        break
                    idle_count = 0  # é‡ç½®è®¡æ•°å™¨
                
                time.sleep(1)  # çŸ­æš‚ä¼‘æ¯
                continue
            
            idle_count = 0  # é‡ç½®ç©ºé—²è®¡æ•°
            
            # å¤„ç†block
            try:
                result = optimizer.process_block(block, worker_id)
                processed_count += 1
                
                if processed_count % 10 == 0:  # æ¯å¤„ç†10ä¸ªä»»åŠ¡æ‰“å°ä¸€æ¬¡ç»Ÿè®¡
                    stats = task_manager.get_stats()
                    print()
                    print()
                    print()
                    print(f"ğŸ“Š {thread_name} å·²å¤„ç†{processed_count}ä¸ªä»»åŠ¡, "
                          f"å…¨å±€è¿›åº¦: {stats['confirmed_accounts']}/{stats['total_accounts']} "
                          f"({stats['completion_rate']:.1%})")
                    print()
                    print()
                    print()
                
            except Exception as e:
                print(f"âŒ {thread_name} å¤„ç†Block {block.id[:8]}æ—¶å‡ºé”™: {e}")
                # æ ‡è®°å¤„ç†å¤±è´¥ï¼Œä½†ç»§ç»­å·¥ä½œ
                task_manager.complete_block(block.id, "PROCESSING_ERROR")
    
    except Exception as e:
        print(f"âŒ {thread_name} å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
    
    finally:
        print(f"ğŸ {thread_name} é€€å‡ºï¼Œå…±å¤„ç†{processed_count}ä¸ªä»»åŠ¡")


def save_predictions_to_csv(predictions: dict, filepath: str):
    """ä¿å­˜é¢„æµ‹ç»“æœåˆ°CSVæ–‡ä»¶"""
    import pandas as pd
    import os
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    predictions_list = [{"ID": aid, "Predict": pred} for aid, pred in predictions.items()]
    df = pd.DataFrame(predictions_list)
    df.to_csv(filepath, index=False)


def test_final_result(task_manager: TaskManager) -> float:
    """æµ‹è¯•æœ€ç»ˆç»“æœ"""
    print("ğŸ§ª æµ‹è¯•æœ€ç»ˆç»“æœ...")
    final_predictions = task_manager.get_global_predictions_copy()
    temp_file = "/Users/mannormal/4011/Qi Zihan/v4/temp/final_test.csv"
    save_predictions_to_csv(final_predictions, temp_file)
    f1_score = upload_file(temp_file)
    try:
        import os
        os.remove(temp_file)
    except:
        pass
    if f1_score is not None:
        print(f"ğŸ¯ æœ€ç»ˆF1åˆ†æ•°: {f1_score:.6f}")
    else:
        print("âŒ æœ€ç»ˆç»“æœæµ‹è¯•å¤±è´¥")
    return f1_score


def save_final_result(task_manager, f1_score):
    """ä¿å­˜æœ€ç»ˆç»“æœ"""
    final_predictions = task_manager.get_global_predictions_copy()
    
    # ä¿å­˜ç»“æœ
    timestamp = int(time.time())
    result_path = f"/Users/mannormal/4011/Qi Zihan/v4/parallel_result_{timestamp}.csv"
    save_predictions_to_csv(final_predictions, result_path)
    
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {result_path}")


if __name__ == "__main__":
    main()