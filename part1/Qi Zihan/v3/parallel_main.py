#!/usr/bin/env python3
"""
V3å¹¶è¡Œä¸»ç¨‹åº - å¹¶è¡Œå¢å¼ºçš„äºŒåˆ†æ³•ä¼˜åŒ–ç³»ç»Ÿ
åŸºäºmain.pyï¼Œæ·»åŠ å¹¶è¡Œå¤„ç†åŠŸèƒ½
"""

import os
import pandas as pd
import copy
import concurrent.futures
import threading
import time
import uuid
#from robust_upload_module import robust_upload_with_retry as upload_file
from simulator import simulate_f1 as upload_file
from confusion_calculator import calculate_confusion_from_f1
# ä½¿ç”¨å†…ç½®çš„å¹¶è¡Œblockå¤„ç†


# å…¨å±€çŠ¶æ€é”ï¼Œé˜²æ­¢çº¿ç¨‹ç«äº‰
state_lock = threading.Lock()

class ParallelStatusManager:
    """å¹¶è¡Œå¤„ç†çŠ¶æ€ç®¡ç†å™¨ - çº¿ç¨‹å®‰å…¨"""
    
    def __init__(self):
        self.block_status = {}
        self.status_lock = threading.Lock()
        self.session_dir = None
        
    def create_session_dir(self):
        """åˆ›å»ºsessionçº§åˆ«çš„ä¸´æ—¶æ–‡ä»¶ç›®å½•"""
        import datetime
        import shutil
        
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        self.session_dir = f"/Users/mannormal/4011/Qi Zihan/v3/sessions/parallel_{timestamp}"
        os.makedirs(self.session_dir, exist_ok=True)
        print(f"ğŸ“ åˆ›å»ºsessionç›®å½•: {self.session_dir}")
        return self.session_dir
    
    def cleanup_session(self):
        """æ¸…ç†sessionç›®å½•"""
        if self.session_dir and os.path.exists(self.session_dir):
            import shutil
            try:
                shutil.rmtree(self.session_dir)
                print(f"ğŸ—‘ï¸ æ¸…ç†sessionç›®å½•: {self.session_dir}")
            except Exception as e:
                print(f"âŒ æ¸…ç†sessionç›®å½•å¤±è´¥: {e}")
    
    def update_block_status(self, block_id, status_info):
        """æ›´æ–°blockçŠ¶æ€"""
        with self.status_lock:
            self.block_status[block_id] = status_info
    
    def get_block_status(self, block_id):
        """è·å–blockçŠ¶æ€"""
        with self.status_lock:
            return self.block_status.get(block_id, {})
    
    def get_all_status(self):
        """è·å–æ‰€æœ‰blockçŠ¶æ€"""
        with self.status_lock:
            return self.block_status.copy()
    
    def format_block_summary(self, processing_stack, current_predictions=None, upload_func=None):
        """æ ¼å¼åŒ–blockçŠ¶æ€æ‘˜è¦ï¼Œæ˜¾ç¤ºåŸºäºF1çš„çœŸå®Good/Badåˆ†ç±»æƒ…å†µ"""
        with self.status_lock:
            if not processing_stack:
                return "  å½“å‰æ— å¾…å¤„ç†blocks"
            
            lines = [f"  å½“å‰æœ‰ {len(processing_stack)} ä¸ªå¾…å¤„ç†blocks:"]
            
            # æ˜¾ç¤ºæ€»ä½“çœŸå®åˆ†ç±»æƒ…å†µï¼ˆé€šè¿‡F1æ¨ç®—ï¼‰
            if current_predictions and upload_func:
                try:
                    current_f1 = test_predictions_f1(current_predictions, upload_func)
                    predicted_bad = sum(1 for pred in current_predictions.values() if pred == 1)
                    confusion = calculate_confusion_from_f1(current_f1, predicted_bad)
                    
                    if confusion:
                        correct_good = confusion['TN']  # æ­£ç¡®åˆ†ç±»çš„Good
                        correct_bad = confusion['TP']   # æ­£ç¡®åˆ†ç±»çš„Bad
                        wrong_good = confusion['FN']    # é”™è¯¯åˆ†ç±»çš„Good (å®é™…æ˜¯Bad)
                        wrong_bad = confusion['FP']     # é”™è¯¯åˆ†ç±»çš„Bad (å®é™…æ˜¯Good)
                        
                        lines.append(f"  ğŸ“Š å½“å‰åˆ†ç±»çŠ¶å†µ (F1={current_f1:.4f}):")
                        lines.append(f"      âœ… æ­£ç¡®: Good={correct_good}, Bad={correct_bad}")
                        lines.append(f"      âŒ é”™è¯¯: FP={wrong_bad}, FN={wrong_good}")
                except:
                    # F1è®¡ç®—å¤±è´¥ï¼Œæ˜¾ç¤ºé¢„æµ‹åˆ†å¸ƒ
                    predicted_good = sum(1 for pred in current_predictions.values() if pred == 0)
                    predicted_bad = sum(1 for pred in current_predictions.values() if pred == 1)
                    lines.append(f"  ğŸ“Š å½“å‰é¢„æµ‹åˆ†å¸ƒ: Good={predicted_good}, Bad={predicted_bad}")
            
            for i, block in enumerate(processing_stack):
                # åªæ˜¾ç¤ºblockå¤§å°ï¼Œé¿å…æ··ä¹±
                if i == 0:
                    lines.append(f"    - Block[æ­£åœ¨å¤„ç†]: {len(block)} ä¸ªè´¦æˆ· â† å½“å‰å¤„ç†")
                else:
                    lines.append(f"    - Block[å¾…å¤„ç†-{i}]: {len(block)} ä¸ªè´¦æˆ·")
            
            return "\n".join(lines)
    
    def format_parallel_progress(self, confirmed_count=None, total_count=None):
        """æ ¼å¼åŒ–å¹¶è¡Œå¤„ç†è¿›åº¦ï¼Œåªæ˜¾ç¤ºåŸºæœ¬å¯é ä¿¡æ¯"""
        # åªæ˜¾ç¤ºæ€»ä½“è¿›åº¦ï¼Œä¸æ˜¾ç¤ºå¯èƒ½æœ‰é”™è¯¯çš„è¯¦ç»†çŠ¶æ€
        if confirmed_count is not None and total_count is not None:
            progress_pct = (confirmed_count / total_count * 100) if total_count > 0 else 0
            return f"ğŸ“ˆ æ€»ä½“è¿›åº¦: {confirmed_count}/{total_count} ({progress_pct:.1f}%) å·²ç¡®è®¤"
        else:
            return "ğŸ“ˆ å¹¶è¡Œå¤„ç†è¿›è¡Œä¸­..."
    
    def update_block_predictions(self, block_id, current_predictions, block_accounts):
        """æ›´æ–°blockçš„é¢„æµ‹åˆ†å¸ƒä¿¡æ¯"""
        good_count = sum(1 for aid in block_accounts if current_predictions.get(aid, 0) == 0)
        bad_count = sum(1 for aid in block_accounts if current_predictions.get(aid, 0) == 1)
        
        with self.status_lock:
            if block_id in self.block_status:
                self.block_status[block_id]['good_pred'] = good_count
                self.block_status[block_id]['bad_pred'] = bad_count

# å…¨å±€çŠ¶æ€ç®¡ç†å™¨
status_manager = ParallelStatusManager()

def parallel_binary_optimize_accounts(account_list, current_predictions, upload_func, max_iterations=None, max_workers=10):
    """
    å¹¶è¡ŒäºŒåˆ†æ³•ä¼˜åŒ– - æ¯ä¸ªblockä½œä¸ºä¸€ä¸ªtask
    
    Args:
        account_list (list): è¦ä¼˜åŒ–çš„è´¦æˆ·IDåˆ—è¡¨
        current_predictions (dict): å½“å‰æ‰€æœ‰è´¦æˆ·çš„é¢„æµ‹
        upload_func (function): ä¸Šä¼ å‡½æ•°
        max_iterations (int): æœ€å¤§è¿­ä»£æ¬¡æ•°
        max_workers (int): æœ€å¤§å¹¶è¡Œworkeræ•°é‡
    
    Returns:
        tuple: (ä¼˜åŒ–åçš„é¢„æµ‹ç»“æœ, ç¡®è®¤çŠ¶æ€)
    """
    
    print(f"=== å¹¶è¡ŒäºŒåˆ†æ³•ä¼˜åŒ– ===")
    print(f"ä¼˜åŒ–è´¦æˆ·æ•°: {len(account_list)}")
    print(f"æœ€å¤§workers: {max_workers}")
    
    # åˆ›å»ºsessionç›®å½•
    session_dir = status_manager.create_session_dir()
    
    try:
        # åˆå§‹åŒ–
        optimized_predictions = copy.deepcopy(current_predictions)
        processing_stack = [account_list.copy()]
        iteration = 0
        
        # ç¡®è®¤çŠ¶æ€
        account_status = {}
        for account_id in account_list:
            account_status[account_id] = -1
        
        # ä¸»å¾ªç¯
        while processing_stack and (max_iterations is None or iteration < max_iterations):
            iteration += 1
            
            print(f"\n--- è¿­ä»£ {iteration} ---")
            print(f"å¾…å¤„ç†blocks: {len(processing_stack)}")
            
            # æ˜¾ç¤ºå½“å‰blockçŠ¶æ€ï¼ˆä»¿ç…§main.pyæ ¼å¼ï¼‰
            block_summary = status_manager.format_block_summary(processing_stack, optimized_predictions, upload_func)
            print(block_summary)
            
            # æ ¹æ®blockæ•°é‡é€‰æ‹©å¤„ç†ç­–ç•¥
            if len(processing_stack) >= 2:
                # å¹¶è¡Œå¤„ç†å¤šä¸ªblocks
                print(f"ğŸš€ å¯åŠ¨å¹¶è¡Œå¤„ç† {len(processing_stack)} ä¸ªblocks (max_workers={max_workers})")
                
                new_blocks = []
                with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                    # æäº¤æ‰€æœ‰blockä»»åŠ¡
                    future_to_block = {}
                    for i, block in enumerate(processing_stack):
                        block_id = f"Block-{i+1}"
                        
                        future = executor.submit(
                            process_single_block, 
                            block, 
                            optimized_predictions.copy(), 
                            upload_func,
                            block_id
                        )
                        future_to_block[future] = (block, i+1)
                    
                    # æ”¶é›†ç»“æœ
                    for future in concurrent.futures.as_completed(future_to_block):
                        block, block_num = future_to_block[future]
                        try:
                            result = future.result()
                            if result:
                                decision = result['decision']
                                
                                if decision == "continue_binary":
                                    # éœ€è¦ç»§ç»­äºŒåˆ†
                                    new_blocks.extend(result['new_blocks'])
                                    
                                elif decision in ["confirmed", "partial_confirmed"]:
                                    # å·²ç¡®è®¤çš„accounts
                                    with state_lock:
                                        for account_id in result['confirmed_accounts']:
                                            optimized_predictions[account_id] = result['predictions'][account_id]
                                            account_status[account_id] = result['predictions'][account_id]
                                    
                                    # éƒ¨åˆ†ç¡®è®¤è¿˜æœ‰å‰©ä½™blocks
                                    if decision == "partial_confirmed" and result.get('new_blocks'):
                                        new_blocks.extend(result['new_blocks'])
                                
                                # ç®€åŒ–çŠ¶æ€æ›´æ–°ï¼Œä¸æ˜¾ç¤ºå¯èƒ½é”™è¯¯çš„ä¿¡æ¯
                                pass
                            
                        except Exception as e:
                            print(f"âŒ Block-{block_num} å¤„ç†å¤±è´¥: {e}")
                            # å¤±è´¥å¤„ç†ï¼šåˆ†è§£ä¸ºæ›´å°blocks
                            if len(block) > 1:
                                new_blocks.extend([[account] for account in block])
                            else:
                                # å•è´¦æˆ·å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                                with state_lock:
                                    optimized_predictions[block[0]] = current_predictions[block[0]]
                                    account_status[block[0]] = current_predictions[block[0]]
                
                # æ›´æ–°å¤„ç†æ ˆ
                processing_stack = new_blocks
                
                # æ˜¾ç¤ºå¹¶è¡Œå¤„ç†çŠ¶æ€
                confirmed_count = sum(1 for status in account_status.values() if status != -1)
                progress = status_manager.format_parallel_progress(confirmed_count, len(account_list))
                print(progress)
                
            else:
                # ä¸²è¡Œå¤„ç†å•ä¸ªblock
                current_block = processing_stack.pop(0)
                result = process_single_block(current_block, optimized_predictions, upload_func, "Single")
                
                if result:
                    decision = result['decision']
                    
                    if decision == "continue_binary":
                        processing_stack.extend(result['new_blocks'])
                        
                    elif decision in ["confirmed", "partial_confirmed"]:
                        # ç¡®è®¤è´¦æˆ·
                        for account_id in result['confirmed_accounts']:
                            optimized_predictions[account_id] = result['predictions'][account_id]
                            account_status[account_id] = result['predictions'][account_id]
                        
                        # éƒ¨åˆ†ç¡®è®¤çš„å‰©ä½™blocks
                        if decision == "partial_confirmed" and result.get('new_blocks'):
                            processing_stack.extend(result['new_blocks'])
            
            # æ˜¾ç¤ºè¿›åº¦
            confirmed_count = sum(1 for status in account_status.values() if status != -1)
            print(f"ğŸ“ˆ è¿­ä»£{iteration}: ç¡®è®¤ {confirmed_count}/{len(account_list)}")
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if confirmed_count == len(account_list):
                print("ğŸ‰ æ‰€æœ‰è´¦æˆ·å·²ç¡®è®¤å®Œæˆ!")
                break
        
        print(f"\n=== å¹¶è¡Œä¼˜åŒ–å®Œæˆ ===")
        print(f"æ€»è¿­ä»£æ¬¡æ•°: {iteration}")
        print(f"å·²ç¡®è®¤è´¦æˆ·: {confirmed_count}/{len(account_list)}")
        
        return optimized_predictions, account_status
        
    finally:
        # ç¡®ä¿æ¸…ç†sessionç›®å½•
        status_manager.cleanup_session()

def process_single_block(block, current_predictions, upload_func, block_name):
    """
    å¤„ç†å•ä¸ªblockçš„å‡½æ•° - åŸºäºbaselineå’ŒF1æ··æ·†çŸ©é˜µæ¯”è¾ƒ
    
    Args:
        block (list): è´¦æˆ·IDåˆ—è¡¨
        current_predictions (dict): å½“å‰é¢„æµ‹
        upload_func (function): ä¸Šä¼ å‡½æ•°
        block_name (str): blockåç§°
    
    Returns:
        dict: å¤„ç†ç»“æœ
    """
    
    # å•ä¸ªè´¦æˆ·æµ‹è¯•ä¸¤ç§æƒ…å†µé€‰æ‹©æ›´å¥½çš„
    if len(block) == 1:
        account_id = block[0]
        
        # æµ‹è¯•ä¿æŒå½“å‰é¢„æµ‹
        current_f1 = test_predictions_f1(current_predictions, upload_func)
        
        # æµ‹è¯•ç¿»è½¬è¿™ä¸ªè´¦æˆ·
        flipped_predictions = current_predictions.copy()
        flipped_predictions[account_id] = 1 - flipped_predictions[account_id]
        flipped_f1 = test_predictions_f1(flipped_predictions, upload_func)
        
        # é€‰æ‹©F1æ›´é«˜çš„é¢„æµ‹
        if flipped_f1 > current_f1:
            return {
                'decision': 'confirmed',
                'confirmed_accounts': [account_id],
                'predictions': {account_id: flipped_predictions[account_id]}
            }
        else:
            return {
                'decision': 'confirmed',
                'confirmed_accounts': [account_id],
                'predictions': {account_id: current_predictions[account_id]}
            }
    
    try:
        # è®¡ç®—baselineï¼ˆå½“å‰é¢„æµ‹çŠ¶æ€ï¼‰
        baseline_f1 = test_predictions_f1(current_predictions, upload_func)
        baseline_bad_count = sum(1 for pred in current_predictions.values() if pred == 1)
        baseline_confusion = calculate_confusion_from_f1(baseline_f1, baseline_bad_count)
        
        if not baseline_confusion:
            print(f"âŒ [{block_name}] æ— æ³•è®¡ç®—baselineæ··æ·†çŸ©é˜µ")
            return {
                'decision': 'continue_binary',
                'new_blocks': [block],
                'confirmed_accounts': [],
                'predictions': {}
            }
        
        baseline_correct = baseline_confusion['TP'] + baseline_confusion['TN']
        
        # æµ‹è¯•ç¿»è½¬å½“å‰blockåçš„æ•ˆæœ
        test_predictions = current_predictions.copy()
        for account_id in block:
            test_predictions[account_id] = 1 - test_predictions[account_id]
        
        test_f1 = test_predictions_f1(test_predictions, upload_func)
        test_bad_count = sum(1 for pred in test_predictions.values() if pred == 1)
        test_confusion = calculate_confusion_from_f1(test_f1, test_bad_count)
        
        if not test_confusion:
            print(f"âŒ [{block_name}] æ— æ³•è®¡ç®—testæ··æ·†çŸ©é˜µ")
            return {
                'decision': 'continue_binary',
                'new_blocks': [block],
                'confirmed_accounts': [],
                'predictions': {}
            }
        
        test_correct = test_confusion['TP'] + test_confusion['TN']
        total_accounts = len(current_predictions)  # æ€»è´¦æˆ·æ•°7558
        
        # å†³ç­–é€»è¾‘ï¼šæ£€æŸ¥æ˜¯å¦è¾¾åˆ°å®Œç¾åˆ†ç±»æˆ–æœ‰æå‡
        if test_correct == total_accounts:
            # ç¿»è½¬åè¾¾åˆ°å®Œç¾åˆ†ç±»ï¼Œç¿»è½¬å¹¶ç¡®è®¤æ•´ä¸ªblock
            confirmed_predictions = {}
            for account_id in block:
                confirmed_predictions[account_id] = 1 - current_predictions[account_id]
            
            return {
                'decision': 'confirmed',
                'confirmed_accounts': block,
                'predictions': confirmed_predictions
            }
        elif baseline_correct == total_accounts:
            # å½“å‰å·²ç»å®Œç¾åˆ†ç±»ï¼Œä¿æŒå¹¶ç¡®è®¤æ•´ä¸ªblock
            return {
                'decision': 'confirmed',
                'confirmed_accounts': block,
                'predictions': {aid: current_predictions[aid] for aid in block}
            }
        elif test_correct > baseline_correct:
            # ç¿»è½¬åæœ‰æå‡ä½†ä¸å®Œç¾ï¼Œéœ€è¦ç»§ç»­äºŒåˆ†æ‰¾åˆ°æœ€ä¼˜å­é›†
            # ä¸èƒ½ç›´æ¥ç¡®è®¤æ•´ä¸ªblockï¼Œè¦ç»§ç»­ç»†åˆ†
            mid = len(block) // 2
            block_a = block[:mid]
            block_b = block[mid:]
            
            return {
                'decision': 'continue_binary',
                'new_blocks': [block_a, block_b] if block_b else [block_a],
                'confirmed_accounts': [],
                'predictions': {}
            }
        else:
            # ç¿»è½¬åæ— æå‡ï¼Œç»§ç»­äºŒåˆ†è¿™ä¸ªblock
            mid = len(block) // 2
            block_a = block[:mid]
            block_b = block[mid:]
            
            return {
                'decision': 'continue_binary',
                'new_blocks': [block_a, block_b] if block_b else [block_a],
                'confirmed_accounts': [],
                'predictions': {}
            }
    
    except Exception as e:
        print(f"âŒ [{block_name}] å¤„ç†å¤±è´¥: {e}")
        return {
            'decision': 'continue_binary',
            'new_blocks': [block],
            'confirmed_accounts': [],
            'predictions': {}
        }

def test_predictions_f1(predictions_dict, upload_func):
    """
    æµ‹è¯•é¢„æµ‹ç»“æœçš„F1åˆ†æ•°
    
    Args:
        predictions_dict (dict): é¢„æµ‹ç»“æœ
        upload_func (function): ä¸Šä¼ å‡½æ•°
    
    Returns:
        float: F1åˆ†æ•°ï¼Œå¤±è´¥è¿”å›0
    """
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        unique_id = f"{int(time.time()*1000000)}_{uuid.uuid4().hex[:8]}"
        session_dir = status_manager.session_dir or "/Users/mannormal/4011/Qi Zihan/v3"
        temp_file = f"{session_dir}/test_f1_{unique_id}.csv"
        
        predictions_list = []
        for account_id, predict in predictions_dict.items():
            predictions_list.append({"ID": account_id, "Predict": predict})
        
        df = pd.DataFrame(predictions_list)
        df.to_csv(temp_file, index=False)
        
        # ä¸Šä¼ æµ‹è¯•
        f1_score = upload_func(temp_file)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_file):
            os.remove(temp_file)
        
        return f1_score if f1_score is not None else 0
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•F1å¤±è´¥: {e}")
        return 0

def save_best_result(predictions_dict, f1_score, output_dir="/Users/mannormal/4011/Qi Zihan/v3/para"):
    """
    ä¿å­˜æœ€ä½³ç»“æœï¼Œæ–‡ä»¶åæ ¼å¼: v{score}.csvn
    
    Args:
        predictions_dict (dict): é¢„æµ‹ç»“æœ {account_id: 0/1}
        f1_score (float): F1åˆ†æ•°
        output_dir (str): è¾“å‡ºç›®å½•
    
    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    
    # åˆ›å»ºDataFrame
    predictions_list = []
    for account_id, predict in predictions_dict.items():
        predictions_list.append({"ID": account_id, "Predict": predict})
    
    df = pd.DataFrame(predictions_list)
    
    # ç”Ÿæˆæ–‡ä»¶åï¼ˆå¹¶è¡Œç‰ˆæœ¬ï¼‰
    score_str = f"{f1_score:.8f}".replace(".", "")[:8]  # å–å‰8ä½æ•°å­—
    filename = f"parallel_v{score_str}ensemble.csv"
    filepath = os.path.join(output_dir, filename)
    
    # ä¿å­˜æ–‡ä»¶
    df.to_csv(filepath, index=False)
    
    print(f"ğŸ’¾ ä¿å­˜æœ€ä½³ç»“æœ: {filename}")
    print(f"  F1åˆ†æ•°: {f1_score:.6f}")
    print(f"  é¢„æµ‹Bad: {len(df[df['Predict'] == 1])}")
    print(f"  é¢„æµ‹Good: {len(df[df['Predict'] == 0])}")
    
    return filepath

def load_initial_predictions():
    print("=== åˆ†å±‚äºŒåˆ†æ³•ä¼˜åŒ– ===")
    
    scores_df = pd.read_csv("/Users/mannormal/4011/account_scores.csv")
    
    layers = [
        {"id": 1, "name": "[0.0-0.1)", "range": (0.0, 0.1), "initial_guess": 0},
        {"id": 2, "name": "[0.1-0.2)", "range": (0.1, 0.2), "initial_guess": 0},
        {"id": 3, "name": "[0.2-0.5)", "range": (0.2, 0.5), "initial_guess": 0},
        {"id": 4, "name": "[0.5-0.8)", "range": (0.5, 0.8), "initial_guess": 1},
        {"id": 5, "name": "[0.8-1.0]", "range": (0.8, 1.0), "initial_guess": 1}
    ]
    layers.reverse()
    
    final_predictions = {}
    state_file = "/Users/mannormal/4011/Qi Zihan/v3/para/optimization_state_para.json"
    total_iterations = 0
    
    if os.path.exists(state_file):
        import json
        with open(state_file, 'r') as f:
            state = json.load(f)
        print(f"æ¢å¤çŠ¶æ€: ä»ç¬¬{state['current_layer']}å±‚å¼€å§‹")
        final_predictions = state['predictions']
        start_layer = state['current_layer']
        total_iterations = state.get('total_iterations', 0)
        print(f"å·²å®Œæˆæ€»è¿­ä»£æ¬¡æ•°: {total_iterations}")
    else:
        start_layer = 1
        final_predictions = {}
        total_iterations = 0
    
    for layer in layers:
        
        if layer['id'] < start_layer:
            continue
            
        print(f"\n=== å¤§è¿­ä»£ v{layer['id']}: {layer['name']} ===")
        
        min_score, max_score = layer["range"]
        if max_score == 1.0:
            layer_accounts = scores_df[(scores_df['predict'] >= min_score) & (scores_df['predict'] <= max_score)]
        else:
            layer_accounts = scores_df[(scores_df['predict'] >= min_score) & (scores_df['predict'] < max_score)]
        
        layer_account_ids = layer_accounts['ID'].tolist()
        print(f"å±‚å†…è´¦æˆ·æ•°: {len(layer_account_ids)}")
        
        if len(layer_account_ids) == 0:
            continue
        
        current_predictions = {}
        for account_id in scores_df['ID']:
            if account_id in final_predictions:
                # å·²ç¡®è®¤çš„è´¦æˆ·ä¿æŒç¡®è®¤çŠ¶æ€
                current_predictions[account_id] = final_predictions[account_id]
            elif account_id in layer_account_ids:
                # å½“å‰å±‚è´¦æˆ·è®¾ä¸ºåˆå§‹çŒœæµ‹ï¼ˆæœªç¡®è®¤çŠ¶æ€-1ä¼šåœ¨äºŒåˆ†æ³•ä¸­å¤„ç†ï¼‰
                current_predictions[account_id] = layer['initial_guess']
            else:
                # å…¶ä»–å±‚è´¦æˆ·è®¾ä¸ºç›¸åå€¼
                current_predictions[account_id] = 1 - layer['initial_guess']
        
        iteration = 1
        temp_file = f"/Users/mannormal/4011/Qi Zihan/v3/para/para_v{layer['id']}.{iteration}.csv"
        temp_df = pd.DataFrame([{"ID": aid, "Predict": pred} for aid, pred in current_predictions.items()])
        temp_df.to_csv(temp_file, index=False)
        
        layer_f1 = upload_file(temp_file)
        
        if layer_f1 is not None:
            predicted_bad = sum(current_predictions.values())
            confusion = calculate_confusion_from_f1(layer_f1, predicted_bad)
            
            if confusion:
                print(f"åˆå§‹F1={layer_f1:.6f}, TP={confusion['TP']}, FP={confusion['FP']}, FN={confusion['FN']}, TN={confusion['TN']}")
                
                # åŠ¨æ€è®¡ç®—è¿­ä»£æ¬¡æ•° (åŸºäºlog2 + ç¼“å†²)
                layer_iterations = max(5, int(len(layer_account_ids).bit_length()) + 3)
                print(f"è®¾ç½®è¿­ä»£æ¬¡æ•°: {layer_iterations} (åŸºäºå±‚å¤§å°{len(layer_account_ids)})")
                print(f"å½“å‰æ€»è¿­ä»£æ¬¡æ•°: {total_iterations}")
                
                optimized_predictions, account_status = parallel_binary_optimize_accounts(
                    layer_account_ids,
                    current_predictions,
                    upload_file,
                    max_iterations=None,  # æ— é™åˆ¶ï¼Œæ‰¾åˆ°ä¸ºæ­¢
                    max_workers=10  # 10ä¸ªå¹¶è¡Œworkers
                )
                
                # ä¿å­˜ä¼˜åŒ–ç»“æœå’Œç¡®è®¤çŠ¶æ€
                for account_id in layer_account_ids:
                    final_predictions[account_id] = optimized_predictions[account_id]
                
                # ç»Ÿè®¡ç¡®è®¤çŠ¶æ€
                confirmed_count = sum(1 for status in account_status.values() if status != -1)
                unconfirmed_count = len(layer_account_ids) - confirmed_count
                print(f"å±‚ä¼˜åŒ–å®Œæˆ: ç¡®è®¤äº† {confirmed_count}/{len(layer_account_ids)} ä¸ªè´¦æˆ·ï¼Œæœªç¡®è®¤: {unconfirmed_count}")
        
        else:
            print(f"âŒ å±‚ v{layer['id']} ä¸Šä¼ å¤±è´¥ï¼Œä½¿ç”¨initial guess")
            for account_id in layer_account_ids:
                final_predictions[account_id] = layer['initial_guess']
        
        import json
        total_iterations += layer_iterations if 'layer_iterations' in locals() else 0
        
        # åˆ›å»ºå®Œæ•´çš„çŠ¶æ€æ–‡ä»¶ï¼ŒåŒ…å«ç¡®è®¤çŠ¶æ€
        all_account_status = {}
        if 'account_status' in locals():
            all_account_status.update(account_status)
        
        state = {
            'current_layer': layer['id'] + 1,
            'predictions': final_predictions,
            'account_status': all_account_status,  # æ–°å¢ç¡®è®¤çŠ¶æ€
            'total_iterations': total_iterations
        }
        with open(state_file, 'w') as f:
            json.dump(state, f)
        print(f"ä¿å­˜çŠ¶æ€: ç¬¬{layer['id']}å±‚å®Œæˆï¼Œç´¯è®¡è¿­ä»£: {total_iterations}")
        
        # Debug: æ˜¾ç¤ºç¡®è®¤çŠ¶æ€ç»Ÿè®¡
        if all_account_status:
            confirmed_good = sum(1 for status in all_account_status.values() if status == 0)
            confirmed_bad = sum(1 for status in all_account_status.values() if status == 1)
            unconfirmed = sum(1 for status in all_account_status.values() if status == -1)
            print(f"å½“å‰æ€»çŠ¶æ€: ç¡®è®¤good={confirmed_good}, ç¡®è®¤bad={confirmed_bad}, æœªç¡®è®¤={unconfirmed}")
    
    for account_id in scores_df['ID']:
        if account_id not in final_predictions:
            final_predictions[account_id] = 0
    
    bad_count = sum(final_predictions.values())
    good_count = len(final_predictions) - bad_count
    
    print(f"\nâœ… æ‰€æœ‰å±‚ä¼˜åŒ–å®Œæˆ")
    print(f"5å±‚é¢„æµ‹ç»“æœ: Bad={bad_count}, Good={good_count}")
    
    # v7.0æŒç»­ä¼˜åŒ– - æ¯æ¬¡F1ç ´æ–°é«˜å°±è¦†ç›–ä¿å­˜
    print(f"\n=== v7.0 æŒç»­ä¼˜åŒ– - ç›®æ ‡F1=1.0 ===")
    
    # åˆå§‹æµ‹è¯•
    v7_file = "/Users/mannormal/4011/Qi Zihan/v3/v7.0.csv"
    temp_df = pd.DataFrame([{"ID": aid, "Predict": pred} for aid, pred in final_predictions.items()])
    temp_df.to_csv(v7_file, index=False)
    
    best_f1 = upload_file(v7_file)
    best_predictions = final_predictions.copy()
    
    print(f"åˆå§‹F1={best_f1:.6f}")
    
    # æŒç»­ä¼˜åŒ–ç›´åˆ°F1=1æˆ–æ— æ³•æå‡
    max_rounds = 20
    scores_dict = dict(zip(scores_df['ID'], scores_df['predict']))
    tested_candidates = set()  # è®°å½•å·²æµ‹è¯•çš„å€™é€‰è´¦æˆ·ç»„åˆ
    no_improvement_rounds = 0  # è¿ç»­æ— æ”¹è¿›è½®æ¬¡è®¡æ•°
    
    for round_num in range(1, max_rounds + 1):
        print(f"\n--- v7.0 è½®æ¬¡ {round_num} ---")
        
        # è®¡ç®—å½“å‰æ··æ·†çŸ©é˜µ
        predicted_bad = sum(best_predictions.values())
        confusion = calculate_confusion_from_f1(best_f1, predicted_bad)
        
        if confusion['FP'] == 0 and confusion['FN'] == 0:
            print("ğŸ‰ è¾¾åˆ°å®Œç¾F1=1.0!")
            break
        
        print(f"TP={confusion['TP']}, FP={confusion['FP']}, FN={confusion['FN']}, TN={confusion['TN']}")
        
        # é€‰æ‹©ä¼˜åŒ–ç›®æ ‡ - ä½¿ç”¨æ¸è¿›ç­–ç•¥é¿å…é‡å¤æµ‹è¯•
        candidates = []
        
        # è®¡ç®—éœ€è¦æµ‹è¯•çš„è´¦æˆ·æ•°é‡ï¼ˆé€æ¸å¢åŠ èŒƒå›´ï¼‰
        fp_test_count = min(confusion['FP'], max(1, confusion['FP'] // (round_num + 1)))
        fn_test_count = min(confusion['FN'], max(1, confusion['FN'] // (round_num + 1)))
        
        if confusion['FP'] > 0:
            # æœ‰FPï¼šä¼˜åŒ–åˆ†æ•°æœ€ä½çš„badé¢„æµ‹è´¦æˆ·
            bad_accounts = [aid for aid, pred in best_predictions.items() if pred == 1]
            # è·³è¿‡å‰é¢è½®æ¬¡å·²æµ‹è¯•çš„è´¦æˆ·
            skip_count = (round_num - 1) * fp_test_count
            fp_candidates = sorted(bad_accounts, key=lambda x: scores_dict[x])[skip_count:skip_count + fp_test_count]
            candidates.extend(fp_candidates)
            print(f"ä¼˜åŒ–{len(fp_candidates)}ä¸ªå¯èƒ½çš„FPè´¦æˆ· (è·³è¿‡å‰{skip_count}ä¸ª)")
        
        if confusion['FN'] > 0:
            # æœ‰FNï¼šä¼˜åŒ–åˆ†æ•°æœ€é«˜çš„goodé¢„æµ‹è´¦æˆ·
            good_accounts = [aid for aid, pred in best_predictions.items() if pred == 0]
            # è·³è¿‡å‰é¢è½®æ¬¡å·²æµ‹è¯•çš„è´¦æˆ·
            skip_count = (round_num - 1) * fn_test_count
            fn_candidates = sorted(good_accounts, key=lambda x: scores_dict[x], reverse=True)[skip_count:skip_count + fn_test_count]
            candidates.extend(fn_candidates)
            print(f"ä¼˜åŒ–{len(fn_candidates)}ä¸ªå¯èƒ½çš„FNè´¦æˆ· (è·³è¿‡å‰{skip_count}ä¸ª)")
        
        if not candidates:
            print("æ²¡æœ‰æ›´å¤šå¯ä¼˜åŒ–çš„è´¦æˆ·")
            break
        
        # æ£€æŸ¥æ˜¯å¦å·²æµ‹è¯•è¿‡è¿™ç»„å€™é€‰è´¦æˆ·
        candidates_key = tuple(sorted(candidates))
        if candidates_key in tested_candidates:
            print("æ­¤ç»„åˆå·²æµ‹è¯•è¿‡ï¼Œå°è¯•æ‰©å¤§èŒƒå›´")
            # å¦‚æœå·²æµ‹è¯•è¿‡ï¼Œå¢åŠ æµ‹è¯•èŒƒå›´
            if confusion['FP'] > 0:
                bad_accounts = [aid for aid, pred in best_predictions.items() if pred == 1]
                fp_candidates = sorted(bad_accounts, key=lambda x: scores_dict[x])[:min(len(bad_accounts), confusion['FP'] + round_num)]
                candidates.extend(fp_candidates)
            if confusion['FN'] > 0:
                good_accounts = [aid for aid, pred in best_predictions.items() if pred == 0]
                fn_candidates = sorted(good_accounts, key=lambda x: scores_dict[x], reverse=True)[:min(len(good_accounts), confusion['FN'] + round_num)]
                candidates.extend(fn_candidates)
            candidates = list(set(candidates))  # å»é‡
            candidates_key = tuple(sorted(candidates))
            
            if candidates_key in tested_candidates:
                print("æ‰©å¤§èŒƒå›´åä»æ˜¯é‡å¤ç»„åˆï¼Œåœæ­¢ä¼˜åŒ–")
                break
        
        tested_candidates.add(candidates_key)
        
        # è¿›è¡Œä¼˜åŒ–
        optimized_predictions, v7_account_status = parallel_binary_optimize_accounts(
            candidates,
            best_predictions,
            upload_file,
            max_iterations=None,
            max_workers=10
        )
        
        # æµ‹è¯•æ–°ç»“æœ
        test_df = pd.DataFrame([{"ID": aid, "Predict": pred} for aid, pred in optimized_predictions.items()])
        test_df.to_csv(v7_file, index=False)
        
        new_f1 = upload_file(v7_file)
        
        if new_f1 > best_f1:
            print(f"ğŸ‰ F1ç ´æ–°é«˜: {best_f1:.6f} â†’ {new_f1:.6f}")
            best_f1 = new_f1
            best_predictions = optimized_predictions.copy()
            print(f"è¦†ç›–ä¿å­˜ v7.0.csv")
            no_improvement_rounds = 0  # é‡ç½®æ— æ”¹è¿›è®¡æ•°
        else:
            print(f"æœ¬è½®æ— æå‡: {new_f1:.6f} â‰¤ {best_f1:.6f}")
            no_improvement_rounds += 1
            
        # å¦‚æœè¿ç»­3è½®æ— æ”¹è¿›ï¼Œåœæ­¢ä¼˜åŒ–
        if no_improvement_rounds >= 3:
            print("è¿ç»­3è½®æ— æ”¹è¿›ï¼Œåœæ­¢ä¼˜åŒ–")
            break
            
        if best_f1 >= 0.9999:
            print("ğŸ‰ æ¥è¿‘å®Œç¾F1!")
            break
    
    print(f"\nv7.0æœ€ç»ˆç»“æœ: F1={best_f1:.6f}")
    print(f"æ€»è®¡å®Œæˆè¿­ä»£æ¬¡æ•°: {total_iterations}")
    
    # ä¿å­˜æœ€ç»ˆç»“æœä¸ºCSVæ–‡ä»¶
    if best_predictions:
        save_best_result(best_predictions, best_f1)
    
    # æœ€ç»ˆä¿å­˜çŠ¶æ€
    import json
    final_state = {
        'current_layer': 6,  # è¡¨ç¤ºå·²å®Œæˆæ‰€æœ‰å±‚
        'predictions': best_predictions,
        'total_iterations': total_iterations,
        'final_f1': best_f1
    }
    with open(state_file, 'w') as f:
        json.dump(final_state, f, indent=2)
    print(f"ä¿å­˜æœ€ç»ˆçŠ¶æ€: æ€»è¿­ä»£{total_iterations}æ¬¡ï¼ŒF1={best_f1:.6f}")
    
    return best_predictions


def main():
    print("=== V3äºŒåˆ†æ³•ä¼˜åŒ–ç³»ç»Ÿ ===")
    result = load_initial_predictions()
    print(f"âœ… å®Œæˆ: {result}")
    reset_score = upload_file("/Users/mannormal/4011/Qi Zihan/v2/results/Transformer_basic_submission_FULL_DATA_f1_0.8913_epochs_130.256.csv")
    print(f"é‡æ–°ä¸Šä¼ æ—§ç‰ˆæœ¬æ–‡ä»¶æµ‹è¯•F1: {reset_score}")
if __name__ == "__main__":
    main()